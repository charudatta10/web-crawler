## No Title No Content Read more ## Generative adversarial network Toggle the table of contents Generative adversarial network 23 languages العربية 閩南語 / Bân-lâm-gú Català Deutsch Ελληνικά Español فارسی Français 한국어 Italiano עברית Nederlands 日本語 Русский Simple English کوردی Suomi Svenska Türkçe Українська Tiếng Việt 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Special pages Permanent link Page information Cite this page Get shortened URL Download QR code Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Appearance move to sidebar hide From Wikipedia, the free encyclopedia Deep learning method Not to be confused with Adversarial machine learning . Part of  series on Machine learning and data mining Paradigms Supervised learning Unsupervised learning Semi-supervised learning Self-supervised learning Reinforcement learning Meta-learning Online learning Batch learning Curriculum learning Rule-based learning Neuro-symbolic AI Neuromorphic engineering Quantum machine learning Problems Classification Generative modeling Regression Clustering Dimensionality reduction Density estimation Anomaly detection Data cleaning AutoML Association rules Semantic analysis Structured prediction Feature engineering Feature learning Learning to rank Grammar induction Ontology learning Multimodal learning Supervised learning ( classification • regression ) Apprenticeship learning Decision trees Ensembles Bagging Boosting Random forest  -NN Linear regression Naive Bayes Artificial neural networks Logistic regression Perceptron Relevance vector machine (RVM) Support vector machine (SVM) Clustering BIRCH CURE Hierarchical  -means Fuzzy Expectation–maximization (EM) DBSCAN OPTICS Mean shift Dimensionality reduction Factor analysis CCA ICA LDA NMF PCA PGD -SNE SDL Structured prediction Graphical models Bayes net Conditional random field Hidden Markov Anomaly detection RANSAC  -NN Local outlier factor Isolation forest Artificial neural network Autoencoder Deep learning Feedforward neural network Recurrent neural network LSTM GRU ESN reservoir computing Boltzmann machine Restricted GAN Diffusion model SOM Convolutional neural network -Net LeNet AlexNet DeepDream Neural radiance field Transformer Vision Mamba Spiking neural network Memtransistor Electrochemical RAM (ECRAM) Reinforcement learning -learning SARSA Temporal difference (TD) Multi-agent Self-play Learning with humans Active learning Crowdsourcing Human-in-the-loop RLHF Model diagnostics Coefficient of determination Confusion matrix Learning curve ROC curve Mathematical foundations Kernel machines Bias–variance tradeoff Computational learning theory Empirical risk minimization Occam learning PAC learning Statistical learning VC theory Journals and conferences ECML PKDD NeurIPS ICML ICLR IJCAI ML JMLR Related articles Glossary of artificial intelligence List of datasets for machine-learning research List of datasets in computer vision and image processing Outline of machine learning    An illustration of how  GAN works  generative adversarial network ( GAN ) is  class of machine learning frameworks and  prominent framework for approaching generative AI . [  ] [  ] The concept was initially developed by Ian Goodfellow and his colleagues in June 2014. [  ] In  GAN, two neural networks contest with each other in the form of  zero-sum game , where one agent' gain is another agent' loss. Given  training set, this technique learns to generate new data with the same statistics as the training set. For example,  GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as  form of generative model for unsupervised learning , GANs have also proved useful for semi-supervised learning , [  ] fully supervised learning , [  ] and reinforcement learning . [  ] The core idea of  GAN is based on the "indirect" training through the discriminator, another neural network that can tell how "realistic" the input seems, which itself is also being updated dynamically. [  ] This means that the generator is not trained to minimize the distance to  specific image, but rather to fool the discriminator. This enables the model to learn in an unsupervised manner. GANs are similar to mimicry in evolutionary biology , with an evolutionary arms race between both networks. Definition [ edit ] Mathematical [ edit ] The original GAN is defined as the following game : [  ] Each probability space (  ,  ref ) {\displaystyle (\Omega ,\mu {\text{ref}})} defines  GAN game. There are  players: generator and discriminator. The generator' strategy set is  (  ) {\displaystyle {\mathcal {}}(\Omega )} , the set of all probability measures   {\displaystyle \mu {}} on  {\displaystyle \Omega } . The discriminator' strategy set is the set of Markov kernels   :  →  [  ,  ] {\displaystyle \mu {}:\Omega \to {\mathcal {}}[,]} , where  [  ,  ] {\displaystyle {\mathcal {}}[,]} is the set of probability measures on [  ,  ] {\displaystyle [,]} . The GAN game is  zero-sum game , with objective function  (   ,   ) :=   ∼  ref ,  ∼   (  ) ⁡ [ ln ⁡  ] +   ∼   ,  ∼   (  ) ⁡ [ ln ⁡ (  −  ) ] . {\displaystyle (\mu {},\mu {}):=\operatorname {} {\sim \mu {\text{ref}},\sim \mu {}()}[\ln ]+\operatorname {} {\sim \mu {},\sim \mu {}()}[\ln(-)].} The generator aims to minimize the objective, and the discriminator aims to maximize the objective. The generator' task is to approach   ≈  ref {\displaystyle \mu {}\approx \mu {\text{ref}}} , that is, to match its own output distribution as closely as possible to the reference distribution. The discriminator' task is to output  value close to  when the input appears to be from the reference distribution, and to output  value close to  when the input looks like it came from the generator distribution. In practice [ edit ] The generative network generates candidates while the discriminative network evaluates them. [  ] The contest operates in terms of data distributions. Typically, the generative network learns to map from  latent space to  data distribution of interest, while the discriminative network distinguishes candidates produced by the generator from the true data distribution. The generative network' training objective is to increase the error rate of the discriminative network (.., "fool" the discriminator network by producing novel candidates that the discriminator thinks are not synthesized (are part of the true data distribution)). [  ] [  ]  known dataset serves as the initial training data for the discriminator. Training involves presenting it with samples from the training dataset until it achieves acceptable accuracy. The generator is trained based on whether it succeeds in fooling the discriminator. Typically, the generator is seeded with randomized input that is sampled from  predefined latent space (..  multivariate normal distribution ). Thereafter, candidates synthesized by the generator are evaluated by the discriminator. Independent backpropagation procedures are applied to both networks so that the generator produces better samples, while the discriminator becomes more skilled at flagging synthetic samples. [  ] When used for image generation, the generator is typically  deconvolutional neural network , and the discriminator is  convolutional neural network . Relation to other statistical machine learning methods [ edit ] GANs are implicit generative models , [ 10 ] which means that they do not explicitly model the likelihood function nor provide  means for finding the latent variable corresponding to  given sample, unlike alternatives such as flow-based generative model . Main types of deep generative models that perform maximum likelihood estimation [ 11 ] Compared to fully visible belief networks such as WaveNet and PixelRNN and autoregressive models in general, GANs can generate one complete sample in one pass, rather than multiple passes through the network. Compared to Boltzmann machines and linear ICA , there is no restriction on the type of function used by the network. Since neural networks are universal approximators , GANs are asymptotically consistent . Variational autoencoders might be universal approximators, but it is not proven as of 2017. [ 11 ] Mathematical properties [ edit ] Measure-theoretic considerations [ edit ] This section provides some of the mathematical theory behind these methods. In modern probability theory based on measure theory ,  probability space also needs to be equipped with  -algebra . As  result,  more rigorous definition of the GAN game would make the following changes: Each probability space (  ,  ,  ref ) {\displaystyle (\Omega ,{\mathcal {}},\mu {\text{ref}})} defines  GAN game. The generator' strategy set is  (  ,  ) {\displaystyle {\mathcal {}}(\Omega ,{\mathcal {}})} , the set of all probability measures   {\displaystyle \mu {}} on the measure-space (  ,  ) {\displaystyle (\Omega ,{\mathcal {}})} . The discriminator' strategy set is the set of Markov kernels   : (  ,  ) →  ( [  ,  ] ,  ( [  ,  ] ) ) {\displaystyle \mu {}:(\Omega ,{\mathcal {}})\to {\mathcal {}}([,],{\mathcal {}}([,]))} , where  ( [  ,  ] ) {\displaystyle {\mathcal {}}([,])} is the Borel -algebra on [  ,  ] {\displaystyle [,]} . Since issues of measurability never arise in practice, these will not concern us further. Choice of the strategy set [ edit ] In the most generic version of the GAN game described above, the strategy set for the discriminator contains all Markov kernels   :  →  [  ,  ] {\displaystyle \mu {}:\Omega \to {\mathcal {}}[,]} , and the strategy set for the generator contains arbitrary probability distributions   {\displaystyle \mu {}} on  {\displaystyle \Omega } . However, as shown below, the optimal discriminator strategy against any   {\displaystyle \mu {}} is deterministic, so there is no loss of generality in restricting the discriminator' strategies to deterministic functions  :  → [  ,  ] {\displaystyle :\Omega \to [,]} . In most applications,  {\displaystyle } is  deep neural network function. As for the generator, while   {\displaystyle \mu {}} could theoretically be any computable probability distribution, in practice, it is usually implemented as  pushforward :   =   ∘  −  {\displaystyle \mu {}=\mu {}\circ ^{-}} . That is, start with  random variable  ∼   {\displaystyle \sim \mu {}} , where   {\displaystyle \mu {}} is  probability distribution that is easy to compute (such as the uniform distribution , or the Gaussian distribution ), then define  function  :   →  {\displaystyle :\Omega {}\to \Omega } . Then the distribution   {\displaystyle \mu {}} is the distribution of  (  ) {\displaystyle ()} . Consequently, the generator' strategy is usually defined as just  {\displaystyle } , leaving  ∼   {\displaystyle \sim \mu {}} implicit. In this formalism, the GAN game objective is  (  ,  ) :=   ∼  ref ⁡ [ ln ⁡  (  ) ] +   ∼   ⁡ [ ln ⁡ (  −  (  (  ) ) ) ] . {\displaystyle (,):=\operatorname {} {\sim \mu {\text{ref}}}[\ln ()]+\operatorname {} {\sim \mu {}}[\ln(-(()))].} Generative reparametrization [ edit ] The GAN architecture has two main components. One is casting optimization into  game, of form min  max   (  ,  ) {\displaystyle \min {}\max {}(,)} , which is different from the usual kind of optimization, of form min   (  ) {\displaystyle \min {\theta }(\theta )} . The other is the decomposition of   {\displaystyle \mu {}} into   ∘  −  {\displaystyle \mu {}\circ ^{-}} , which can be understood as  reparametrization trick. To see its significance, one must compare GAN with previous methods for learning generative models, which were plagued with "intractable probabilistic computations that arise in maximum likelihood estimation and related strategies". [  ] At the same time, Kingma and Welling [ 12 ] and Rezende et al. [ 13 ] developed the same idea of reparametrization into  general stochastic backpropagation method. Among its first applications was the variational autoencoder . Move order and strategic equilibria [ edit ] In the original paper, as well as most subsequent papers, it is usually assumed that the generator moves first , and the discriminator moves second , thus giving the following minimax game: min   max    (   ,   ) :=   ∼  ref ,  ∼   (  ) ⁡ [ ln ⁡  ] +   ∼   ,  ∼   (  ) ⁡ [ ln ⁡ (  −  ) ] . {\displaystyle \min {\mu {}}\max {\mu {}}(\mu {},\mu {}):=\operatorname {} {\sim \mu {\text{ref}},\sim \mu {}()}[\ln ]+\operatorname {} {\sim \mu {},\sim \mu {}()}[\ln(-)].} If both the generator' and the discriminator' strategy sets are spanned by  finite number of strategies, then by the minimax theorem , min   max    (   ,   ) = max   min    (   ,   ) {\displaystyle \min {\mu {}}\max {\mu {}}(\mu {},\mu {})=\max {\mu {}}\min {\mu {}}(\mu {},\mu {})} that is, the move order does not matter. However, since the strategy sets are both not finitely spanned, the minimax theorem does not apply, and the idea of an "equilibrium" becomes delicate. To wit, there are the following different concepts of equilibrium: Equilibrium when generator moves first, and discriminator moves second:  ^  ∈ arg ⁡ min   max    (   ,   ) ,  ^  ∈ arg ⁡ max    (  ^  ,   ) , {\displaystyle {\hat {\mu }}{}\in \arg \min {\mu {}}\max {\mu {}}(\mu {},\mu {}),\quad {\hat {\mu }}{}\in \arg \max {\mu {}}({\hat {\mu }}{},\mu {}),\quad } Equilibrium when discriminator moves first, and generator moves second:  ^  ∈ arg ⁡ max   min    (   ,   ) ,  ^  ∈ arg ⁡ min    (   ,  ^  ) , {\displaystyle {\hat {\mu }}{}\in \arg \max {\mu {}}\min {\mu {}}(\mu {},\mu {}),\quad {\hat {\mu }}{}\in \arg \min {\mu {}}(\mu {},{\hat {\mu }}{}),} Nash equilibrium (  ^  ,  ^  ) {\displaystyle ({\hat {\mu }}{},{\hat {\mu }}{})} , which is stable under simultaneous move order:  ^  ∈ arg ⁡ max    (  ^  ,   ) ,  ^  ∈ arg ⁡ min    (   ,  ^  ) {\displaystyle {\hat {\mu }}{}\in \arg \max {\mu {}}({\hat {\mu }}{},\mu {}),\quad {\hat {\mu }}{}\in \arg \min {\mu {}}(\mu {},{\hat {\mu }}{})} For general games, these equilibria do not have to agree, or even to exist. For the original GAN game, these equilibria all exist, and are all equal. However, for more general GAN games, these do not necessarily exist, or agree. [ 14 ] Main theorems for GAN game [ edit ] The original GAN paper proved the following two theorems: [  ] Theorem (the optimal discriminator computes the Jensen–Shannon divergence) — For any fixed generator strategy   {\displaystyle \mu {}} , let the optimal reply be  ∗ = arg ⁡ max   (   ,  ) {\displaystyle ^{*}=\arg \max {}(\mu {},)} , then  ∗ (  ) =   ref  (  ref +   )  (   ,  ∗ ) =     (  ref ;   ) −  ln ⁡  {\displaystyle {\begin{aligned}^{*}()&={\frac {\mu {\text{ref}}}{(\mu {\text{ref}}+\mu {})}}\\[6pt](\mu {},^{*})&=2D_{JS}(\mu {\text{ref}};\mu {})-\ln \end{aligned}}} where the derivative is the Radon–Nikodym derivative , and    {\displaystyle D_{JS}} is the Jensen–Shannon divergence . Proof By Jensen' inequality,   ∼  ref ,  ∼   (  ) ⁡ [ ln ⁡  ] ≤   ∼  ref ⁡ [ ln ⁡   ∼   (  ) ⁡ [  ] ] {\displaystyle \operatorname {} {\sim \mu {\text{ref}},\sim \mu {}()}[\ln ]\leq \operatorname {} {\sim \mu {\text{ref}}}[\ln \operatorname {} {\sim \mu {}()}[]]} and similarly for the other term. Therefore, the optimal reply can be deterministic, ..   (  ) =   (  ) {\displaystyle \mu {}()=\delta {()}} for some function  :  → [  ,  ] {\displaystyle :\Omega \to [,]} , in which case  (   ,   ) :=   ∼  ref ⁡ [ ln ⁡  (  ) ] +   ∼   ⁡ [ ln ⁡ (  −  (  ) ) ] . {\displaystyle (\mu {},\mu {}):=\operatorname {} {\sim \mu {\text{ref}}}[\ln ()]+\operatorname {} {\sim \mu {}}[\ln(-())].} To define suitable density functions, we define  base measure  :=  ref +   {\displaystyle \mu :=\mu {\text{ref}}+\mu {}} , which allows us to take the Radon–Nikodym derivatives  ref =   ref     =      {\displaystyle \rho {\text{ref}}={\frac {\mu {\text{ref}}}{\mu }}\quad \rho {}={\frac {\mu {}}{\mu }}} with  ref +   =  {\displaystyle \rho {\text{ref}}+\rho {}=} . We then have  (   ,   ) := ∫  (   ) [  ref (  ) ln ⁡ (  (  ) ) +   (  ) ln ⁡ (  −  (  ) ) ] . {\displaystyle (\mu {},\mu {}):=\int \mu (dx)\left[\rho {\text{ref}}()\ln(())+\rho {}()\ln(-())\right].} The integrand is just the negative cross-entropy between two Bernoulli random variables with parameters  ref (  ) {\displaystyle \rho {\text{ref}}()} and  (  ) {\displaystyle ()} . We can write this as −  (  ref (  ) ) −    (  ref (  ) ∥  (  ) ) {\displaystyle -(\rho {\text{ref}}())-D_{KL}(\rho {\text{ref}}()\parallel ())} , where  {\displaystyle } is the binary entropy function , so  (   ,   ) = − ∫  (   ) (  (  ref (  ) ) +    (  ref (  ) ∥  (  ) ) ) . {\displaystyle (\mu {},\mu {})=-\int \mu (dx)((\rho {\text{ref}}())+D_{KL}(\rho {\text{ref}}()\parallel ())).} This means that the optimal strategy for the discriminator is  (  ) =  ref (  ) {\displaystyle ()=\rho {\text{ref}}()} , with  (   ,   ∗ ) = − ∫  (   )  (  ref (  ) ) =    (  ref ∥   ) −  ln ⁡  {\displaystyle (\mu {},\mu {}^{*})=-\int \mu (dx)(\rho {\text{ref}}())=D_{JS}(\mu {\text{ref}}\parallel \mu {})-\ln } after routine calculation. Interpretation : For any fixed generator strategy   {\displaystyle \mu {}} , the optimal discriminator keeps track of the likelihood ratio between the reference distribution and the generator distribution:  (  )  −  (  ) =   ref    (  ) =  ref (   )   (   ) ;  (  ) =  ( ln ⁡  ref (   ) − ln ⁡   (   ) ) {\displaystyle {\frac {()}{-()}}={\frac {\mu {\text{ref}}}{\mu {}}}()={\frac {\mu {\text{ref}}(dx)}{\mu {}(dx)}};\quad ()=\sigma (\ln \mu {\text{ref}}(dx)-\ln \mu {}(dx))} where  {\displaystyle \sigma } is the logistic function . In particular, if the prior probability for an image  {\displaystyle } to come from the reference distribution is equal to   {\displaystyle {\frac {}{}}} , then  (  ) {\displaystyle ()} is just the posterior probability that  {\displaystyle } came from the reference distribution:  (  ) = Pr (  came from reference distribution ∣  ) . {\displaystyle ()=\Pr({\text{ came from reference distribution}}\mid ).} Theorem (the unique equilibrium point) — For any GAN game, there exists  pair (  ^  ,  ^  ) {\displaystyle ({\hat {\mu }}{},{\hat {\mu }}{})} that is both  sequential equilibrium and  Nash equilibrium:  (  ^  ,  ^  ) = min   max    (   ,   ) = max   min    (   ,   ) = −  ln ⁡   ^  ∈ arg ⁡ max   min    (   ,   ) ,  ^  ∈ arg ⁡ min   max    (   ,   )  ^  ∈ arg ⁡ max    (  ^  ,   ) ,  ^  ∈ arg ⁡ min    (   ,  ^  ) ∀  ∈  ,  ^  (  ) =    ,  ^  =  ref {\displaystyle {\begin{aligned}&({\hat {\mu }}{},{\hat {\mu }}{})=\min {\mu {}}\max {\mu {}}(\mu {},\mu {})=&\max {\mu {}}\min {\mu {}}(\mu {},\mu {})=-\ln \\[6pt]&{\hat {\mu }}{}\in \arg \max {\mu {}}\min {\mu {}}(\mu {},\mu {}),&\quad {\hat {\mu }}{}\in \arg \min {\mu {}}\max {\mu {}}(\mu {},\mu {})\\[6pt]&{\hat {\mu }}{}\in \arg \max {\mu {}}({\hat {\mu }}{},\mu {}),&\quad {\hat {\mu }}{}\in \arg \min {\mu {}}(\mu {},{\hat {\mu }}{})\\[6pt]&\forall \in \Omega ,{\hat {\mu }}{}()=\delta {\frac {}{}},&\quad {\hat {\mu }}{}=\mu {\text{ref}}\end{aligned}}} That is, the generator perfectly mimics the reference, and the discriminator outputs   {\displaystyle {\frac {}{}}} deterministically on all inputs. Proof From the previous proposition, arg ⁡ min   max    (   ,   ) =  ref ; min   max    (   ,   ) = −  ln ⁡ . {\displaystyle \arg \min {\mu {}}\max {\mu {}}(\mu {},\mu {})=\mu {\text{ref}};\quad \min {\mu {}}\max {\mu {}}(\mu {},\mu {})=-\ln .} For any fixed discriminator strategy   {\displaystyle \mu {}} , any   {\displaystyle \mu {}} concentrated on the set {  ∣   ∼   (  ) ⁡ [ ln ⁡ (  −  ) ] = inf    ∼   (  ) ⁡ [ ln ⁡ (  −  ) ] } {\displaystyle \{\mid \operatorname {} {\sim \mu {}()}[\ln(-)]=\inf {}\operatorname {} {\sim \mu {}()}[\ln(-)]\}} is an optimal strategy for the generator. Thus, arg ⁡ max   min    (   ,   ) = arg ⁡ max     ∼  ref ,  ∼   (  ) ⁡ [ ln ⁡  ] + inf    ∼   (  ) ⁡ [ ln ⁡ (  −  ) ] . {\displaystyle \arg \max {\mu {}}\min {\mu {}}(\mu {},\mu {})=\arg \max {\mu {}}\operatorname {} {\sim \mu {\text{ref}},\sim \mu {}()}[\ln ]+\inf {}\operatorname {} {\sim \mu {}()}[\ln(-)].} By Jensen' inequality, the discriminator can only improve by adopting the deterministic strategy of always playing  (  ) =   ∼   (  ) ⁡ [  ] {\displaystyle ()=\operatorname {} {\sim \mu {}()}[]} . Therefore, arg ⁡ max   min    (   ,   ) = arg ⁡ max    ∼  ref ⁡ [ ln ⁡  (  ) ] + inf  ln ⁡ (  −  (  ) ) {\displaystyle \arg \max {\mu {}}\min {\mu {}}(\mu {},\mu {})=\arg \max {}\operatorname {} {\sim \mu {\text{ref}}}[\ln ()]+\inf {}\ln(-())} By Jensen' inequality, ln ⁡   ∼  ref ⁡ [  (  ) ] + inf  ln ⁡ (  −  (  ) ) = ln ⁡   ∼  ref ⁡ [  (  ) ] + ln ⁡ (  − sup   (  ) ) = ln ⁡ [   ∼  ref ⁡ [  (  ) ] (  − sup   (  ) ) ] ≤ ln ⁡ [ sup   (  ) ) (  − sup   (  ) ) ] ≤ ln ⁡   , {\displaystyle {\begin{aligned}&\ln \operatorname {} {\sim \mu {\text{ref}}}[()]+\inf {}\ln(-())\\[6pt]={}&\ln \operatorname {} {\sim \mu {\text{ref}}}[()]+\ln(-\sup {}())\\[6pt]={}&\ln[\operatorname {} {\sim \mu {\text{ref}}}[()](-\sup {}())]\leq \ln[\sup {}())(-\sup {}())]\leq \ln {\frac {}{}},\end{aligned}}} with equality if  (  ) =   {\displaystyle ()={\frac {}{}}} , so ∀  ∈  ,  ^  (  ) =    ; max   min    (   ,   ) = −  ln ⁡ . {\displaystyle \forall \in \Omega ,{\hat {\mu }}{}()=\delta {\frac {}{}};\quad \max {\mu {}}\min {\mu {}}(\mu {},\mu {})=-\ln .} Finally, to check that this is  Nash equilibrium, note that when   =  ref {\displaystyle \mu {}=\mu {\text{ref}}} , we have  (   ,   ) :=   ∼  ref ,  ∼   (  ) ⁡ [ ln ⁡ (  (  −  ) ) ] {\displaystyle (\mu {},\mu {}):=\operatorname {} {\sim \mu {\text{ref}},\sim \mu {}()}[\ln((-))]} which is always maximized by  =   {\displaystyle ={\frac {}{}}} . When ∀  ∈  ,   (  ) =    {\displaystyle \forall \in \Omega ,\mu {}()=\delta {\frac {}{}}} , any strategy is optimal for the generator. Training and evaluating GAN [ edit ] Training [ edit ] Unstable convergence [ edit ] While the GAN game has  unique global equilibrium point when both the generator and discriminator have access to their entire strategy sets, the equilibrium is no longer guaranteed when they have  restricted strategy set. [ 14 ] In practice, the generator has access only to measures of form   ∘   −  {\displaystyle \mu {}\circ G_{\theta }^{-}} , where   {\displaystyle G_{\theta }} is  function computed by  neural network with parameters  {\displaystyle \theta } , and   {\displaystyle \mu {}} is an easily sampled distribution, such as the uniform or normal distribution. Similarly, the discriminator has access only to functions of form   {\displaystyle D_{\zeta }} ,  function computed by  neural network with parameters  {\displaystyle \zeta } . These restricted strategy sets take up  vanishingly small proportion of their entire strategy sets. [ 15 ] Further, even if an equilibrium still exists, it can only be found by searching in the high-dimensional space of all possible neural network functions. The standard strategy of using gradient descent to find the equilibrium often does not work for GAN, and often the game "collapses" into one of several failure modes. To improve the convergence stability, some training strategies start with an easier task, such as generating low-resolution images [ 16 ] or simple images (one object with uniform background), [ 17 ] and gradually increase the difficulty of the task during training. This essentially translates to applying  curriculum learning scheme. [ 18 ] Mode collapse [ edit ] GANs often suffer from mode collapse where they fail to generalize properly, missing entire modes from the input data. For example,  GAN trained on the MNIST dataset containing many samples of each digit might only generate pictures of digit . This was termed "the Helvetica scenario". [  ] One way this can happen is if the generator learns too fast compared to the discriminator. If the discriminator  {\displaystyle } is held constant, then the optimal generator would only output elements of arg ⁡ max   (  ) {\displaystyle \arg \max {}()} . [ 19 ] So for example, if during GAN training for generating MNIST dataset, for  few epochs, the discriminator somehow prefers the digit  slightly more than other digits, the generator may seize the opportunity to generate only digit , then be unable to escape the local minimum after the discriminator improves. Some researchers perceive the root problem to be  weak discriminative network that fails to notice the pattern of omission, while others assign blame to  bad choice of objective function . Many solutions have been proposed, but it is still an open problem. [ 20 ] [ 21 ] Even the state-of-the-art architecture, BigGAN (2019), could not avoid mode collapse. The authors resorted to "allowing collapse to occur at the later stages of training, by which time  model is sufficiently trained to achieve good results". [ 22 ] Two time-scale update rule [ edit ] The two time-scale update rule (TTUR) is proposed to make GAN convergence more stable by making the learning rate of the generator lower than that of the discriminator. The authors argued that the generator should move slower than the discriminator, so that it does not "drive the discriminator steadily into new regions without capturing its gathered information". They proved that  general class of games that included the GAN game, when trained under TTUR, "converges under mild assumptions to  stationary local Nash equilibrium". [ 23 ] They also proposed using the Adam stochastic optimization [ 24 ] to avoid mode collapse, as well as the Fréchet inception distance for evaluating GAN performances. Vanishing gradient [ edit ] Conversely, if the discriminator learns too fast compared to the generator, then the discriminator could almost perfectly distinguish    ,  ref {\displaystyle \mu {G_{\theta }},\mu {\text{ref}}} . In such case, the generator   {\displaystyle G_{\theta }} could be stuck with  very high loss no matter which direction it changes its  {\displaystyle \theta } , meaning that the gradient ∇   (   ,   ) {\displaystyle \nabla {\theta }(G_{\theta },D_{\zeta })} would be close to zero. In such case, the generator cannot learn,  case of the vanishing gradient problem . [ 15 ] Intuitively speaking, the discriminator is too good, and since the generator cannot take any small step (only small steps are considered in gradient descent) to improve its payoff, it does not even try. One important method for solving this problem is the Wasserstein GAN . Evaluation [ edit ] GANs are usually evaluated by Inception score (IS), which measures how varied the generator' outputs are (as classified by an image classifier, usually Inception-v3 ), or Fréchet inception distance (FID), which measures how similar the generator' outputs are to  reference set (as classified by  learned image featurizer, such as Inception-v3 without its final layer). Many papers that propose new GAN architectures for image generation report how their architectures break the state of the art on FID or IS. Another evaluation method is the Learned Perceptual Image Patch Similarity (LPIPS), which starts with  learned image featurizer   : Image →   {\displaystyle f_{\theta }:{\text{Image}}\to \mathbb {} ^{}} , and finetunes it by supervised learning on  set of (  ,  ′ ,                     ⁡ (  ,  ′ ) ) {\displaystyle (,',\operatorname {perceptual~difference} (,'))} , where  {\displaystyle } is an image,  ′ {\displaystyle '} is  perturbed version of it, and                     ⁡ (  ,  ′ ) {\displaystyle \operatorname {perceptual~difference} (,')} is how much they differ, as reported by human subjects. The model is finetuned so that it can approximate ‖   (  ) −   (  ′ ) ‖ ≈                     ⁡ (  ,  ′ ) {\displaystyle \|f_{\theta }()-f_{\theta }(')\|\approx \operatorname {perceptual~difference} (,')} . This finetuned model is then used to define LPIPS ⁡ (  ,  ′ ) := ‖   (  ) −   (  ′ ) ‖ {\displaystyle \operatorname {LPIPS} (,'):=\|f_{\theta }()-f_{\theta }(')\|} . [ 25 ] Other evaluation methods are reviewed in. [ 26 ] Variants [ edit ] There is  veritable zoo of GAN variants. [ 27 ] Some of the most prominent are as follows: Conditional GAN [ edit ] Conditional GANs are similar to standard GANs except they allow the model to conditionally generate samples based on additional information. For example, if we want to generate  cat face given  dog picture, we could use  conditional GAN. The generator in  GAN game generates   {\displaystyle \mu {}} ,  probability distribution on the probability space  {\displaystyle \Omega } . This leads to the idea of  conditional GAN, where instead of generating one probability distribution on  {\displaystyle \Omega } , the generator generates  different probability distribution   (  ) {\displaystyle \mu {}()} on  {\displaystyle \Omega } , for each given class label  {\displaystyle } . For example, for generating images that look like ImageNet , the generator should be able to generate  picture of cat when given the class label "cat". In the original paper, [  ] the authors noted that GAN can be trivially extended to conditional GAN by providing the labels to both the generator and the discriminator. Concretely, the conditional GAN game is just the GAN game with class labels provided:  (   ,  ) :=   ∼   ,  ∼  ref (  ) ⁡ [ ln ⁡  (  ,  ) ] +   ∼   ,  ∼   (  ) ⁡ [ ln ⁡ (  −  (  ,  ) ) ] {\displaystyle (\mu {},):=\operatorname {} {\sim \mu {},\sim \mu {\text{ref}}()}[\ln (,)]+\operatorname {} {\sim \mu {},\sim \mu {}()}[\ln(-(,))]} where   {\displaystyle \mu {}} is  probability distribution over classes,  ref (  ) {\displaystyle \mu {\text{ref}}()} is the probability distribution of real images of class  {\displaystyle } , and   (  ) {\displaystyle \mu {}()} the probability distribution of images generated by the generator when given class label  {\displaystyle } . In 2017,  conditional GAN learned to generate 1000 image classes of ImageNet . [ 28 ] GANs with alternative architectures [ edit ] The GAN game is  general framework and can be run with any reasonable parametrization of the generator  {\displaystyle } and discriminator  {\displaystyle } . In the original paper, the authors demonstrated it using multilayer perceptron networks and convolutional neural networks . Many alternative architectures have been tried. Deep convolutional GAN (DCGAN): [ 29 ] For both generator and discriminator, uses only deep networks consisting entirely of convolution-deconvolution layers, that is, fully convolutional networks. [ 30 ] Self-attention GAN (SAGAN): [ 31 ] Starts with the DCGAN, then adds residually-connected standard self-attention modules to the generator and discriminator. Variational autoencoder GAN (VAEGAN): [ 32 ] Uses  variational autoencoder (VAE) for the generator. Transformer GAN (TransGAN): [ 33 ] Uses the pure transformer architecture for both the generator and discriminator, entirely devoid of convolution-deconvolution layers. Flow-GAN: [ 34 ] Uses flow-based generative model for the generator, allowing efficient computation of the likelihood function. GANs with alternative objectives [ edit ] Many GAN variants are merely obtained by changing the loss functions for the generator and discriminator. Original GAN: We recast the original GAN objective into  form more convenient for comparison: { min    (  ,   ) = −   ∼   ⁡ [ ln ⁡  (  ) ] −   ∼  ref ⁡ [ ln ⁡ (  −  (  ) ) ] min    (  ,   ) = −   ∼   ⁡ [ ln ⁡ (  −  (  ) ) ] {\displaystyle {\begin{cases}\min {}L_{}(,\mu {})=-\operatorname {} {\sim \mu {}}[\ln ()]-\operatorname {} {\sim \mu {\text{ref}}}[\ln(-())]\\\min {}L_{}(,\mu {})=-\operatorname {} {\sim \mu {}}[\ln(-())]\end{cases}}} Original GAN, non-saturating loss: This objective for generator was recommended in the original paper for faster convergence. [  ]   =   ∼   ⁡ [ ln ⁡  (  ) ] {\displaystyle L_{}=\operatorname {} {\sim \mu {}}[\ln ()]} The effect of using this objective is analyzed in Section .. of Arjovsky et al. [ 35 ] Original GAN, maximum likelihood:   =   ∼   ⁡ [ ( exp ∘  −  ∘  ) (  ) ] {\displaystyle L_{}=\operatorname {} {\sim \mu {}}[({\exp }\circ \sigma ^{-}\circ )()]} where  {\displaystyle \sigma } is the logistic function. When the discriminator is optimal, the generator gradient is the same as in maximum likelihood estimation , even though GAN cannot perform maximum likelihood estimation itself . [ 36 ] [ 37 ] Hinge loss GAN : [ 38 ]   = −   ∼  ref ⁡ [ min (  , −  +  (  ) ) ] −   ∼   ⁡ [ min (  , −  −  (  ) ) ] {\displaystyle L_{}=-\operatorname {} {\sim p_{\text{ref}}}\left[\min \left(,-+()\right)\right]-\operatorname {} {\sim \mu {}}\left[\min \left(,--\left(\right)\right)\right]}   = −   ∼   ⁡ [  (  ) ] {\displaystyle L_{}=-\operatorname {} {\sim \mu {}}[()]} Least squares GAN: [ 39 ]   =   ∼  ref ⁡ [ (  (  ) −  )  ] +   ∼   ⁡ [ (  (  ) −  )  ] {\displaystyle L_{}=\operatorname {} {\sim \mu {\text{ref}}}[(()-)^{}]+\operatorname {} {\sim \mu {}}[(()-)^{}]}   =   ∼   ⁡ [ (  (  ) −  )  ] {\displaystyle L_{}=\operatorname {} {\sim \mu {}}[(()-)^{}]} where  ,  ,  {\displaystyle ,,} are parameters to be chosen. The authors recommended  = −  ,  =  ,  =  {\displaystyle =-,=,=} . Wasserstein GAN (WGAN) [ edit ] Main article: Wasserstein GAN The Wasserstein GAN modifies the GAN game at two points: The discriminator' strategy set is the set of measurable functions of type  :  →  {\displaystyle :\Omega \to \mathbb {} } with bounded Lipschitz norm : ‖  ‖  ≤  {\displaystyle \|\|{}\leq } , where  {\displaystyle } is  fixed positive constant. The objective is      (   ,  ) :=   ∼   ⁡ [  (  ) ] −   ∼  ref [  (  ) ] {\displaystyle L_{WGAN}(\mu {},):=\operatorname {} {\sim \mu {}}[()]-\mathbb {} {\sim \mu {\text{ref}}}[()]} One of its purposes is to solve the problem of mode collapse (see above). [ 15 ] The authors claim "In no experiment did we see evidence of mode collapse for the WGAN algorithm". GANs with more than two players [ edit ] Adversarial autoencoder [ edit ] An adversarial autoencoder (AAE) [ 40 ] is more autoencoder than GAN. The idea is to start with  plain autoencoder , but train  discriminator to discriminate the latent vectors from  reference distribution (often the normal distribution). InfoGAN [ edit ] In conditional GAN, the generator receives both  noise vector  {\displaystyle } and  label  {\displaystyle } , and produces an image  (  ,  ) {\displaystyle (,)} . The discriminator receives image-label pairs (  ,  ) {\displaystyle (,)} , and computes  (  ,  ) {\displaystyle (,)} . When the training dataset is unlabeled, conditional GAN does not work directly. The idea of InfoGAN is to decree that every latent vector in the latent space can be decomposed as (  ,  ) {\displaystyle (,)} : an incompressible noise part  {\displaystyle } , and an informative label part  {\displaystyle } , and encourage the generator to comply with the decree, by encouraging it to maximize  (  ,  (  ,  ) ) {\displaystyle (,(,))} , the mutual information between  {\displaystyle } and  (  ,  ) {\displaystyle (,)} , while making no demands on the mutual information  {\displaystyle } between  (  ,  ) {\displaystyle (,)} . Unfortunately,  (  ,  (  ,  ) ) {\displaystyle (,(,))} is intractable in general, The key idea of InfoGAN is Variational Mutual Information Maximization: [ 41 ] indirectly maximize it by maximizing  lower bound  ^ (  ,  ) =   ∼   ,  ∼   [ ln ⁡  (  ∣  (  ,  ) ) ] ;  (  ,  (  ,  ) ) ≥ sup   ^ (  ,  ) {\displaystyle {\hat {}}(,)=\mathbb {} {\sim \mu {},\sim \mu {}}[\ln (\mid (,))];\quad (,(,))\geq \sup {}{\hat {}}(,)} where  {\displaystyle } ranges over all Markov kernels of type  :   →  (   ) {\displaystyle :\Omega {}\to {\mathcal {}}(\Omega {})} . The InfoGAN game is defined as follows: [ 42 ] Three probability spaces define an InfoGAN game: (   ,  ref ) {\displaystyle (\Omega {},\mu {\text{ref}})} , the space of reference images. (   ,   ) {\displaystyle (\Omega {},\mu {})} , the fixed random noise generator. (   ,   ) {\displaystyle (\Omega {},\mu {})} , the fixed random information generator. There are  players in  teams: generator, , and discriminator. The generator and  are on one team, and the discriminator on the other team. The objective function is  (  ,  ,  ) =     (  ,  ) −   ^ (  ,  ) {\displaystyle (,,)=L_{GAN}(,)-\lambda {\hat {}}(,)} where     (  ,  ) =   ∼  ref , ⁡ [ ln ⁡  (  ) ] +   ∼   ⁡ [ ln ⁡ (  −  (  (  ,  ) ) ) ] {\displaystyle L_{GAN}(,)=\operatorname {} {\sim \mu {\text{ref}},}[\ln ()]+\operatorname {} {\sim \mu {}}[\ln(-((,)))]} is the original GAN game objective, and  ^ (  ,  ) =   ∼   ,  ∼   [ ln ⁡  (  ∣  (  ,  ) ) ] {\displaystyle {\hat {}}(,)=\mathbb {} {\sim \mu {},\sim \mu {}}[\ln (\mid (,))]} Generator- team aims to minimize the objective, and discriminator aims to maximize it: min  ,  max   (  ,  ,  ) {\displaystyle \min {,}\max {}(,,)} Bidirectional GAN (BiGAN) [ edit ] The standard GAN generator is  function of type  :   →   {\displaystyle :\Omega {}\to \Omega {}} , that is, it is  mapping from  latent space   {\displaystyle \Omega {}} to the image space   {\displaystyle \Omega {}} . This can be understood as  "decoding" process, whereby every latent vector  ∈   {\displaystyle \in \Omega {}} is  code for an image  ∈   {\displaystyle \in \Omega {}} , and the generator performs the decoding. This naturally leads to the idea of training another network that performs "encoding", creating an autoencoder out of the encoder-generator pair. Already in the original paper, [  ] the authors noted that "Learned approximate inference can be performed by training an auxiliary network to predict  {\displaystyle } given  {\displaystyle } ". The bidirectional GAN architecture performs exactly this. [ 43 ] The BiGAN is defined as follows: Two probability spaces define  BiGAN game: (   ,   ) {\displaystyle (\Omega {},\mu {})} , the space of reference images. (   ,   ) {\displaystyle (\Omega {},\mu {})} , the latent space. There are  players in  teams: generator, encoder, and discriminator. The generator and encoder are on one team, and the discriminator on the other team. The generator' strategies are functions  :   →   {\displaystyle :\Omega {}\to \Omega {}} , and the encoder' strategies are functions  :   →   {\displaystyle :\Omega {}\to \Omega {}} . The discriminator' strategies are functions  :   → [  ,  ] {\displaystyle :\Omega {}\to [,]} . The objective function is  (  ,  ,  ) =   ∼   [ ln ⁡  (  ,  (  ) ) ] +   ∼   [ ln ⁡ (  −  (  (  ) ,  ) ) ] {\displaystyle (,,)=\mathbb {} {\sim \mu {}}[\ln (,())]+\mathbb {} {\sim \mu {}}[\ln(-((),))]} Generator-encoder team aims to minimize the objective, and discriminator aims to maximize it: min  ,  max   (  ,  ,  ) {\displaystyle \min {,}\max {}(,,)} In the paper, they gave  more abstract definition of the objective as:  (  ,  ,  ) =  (  ,  ) ∼   ,  [ ln ⁡  (  ,  ) ] +  (  ,  ) ∼   ,  [ ln ⁡ (  −  (  ,  ) ) ] {\displaystyle (,,)=\mathbb {} {(,)\sim \mu {,}}[\ln (,)]+\mathbb {} {(,)\sim \mu {,}}[\ln(-(,))]} where   ,  (   ,   ) =   (   ) ⋅   (  ) (   ) {\displaystyle \mu {,}(dx,dz)=\mu {}(dx)\cdot \delta {()}(dz)} is the probability distribution on   ×   {\displaystyle \Omega {}\times \Omega {}} obtained by pushing   {\displaystyle \mu {}} forward via  ↦ (  ,  (  ) ) {\displaystyle \mapsto (,())} , and   ,  (   ,   ) =   (  ) (   ) ⋅   (   ) {\displaystyle \mu {,}(dx,dz)=\delta {()}(dx)\cdot \mu {}(dz)} is the probability distribution on   ×   {\displaystyle \Omega {}\times \Omega {}} obtained by pushing   {\displaystyle \mu {}} forward via  ↦ (  (  ) ,  ) {\displaystyle \mapsto ((),)} . Applications of bidirectional models include semi-supervised learning , [ 44 ] interpretable machine learning , [ 45 ] and neural machine translation . [ 46 ] CycleGAN [ edit ] CycleGAN is an architecture for performing translations between two domains, such as between photos of horses and photos of zebras, or photos of night cities and photos of day cities. The CycleGAN game is defined as follows: [ 47 ] There are two probability spaces (   ,   ) , (   ,   ) {\displaystyle (\Omega {},\mu {}),(\Omega {},\mu {})} , corresponding to the two domains needed for translations fore-and-back. There are  players in  teams: generators   :   →   ,   :   →   {\displaystyle G_{}:\Omega {}\to \Omega {},G_{}:\Omega {}\to \Omega {}} , and discriminators   :   → [  ,  ] ,   :   → [  ,  ] {\displaystyle D_{}:\Omega {}\to [,],D_{}:\Omega {}\to [,]} . The objective function is  (   ,   ,   ,   ) =     (   ,   ) +     (   ,   ) +        (   ,   ) {\displaystyle (G_{},G_{},D_{},D_{})=L_{GAN}(G_{},D_{})+L_{GAN}(G_{},D_{})+\lambda L_{cycle}(G_{},G_{})} where  {\displaystyle \lambda } is  positive adjustable parameter,     {\displaystyle L_{GAN}} is the GAN game objective, and       {\displaystyle L_{cycle}} is the cycle consistency loss :       (   ,   ) =   ∼   ‖   (   (  ) ) −  ‖ +   ∼   ‖   (   (  ) ) −  ‖ {\displaystyle L_{cycle}(G_{},G_{})=E_{\sim \mu {}}\|G_{}(G_{}())-\|+E_{\sim \mu {}}\|G_{}(G_{}())-\|} The generators aim to minimize the objective, and the discriminators aim to maximize it: min   ,   max   ,    (   ,   ,   ,   ) {\displaystyle \min {G_{},G_{}}\max {D_{},D_{}}(G_{},G_{},D_{},D_{})} Unlike previous work like pix2pix, [ 48 ] which requires paired training data, cycleGAN requires no paired data. For example, to train  pix2pix model to turn  summer scenery photo to winter scenery photo and back, the dataset must contain pairs of the same place in summer and winter, shot at the same angle; cycleGAN would only need  set of summer scenery photos, and an unrelated set of winter scenery photos. GANs with particularly large or small scales [ edit ] BigGAN [ edit ] The BigGAN is essentially  self-attention GAN trained on  large scale (up to 80 million parameters) to generate large images of ImageNet (up to 512  512 resolution), with numerous engineering tricks to make it converge. [ 22 ] [ 49 ] Invertible data augmentation [ edit ] When there is insufficient training data, the reference distribution  ref {\displaystyle \mu {\text{ref}}} cannot be well-approximated by the empirical distribution given by the training dataset. In such cases, data augmentation can be applied, to allow training GAN on smaller datasets. Naïve data augmentation, however, brings its problems. Consider the original GAN game, slightly reformulated as follows: { min    (  ,   ) = −   ∼  ref ⁡ [ ln ⁡  (  ) ] −   ∼   ⁡ [ ln ⁡ (  −  (  ) ) ] min    (  ,   ) = −   ∼   ⁡ [ ln ⁡ (  −  (  ) ) ] {\displaystyle {\begin{cases}\min {}L_{}(,\mu {})=-\operatorname {} {\sim \mu {\text{ref}}}[\ln ()]-\operatorname {} {\sim \mu {}}[\ln(-())]\\\min {}L_{}(,\mu {})=-\operatorname {} {\sim \mu {}}[\ln(-())]\end{cases}}} Now we use data augmentation by randomly sampling semantic-preserving transforms  :  →  {\displaystyle :\Omega \to \Omega } and applying them to the dataset, to obtain the reformulated GAN game: { min    (  ,   ) = −   ∼  ref ,  ∼  trans ⁡ [ ln ⁡  (  (  ) ) ] −   ∼   ⁡ [ ln ⁡ (  −  (  ) ) ] min    (  ,   ) = −   ∼   ⁡ [ ln ⁡ (  −  (  ) ) ] {\displaystyle {\begin{cases}\min {}L_{}(,\mu {})=-\operatorname {} {\sim \mu {\text{ref}},\sim \mu {\text{trans}}}[\ln (())]-\operatorname {} {\sim \mu {}}[\ln(-())]\\\min {}L_{}(,\mu {})=-\operatorname {} {\sim \mu {}}[\ln(-())]\end{cases}}} This is equivalent to  GAN game with  different distribution  ref ′ {\displaystyle \mu {\text{ref}}'} , sampled by  (  ) {\displaystyle ()} , with  ∼  ref ,  ∼  trans {\displaystyle \sim \mu {\text{ref}},\sim \mu {\text{trans}}} . For example, if  ref {\displaystyle \mu {\text{ref}}} is the distribution of images in ImageNet, and  trans {\displaystyle \mu {\text{trans}}} samples identity-transform with probability ., and horizontal-reflection with probability ., then  ref ′ {\displaystyle \mu {\text{ref}}'} is the distribution of images in ImageNet and horizontally-reflected ImageNet, combined. The result of such training would be  generator that mimics  ref ′ {\displaystyle \mu {\text{ref}}'} . For example, it would generate images that look like they are randomly cropped, if the data augmentation uses random cropping. The solution is to apply data augmentation to both generated and real images: { min    (  ,   ) = −   ∼  ref ,  ∼  trans ⁡ [ ln ⁡  (  (  ) ) ] −   ∼   ,  ∼  trans ⁡ [ ln ⁡ (  −  (  (  ) ) ) ] min    (  ,   ) = −   ∼   ,  ∼  trans ⁡ [ ln ⁡ (  −  (  (  ) ) ) ] {\displaystyle {\begin{cases}\min {}L_{}(,\mu {})=-\operatorname {} {\sim \mu {\text{ref}},\sim \mu {\text{trans}}}[\ln (())]-\operatorname {} {\sim \mu {},\sim \mu {\text{trans}}}[\ln(-(()))]\\\min {}L_{}(,\mu {})=-\operatorname {} {\sim \mu {},\sim \mu {\text{trans}}}[\ln(-(()))]\end{cases}}} The authors demonstrated high-quality generation using just 100-picture-large datasets. [ 50 ] The StyleGAN--ADA paper points out  further point on data augmentation: it must be invertible . [ 51 ] Continue with the example of generating ImageNet pictures. If the data augmentation is "randomly rotate the picture by , 90, 180, 270 degrees with equal probability", then there is no way for the generator to know which is the true orientation: Consider two generators  ,  ′ {\displaystyle ,'} , such that for any latent  {\displaystyle } , the generated image  (  ) {\displaystyle ()} is  90-degree rotation of  ′ (  ) {\displaystyle '()} . They would have exactly the same expected loss, and so neither is preferred over the other. The solution is to only use invertible data augmentation: instead of "randomly rotate the picture by , 90, 180, 270 degrees with equal probability", use "randomly rotate the picture by 90, 180, 270 degrees with . probability, and keep the picture as it is with . probability". This way, the generator is still rewarded to keep images oriented the same way as un-augmented ImageNet pictures. Abstractly, the effect of randomly sampling transformations  :  →  {\displaystyle :\Omega \to \Omega } from the distribution  trans {\displaystyle \mu {\text{trans}}} is to define  Markov kernel  trans :  →  (  ) {\displaystyle K_{\text{trans}}:\Omega \to {\mathcal {}}(\Omega )} . Then, the data-augmented GAN game pushes the generator to find some  ^  ∈  (  ) {\displaystyle {\hat {\mu }}{}\in {\mathcal {}}(\Omega )} , such that  trans ∗  ref =  trans ∗  ^  {\displaystyle K_{\text{trans}}*\mu {\text{ref}}=K_{\text{trans}}*{\hat {\mu }}{}} where ∗ {\displaystyle *} is the Markov kernel convolution .  data-augmentation method is defined to be invertible if its Markov kernel  trans {\displaystyle K_{\text{trans}}} satisfies  trans ∗  =  trans ∗  ′ ⟹  =  ′ ∀  ,  ′ ∈  (  ) {\displaystyle K_{\text{trans}}*\mu =K_{\text{trans}}*\mu '\implies \mu =\mu '\quad \forall \mu ,\mu '\in {\mathcal {}}(\Omega )} Immediately by definition, we see that composing multiple invertible data-augmentation methods results in yet another invertible method. Also by definition, if the data-augmentation method is invertible, then using it in  GAN game does not change the optimal strategy  ^  {\displaystyle {\hat {\mu }}{}} for the generator, which is still  ref {\displaystyle \mu {\text{ref}}} . There are two prototypical examples of invertible Markov kernels: Discrete case : Invertible stochastic matrices , when  {\displaystyle \Omega } is finite. For example, if  = { ↑ , ↓ , ← , → } {\displaystyle \Omega =\{\uparrow ,\downarrow ,\leftarrow ,\rightarrow \}} is the set of four images of an arrow, pointing in  directions, and the data augmentation is "randomly rotate the picture by 90, 180, 270 degrees with probability  {\displaystyle } , and keep the picture as it is with probability (  −   ) {\displaystyle (-3p)} ", then the Markov kernel  trans {\displaystyle K_{\text{trans}}} can be represented as  stochastic matrix: [  trans ] = [ (  −   )     (  −   )     (  −   )     (  −   ) ] {\displaystyle [K_{\text{trans}}]={\begin{bmatrix}(-3p)&&&\\&(-3p)&&\\&&(-3p)&\\&&&(-3p)\end{bmatrix}}} and  trans {\displaystyle K_{\text{trans}}} is an invertible kernel iff [  trans ] {\displaystyle [K_{\text{trans}}]} is an invertible matrix, that is,  ≠  /  {\displaystyle \neq /} . Continuous case : The gaussian kernel, when  =   {\displaystyle \Omega =\mathbb {} ^{}} for some  ≥  {\displaystyle \geq } . For example, if  =  256  {\displaystyle \Omega =\mathbb {} ^{256^{}}} is the space of 256x256 images, and the data-augmentation method is "generate  gaussian noise  ∼  (  ,  256  ) {\displaystyle \sim {\mathcal {}}(,I_{256^{}})} , then add   {\displaystyle \epsilon } to the image", then  trans {\displaystyle K_{\text{trans}}} is just convolution by the density function of  (  ,    256  ) {\displaystyle {\mathcal {}}(,\epsilon ^{}I_{256^{}})} . This is invertible, because convolution by  gaussian is just convolution by the heat kernel , so given any  ∈  (   ) {\displaystyle \mu \in {\mathcal {}}(\mathbb {} ^{})} , the convolved distribution  trans ∗  {\displaystyle K_{\text{trans}}*\mu } can be obtained by heating up   {\displaystyle \mathbb {} ^{}} precisely according to  {\displaystyle \mu } , then wait for time   /  {\displaystyle \epsilon ^{}/} . With that, we can recover  {\displaystyle \mu } by running the heat equation backwards in time for   /  {\displaystyle \epsilon ^{}/} . More examples of invertible data augmentations are found in the paper. [ 51 ] SinGAN [ edit ] SinGAN pushes data augmentation to the limit, by using only  single image as training data and performing data augmentation on it. The GAN architecture is adapted to this training method by using  multi-scale pipeline. The generator  {\displaystyle } is decomposed into  pyramid of generators  =   ∘   ∘ ⋯ ∘   {\displaystyle =G_{}\circ G_{}\circ \cdots \circ G_{}} , with the lowest one generating the image   (   ) {\displaystyle G_{}(z_{})} at the lowest resolution, then the generated image is scaled up to  (   (   ) ) {\displaystyle (G_{}(z_{}))} , and fed to the next level to generate an image   −  (   −  +  (   (   ) ) ) {\displaystyle G_{-}(z_{-}+(G_{}(z_{})))} at  higher resolution, and so on. The discriminator is decomposed into  pyramid as well. [ 52 ] StyleGAN series [ edit ] Main article: StyleGAN The StyleGAN family is  series of architectures published by Nvidia ' research division. Progressive GAN [ edit ] Progressive GAN [ 16 ] is  method for training GAN for large-scale image generation stably, by growing  GAN generator from small to large scale in  pyramidal fashion. Like SinGAN, it decomposes the generator as  =   ∘   ∘ ⋯ ∘   {\displaystyle =G_{}\circ G_{}\circ \cdots \circ G_{}} , and the discriminator as  =   ∘   ∘ ⋯ ∘   {\displaystyle =D_{}\circ D_{}\circ \cdots \circ D_{}} . During training, at first only   ,   {\displaystyle G_{},D_{}} are used in  GAN game to generate 4x4 images. Then   −  ,   −  {\displaystyle G_{-},D_{-}} are added to reach the second stage of GAN game, to generate 8x8 images, and so on, until we reach  GAN game to generate 1024x1024 images. To avoid shock between stages of the GAN game, each new layer is "blended in" (Figure  of the paper [ 16 ] ). For example, this is how the second stage GAN game starts: Just before, the GAN game consists of the pair   ,   {\displaystyle G_{},D_{}} generating and discriminating 4x4 images. Just after, the GAN game consists of the pair ( (  −  ) +  ⋅   −  ) ∘  ∘   ,   ∘  ∘ ( (  −  ) +  ⋅   −  ) {\displaystyle ((-\alpha )+\alpha \cdot G_{-})\circ \circ G_{},D_{}\circ \circ ((-\alpha )+\alpha \cdot D_{-})} generating and discriminating 8x8 images. Here, the functions  ,  {\displaystyle ,} are image up- and down-sampling functions, and  {\displaystyle \alpha } is  blend-in factor (much like an alpha in image composing) that smoothly glides from  to . StyleGAN- [ edit ] The main architecture of StyleGAN- and StyleGAN- StyleGAN- is designed as  combination of Progressive GAN with neural style transfer . [ 53 ] The key architectural choice of StyleGAN- is  progressive growth mechanism, similar to Progressive GAN. Each generated image starts as  constant  ×  × 512 {\displaystyle \times \times 512} array, and repeatedly passed through style blocks. Each style block applies  "style latent vector" via affine transform ("adaptive instance normalization"), similar to how neural style transfer uses Gramian matrix . It then adds noise, and normalize (subtract the mean, then divide by the variance). At training time, usually only one style latent vector is used per image generated, but sometimes two ("mixing regularization") in order to encourage each style block to independently perform its stylization without expecting help from other style blocks (since they might receive an entirely different style latent vector). After training, multiple style latent vectors can be fed into each style block. Those fed to the lower layers control the large-scale styles, and those fed to the higher layers control the fine-detail styles. Style-mixing between two images  ,  ′ {\displaystyle ,'} can be performed as well. First, run  gradient descent to find  ,  ′ {\displaystyle ,'} such that  (  ) ≈  ,  (  ′ ) ≈  ′ {\displaystyle ()\approx ,(')\approx '} . This is called "projecting an image back to style latent space". Then,  {\displaystyle } can be fed to the lower style blocks, and  ′ {\displaystyle '} to the higher style blocks, to generate  composite image that has the large-scale style of  {\displaystyle } , and the fine-detail style of  ′ {\displaystyle '} . Multiple images can also be composed this way. StyleGAN- [ edit ] StyleGAN- improves upon StyleGAN-, by using the style latent vector to transform the convolution layer' weights instead, thus solving the "blob" problem. [ 54 ] This was updated by the StyleGAN--ADA ("ADA" stands for "adaptive"), [ 51 ] which uses invertible data augmentation as described above. It also tunes the amount of data augmentation applied by starting at zero, and gradually increasing it until an "overfitting heuristic" reaches  target level, thus the name "adaptive". StyleGAN- [ edit ] StyleGAN- [ 55 ] improves upon StyleGAN- by solving the "texture sticking" problem, which can be seen in the official videos. [ 56 ] They analyzed the problem by the Nyquist–Shannon sampling theorem , and argued that the layers in the generator learned to exploit the high-frequency signal in the pixels they operate upon. To solve this, they proposed imposing strict lowpass filters between each generator' layers, so that the generator is forced to operate on the pixels in  way faithful to the continuous signals they represent, rather than operate on them as merely discrete signals. They further imposed rotational and translational invariance by using more signal filters . The resulting StyleGAN- is able to solve the texture sticking problem, as well as generating images that rotate and translate smoothly. Applications [ edit ] GAN applications have increased rapidly. [ 57 ] Transfer learning [ edit ] State-of-art transfer learning research use GANs to enforce the alignment of the latent feature space, such as in deep reinforcement learning. [ 58 ] This works by feeding the embeddings of the source and target task to the discriminator which tries to guess the context. The resulting loss is then (inversely) backpropagated through the encoder. Commercial [ edit ] GANs that produce photorealistic images can be used to visualize interior design , industrial design , shoes, [ 59 ] bags, and clothing items or items for computer games ' scenes. [ citation needed ] Such networks were reported to be used by Facebook . [ 60 ] Fashion, art and advertising [ edit ] GANs can be used to generate art; The Verge wrote in March 2019 that "The images created by GANs have become the defining look of contemporary AI art." [ 61 ] GANs can also be used to inpaint photographs [ 62 ] or create photos of imaginary fashion models, with no need to hire  model, photographer or makeup artist, or pay for  studio and transportation. [ 63 ] GANs have also been used for virtual shadow generation. [ 64 ] In 2018, GANs reached the video game modding community, as  method of up-scaling low-resolution 2D textures in old video games by recreating them in 4k or higher resolutions via image training, and then down-sampling them to fit the game' native resolution (with results resembling the supersampling method of anti-aliasing ). [ 65 ] With proper training, GANs provide  clearer and sharper 2D texture image magnitudes higher in quality than the original, while fully retaining the original' level of details, colors, etc. Known examples of extensive GAN usage include Final Fantasy VIII , Final Fantasy IX , Resident Evil REmake HD Remaster, and Max Payne . [ citation needed ] In 2020, Artbreeder was used to create the main antagonist in the sequel to the psychological web horror series Ben Drowned . The author would later go on to praise GAN applications for their ability to help generate assets for independent artists who are short on budget and manpower. [ 66 ] [ 67 ] In May 2020, Nvidia researchers taught an AI system (termed "GameGAN") to recreate the game of Pac-Man simply by watching it being played. [ 68 ] [ 69 ] Science [ edit ] GANs can improve astronomical images [ 70 ] and simulate gravitational lensing for dark matter research. [ 71 ] [ 72 ] [ 73 ] They were used in 2019 to successfully model the distribution of dark matter in  particular direction in space and to predict the gravitational lensing that will occur. [ 74 ] [ 75 ] GANs have been proposed as  fast and accurate way of modeling high energy jet formation [ 76 ] and modeling showers through calorimeters of high-energy physics experiments. [ 77 ] [ 78 ] [ 79 ] [ 80 ] GANs have also been trained to accurately approximate bottlenecks in computationally expensive simulations of particle physics experiments. Applications in the context of present and proposed CERN experiments have demonstrated the potential of these methods for accelerating simulation and/or improving simulation fidelity. [ 81 ] [ 82 ] In 2016 GANs were used to generate new molecules for  variety of protein targets implicated in cancer, inflammation, and fibrosis. In 2019 GAN-generated molecules were validated experimentally all the way into mice. [ 83 ] [ 84 ] Moreover, GANs have gained significant attention for their potential in reconstructing velocity and scalar fields in turbulent flows. [ 85 ] [ 86 ] [ 87 ] Medical [ edit ] One of the major concerns in medical imaging is preserving patient privacy. Due to these reasons, researchers often face difficulties in obtaining medical images for their research purposes. Recently, GANs have been widely used for generating synthetic medical images, such as MRI and PET images, to address this challenge. [ 88 ] GAN can be used to detect glaucomatous images helping the early diagnosis which is essential to avoid partial or total loss of vision. [ 89 ] GANs have been used to create forensic facial reconstructions of deceased historical figures. [ 90 ] Audio [ edit ] In August 2019,  large dataset consisting of 12,197 MIDI songs each with paired lyrics and melody alignment was created for neural melody generation from lyrics using conditional GAN-LSTM (refer to sources at GitHub AI Melody Generation from Lyrics ). [ 91 ] Concerns about malicious applications [ edit ] Main article: Deepfake An image generated by  StyleGAN that looks deceptively like  photograph of  real person. This image was generated by  StyleGAN based on an analysis of portraits. Another example of  GAN generated portrait Concerns have been raised about the potential use of GAN-based human image synthesis for sinister purposes, .., to produce fake, possibly incriminating, photographs and videos. [ 92 ] GANs can be used to generate unique, realistic profile photos of people who do not exist, in order to automate creation of fake social media profiles. [ 93 ] In 2019 the state of California considered [ 94 ] and passed on October , 2019, the bill AB-602 , which bans the use of human image synthesis technologies to make fake pornography without the consent of the people depicted, and bill AB-730 , which prohibits distribution of manipulated videos of  political candidate within 60 days of an election. Both bills were authored by Assembly member Marc Berman and signed by Governor Gavin Newsom . The laws went into effect in 2020. [ 95 ] DARPA' Media Forensics program studies ways to counteract fake media, including fake media produced using GANs. [ 96 ] Miscellaneous applications [ edit ] GANs have been used to show how an individual' appearance might change with age. [ 97 ] reconstruct 3D models of objects from images , [ 98 ] generate novel objects as 3D point clouds, [ 99 ] model patterns of motion in video. [ 100 ] inpaint missing features in maps, transfer map styles in cartography [ 101 ] or augment street view imagery. [ 102 ] use feedback to generate images and replace image search systems. [ 103 ] visualize the effect that climate change will have on specific houses. [ 104 ] reconstruct an image of  person' face after listening to their voice. [ 105 ] produces videos of  person speaking, given only  single photo of that person. [ 106 ] recurrent sequence generation. [ 107 ] History [ edit ] In 1991, Juergen Schmidhuber published "artificial curiosity", neural networks in  zero-sum game . [ 108 ] The first network is  generative model that models  probability distribution over output patterns. The second network learns by gradient descent to predict the reactions of the environment to these patterns. GANs can be regarded as  case where the environmental reaction is  or  depending on whether the first network' output is in  given set. [ 109 ] Other people had similar ideas but did not develop them similarly. An idea involving adversarial networks was published in  2010 blog post by Olli Niemitalo. [ 110 ] This idea was never implemented and did not involve stochasticity in the generator and thus was not  generative model. It is now known as  conditional GAN or cGAN. [ 111 ] An idea similar to GANs was used to model animal behavior by Li, Gauci and Gross in 2013. [ 112 ] Another inspiration for GANs was noise-contrastive estimation, [ 113 ] which uses the same loss function as GANs and which Goodfellow studied during his PhD in 2010–2014. Adversarial machine learning has other uses besides generative modeling and can be applied to models other than neural networks. In control theory, adversarial learning based on neural networks was used in 2006 to train robust controllers in  game theoretic sense, by alternating the iterations between  minimizer policy, the controller, and  maximizer policy, the disturbance. [ 114 ] [ 115 ] In 2017,  GAN was used for image enhancement focusing on realistic textures rather than pixel-accuracy, producing  higher image quality at high magnification. [ 116 ] In 2017, the first faces were generated. [ 117 ] These were exhibited in February 2018 at the Grand Palais. [ 118 ] [ 119 ] Faces generated by StyleGAN [ 120 ] in 2019 drew comparisons with Deepfakes . [ 121 ] [ 122 ] [ 123 ] Beginning in 2017, GAN technology began to make its presence felt in the fine arts arena with the appearance of  newly developed implementation which was said to have crossed the threshold of being able to generate unique and appealing abstract paintings, and thus dubbed  "CAN", for "creative adversarial network". [ 124 ]  GAN system was used to create the 2018 painting Edmond de Belamy , which sold for US$432,500. [ 125 ] An early 2019 article by members of the original CAN team discussed further progress with that system, and gave consideration as well to the overall prospects for an AI-enabled art. [ 126 ] References [ edit ] ^ "Generative AI and Future" . November 15, 2022. ^ "CSDL | IEEE Computer Society" . ^           Goodfellow, Ian; Pouget-Abadie, Jean; Mirza, Mehdi; Xu, Bing; Warde-Farley, David; Ozair, Sherjil; Courville, Aaron; Bengio, Yoshua (2014). Generative Adversarial Nets (PDF) . Proceedings of the International Conference on Neural Information Processing Systems (NIPS 2014). pp. 2672–2680. ^ Salimans, Tim; Goodfellow, Ian; Zaremba, Wojciech; Cheung, Vicki; Radford, Alec; Chen, Xi (2016). "Improved Techniques for Training GANs". arXiv : 1606.03498 [ cs.LG ]. ^ Isola, Phillip; Zhu, Jun-Yan; Zhou, Tinghui; Efros, Alexei (2017). "Image-to-Image Translation with Conditional Adversarial Nets" . Computer Vision and Pattern Recognition . ^ Ho, Jonathon; Ermon, Stefano (2016). "Generative Adversarial Imitation Learning" . Advances in Neural Information Processing Systems . 29 : 4565–4573. arXiv : 1606.03476 . ^ "Vanilla GAN (GANs in computer vision: Introduction to generative learning)" . theaisummer.com . AI Summer. April 10, 2020. Archived from the original on June , 2020 . Retrieved September 20, 2020 . ^ Luc, Pauline; Couprie, Camille; Chintala, Soumith; Verbeek, Jakob (November 25, 2016). "Semantic Segmentation using Adversarial Networks". NIPS Workshop on Adversarial Training, Dec, Barcelona, Spain . 2016 . arXiv : 1611.08408 . ^ Andrej Karpathy ; Pieter Abbeel ; Greg Brockman; Peter Chen; Vicki Cheung; Rocky Duan; Ian Goodfellow; Durk Kingma; Jonathan Ho; Rein Houthooft; Tim Salimans; John Schulman; Ilya Sutskever; Wojciech Zaremba, Generative Models , OpenAI , retrieved April , 2016 ^ Mohamed, Shakir; Lakshminarayanan, Balaji (2016). "Learning in Implicit Generative Models". arXiv : 1610.03483 [ stat.ML ]. ^   Goodfellow, Ian (April , 2017). "NIPS 2016 Tutorial: Generative Adversarial Networks". arXiv : 1701.00160 [ cs.LG ]. ^ Kingma, Diederik .; Welling, Max (May , 2014). "Auto-Encoding Variational Bayes". arXiv : 1312.6114 [ stat.ML ]. ^ Rezende, Danilo Jimenez; Mohamed, Shakir; Wierstra, Daan (June 18, 2014). "Stochastic Backpropagation and Approximate Inference in Deep Generative Models" . International Conference on Machine Learning . PMLR: 1278–1286. arXiv : 1401.4082 . ^   Farnia, Farzan; Ozdaglar, Asuman (November 21, 2020). "Do GANs always have Nash equilibria?" . International Conference on Machine Learning . PMLR: 3029–3039. ^    Weng, Lilian (April 18, 2019). "From GAN to WGAN". arXiv : 1904.08994 [ cs.LG ]. ^    Karras, Tero; Aila, Timo; Laine, Samuli; Lehtinen, Jaakko (October , 2017). "Progressive Growing of GANs for Improved Quality, Stability, and Variation". arXiv : 1710.10196 [ cs.NE ]. ^ Soviany, Petru; Ardei, Claudiu; Ionescu, Radu Tudor; Leordeanu, Marius (October 22, 2019). "Image Difficulty Curriculum for Generative Adversarial Networks (CuGAN)". arXiv : 1910.08967 [ cs.LG ]. ^ Hacohen, Guy; Weinshall, Daphna (May 24, 2019). "On The Power of Curriculum Learning in Training Deep Networks" . International Conference on Machine Learning . PMLR: 2535–2544. arXiv : 1904.03626 . ^ "/MachineLearning - Comment by /ian_goodfellow on "[] [1701.07875] Wasserstein GAN" . reddit . January 30, 2017 . Retrieved July 15, 2022 . ^ Lin, Zinan; et al. (December 2018). PacGAN: the power of two samples in generative adversarial networks . 32nd International Conference on Neural Information Processing Systems. pp. 1505–1514. arXiv : 1712.04086 . ^ Mescheder, Lars; Geiger, Andreas; Nowozin, Sebastian (July 31, 2018). "Which Training Methods for GANs do actually Converge?". arXiv : 1801.04406 [ cs.LG ]. ^   Brock, Andrew; Donahue, Jeff; Simonyan, Karen (September , 2018). Large Scale GAN Training for High Fidelity Natural Image Synthesis . International Conference on Learning Representations 2019. arXiv : 1809.11096 . ^ Heusel, Martin; Ramsauer, Hubert; Unterthiner, Thomas; Nessler, Bernhard; Hochreiter, Sepp (2017). "GANs Trained by  Two Time-Scale Update Rule Converge to  Local Nash Equilibrium" . Advances in Neural Information Processing Systems . 30 . Curran Associates, Inc. arXiv : 1706.08500 . ^ Kingma, Diederik .; Ba, Jimmy (January 29, 2017). "Adam:  Method for Stochastic Optimization". arXiv : 1412.6980 [ cs.LG ]. ^ Zhang, Richard; Isola, Phillip; Efros, Alexei .; Shechtman, Eli; Wang, Oliver (2018). "The Unreasonable Effectiveness of Deep Features as  Perceptual Metric". pp. 586–595. arXiv : 1801.03924 [ cs.CV ]. ^ Borji, Ali (February , 2019). "Pros and cons of GAN evaluation measures" . Computer Vision and Image Understanding . 179 : 41–65. arXiv : 1802.03446 . doi : 10.1016/.cviu.2018.10.009 . ISSN 1077-3142 . S2CID 3627712 . ^ Hindupur, Avinash (July 15, 2022), The GAN Zoo , retrieved July 15, 2022 ^ Odena, Augustus; Olah, Christopher; Shlens, Jonathon (July 17, 2017). "Conditional Image Synthesis with Auxiliary Classifier GANs" . International Conference on Machine Learning . PMLR: 2642–2651. arXiv : 1610.09585 . ^ Radford, Alec; Metz, Luke; Chintala, Soumith (2016). "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks". ICLR . S2CID 11758569 . ^ Long, Jonathan; Shelhamer, Evan; Darrell, Trevor (2015). "Fully Convolutional Networks for Semantic Segmentation" . CVF : 3431–3440. ^ Zhang, Han; Goodfellow, Ian; Metaxas, Dimitris; Odena, Augustus (May 24, 2019). "Self-Attention Generative Adversarial Networks" . International Conference on Machine Learning . PMLR: 7354–7363. ^ Larsen, Anders Boesen Lindbo; Sønderby, Søren Kaae; Larochelle, Hugo; Winther, Ole (June 11, 2016). "Autoencoding beyond pixels using  learned similarity metric" . International Conference on Machine Learning . PMLR: 1558–1566. arXiv : 1512.09300 . ^ Jiang, Yifan; Chang, Shiyu; Wang, Zhangyang (December , 2021). "TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up". arXiv : 2102.07074 [ cs.CV ]. ^ Grover, Aditya; Dhar, Manik; Ermon, Stefano (May , 2017). "Flow-GAN: Combining Maximum Likelihood and Adversarial Learning in Generative Models". arXiv : 1705.08868 [ cs.LG ]. ^ Arjovsky, Martin; Bottou, Léon (January , 2017). "Towards Principled Methods for Training Generative Adversarial Networks". arXiv : 1701.04862 [ stat.ML ]. ^ Goodfellow, Ian . (December , 2014). "On distinguishability criteria for estimating generative models". arXiv : 1412.6515 [ stat.ML ]. ^ Goodfellow, Ian (August 31, 2016). "Generative Adversarial Networks (GANs), Presentation at Berkeley Artificial Intelligence Lab" (PDF) . Archived (PDF) from the original on May , 2022. ^ Lim, Jae Hyun; Ye, Jong Chul (May , 2017). "Geometric GAN". arXiv : 1705.02894 [ stat.ML ]. ^ Mao, Xudong; Li, Qing; Xie, Haoran; Lau, Raymond . .; Wang, Zhen; Paul Smolley, Stephen (2017). "Least Squares Generative Adversarial Networks" : 2794–2802. {{ cite journal }} : Cite journal requires |journal= ( help ) ^ Makhzani, Alireza; Shlens, Jonathon; Jaitly, Navdeep; Goodfellow, Ian ; Frey, Brendan (2016). "Adversarial Autoencoders". arXiv : 1511.05644 [ cs.LG ]. ^ Barber, David; Agakov, Felix (December , 2003). "The IM algorithm:  variational approach to Information Maximization" . Proceedings of the 16th International Conference on Neural Information Processing Systems . NIPS'03. Cambridge, MA, USA: MIT Press: 201–208. ^ Chen, Xi; Duan, Yan; Houthooft, Rein; Schulman, John; Sutskever, Ilya; Abbeel, Pieter (2016). "InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets" . Advances in Neural Information Processing Systems . 29 . Curran Associates, Inc. arXiv : 1606.03657 . ^ Donahue, Jeff; Krähenbühl, Philipp; Darrell, Trevor (2016). "Adversarial Feature Learning". arXiv : 1605.09782 [ cs.LG ]. ^ Dumoulin, Vincent; Belghazi, Ishmael; Poole, Ben; Mastropietro, Olivier; Arjovsky, Alex; Courville, Aaron (2016). "Adversarially Learned Inference". arXiv : 1606.00704 [ stat.ML ]. ^ Xi Chen; Yan Duan; Rein Houthooft; John Schulman; Ilya Sutskever ; Pieter Abeel (2016). "InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets". arXiv : 1606.03657 [ cs.LG ]. ^ Zhirui Zhang; Shujie Liu; Mu Li; Ming Zhou; Enhong Chen (October 2018). "Bidirectional Generative Adversarial Networks for Neural Machine Translation" (PDF) . pp. 190–199. ^ Zhu, Jun-Yan; Park, Taesung; Isola, Phillip; Efros, Alexei . (2017). "Unpaired Image-To-Image Translation Using Cycle-Consistent Adversarial Networks". pp. 2223–2232. arXiv : 1703.10593 [ cs.CV ]. ^ Isola, Phillip; Zhu, Jun-Yan; Zhou, Tinghui; Efros, Alexei . (2017). "Image-To-Image Translation With Conditional Adversarial Networks". pp. 1125–1134. arXiv : 1611.07004 [ cs.CV ]. ^ Brownlee, Jason (August 22, 2019). " Gentle Introduction to BigGAN the Big Generative Adversarial Network" . Machine Learning Mastery . Retrieved July 15, 2022 . ^ Shengyu, Zhao; Zhijian, Liu; Ji, Lin; Jun-Yan, Zhu; Song, Han (2020). "Differentiable Augmentation for Data-Efficient GAN Training" . Advances in Neural Information Processing Systems . 33 . arXiv : 2006.10738 . ^    Tero, Karras; Miika, Aittala; Janne, Hellsten; Samuli, Laine; Jaakko, Lehtinen; Timo, Aila (2020). "Training Generative Adversarial Networks with Limited Data" . Advances in Neural Information Processing Systems . 33 . ^ Shaham, Tamar Rott; Dekel, Tali; Michaeli, Tomer (October 2019). "SinGAN: Learning  Generative Model from  Single Natural Image" . 2019 IEEE/CVF International Conference on Computer Vision (ICCV) . IEEE. pp. 4569–4579. arXiv : 1905.01164 . doi : 10.1109/iccv.2019.00467 . ISBN 978--7281-4803- . S2CID 145052179 . ^ Karras, Tero; Laine, Samuli; Aila, Timo (June 2019). " Style-Based Generator Architecture for Generative Adversarial Networks" . 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) . IEEE. pp. 4396–4405. arXiv : 1812.04948 . doi : 10.1109/cvpr.2019.00453 . ISBN 978--7281-3293- . S2CID 54482423 . ^ Karras, Tero; Laine, Samuli; Aittala, Miika; Hellsten, Janne; Lehtinen, Jaakko; Aila, Timo (June 2020). "Analyzing and Improving the Image Quality of StyleGAN" . 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) . IEEE. pp. 8107–8116. arXiv : 1912.04958 . doi : 10.1109/cvpr42600.2020.00813 . ISBN 978--7281-7168- . S2CID 209202273 . ^ Timo, Karras, Tero Aittala, Miika Laine, Samuli Härkönen, Erik Hellsten, Janne Lehtinen, Jaakko Aila (June 23, 2021). Alias-Free Generative Adversarial Networks . OCLC 1269560084 . {{ cite book }} : CS1 maint: multiple names: authors list ( link ) ^ Karras, Tero; Aittala, Miika; Laine, Samuli; Härkönen, Erik; Hellsten, Janne; Lehtinen, Jaakko; Aila, Timo. "Alias-Free Generative Adversarial Networks (StyleGAN3)" . nvlabs.github.io . Retrieved July 16, 2022 . ^ Caesar, Holger (March , 2019),  list of papers on Generative Adversarial (Neural) Networks: nightrome/really-awesome-gan , retrieved March , 2019 ^ Li, Bonnie; François-Lavet, Vincent; Doan, Thang; Pineau, Joelle (February 14, 2021). "Domain Adversarial Reinforcement Learning". arXiv : 2102.07097 [ cs.LG ]. ^ Wei, Jerry (July , 2019). "Generating Shoe Designs with Machine Learning" . Medium . Retrieved November , 2019 . ^ Greenemeier, Larry (June 20, 2016). "When Will Computers Have Common Sense? Ask Facebook" . Scientific American . Retrieved July 31, 2016 . ^ Vincent, James (March , 2019). " never-ending stream of AI art goes up for auction" . The Verge . Retrieved June 13, 2020 . ^ Yu, Jiahui, et al. " Generative image inpainting with contextual attention ." Proceedings of the IEEE conference on computer vision and pattern recognition. 2018. ^ Wong, Ceecee (May 27, 2019). "The Rise of AI Supermodels" . CDO Trends . ^ Taif, .; Ugail, .; Mehmood, . (2020). "Cast Shadow Generation Using Generative Adversarial Networks". Computational Science – ICCS 2020 . Lecture Notes in Computer Science. Vol. 12141. pp. 481–495. doi : 10.1007/978--030-50426-7_36 . ISBN 978--030-50425- . PMC 7302543 . ^ Tang, Xiaoou; Qiao, Yu; Loy, Chen Change; Dong, Chao; Liu, Yihao; Gu, Jinjin; Wu, Shixiang; Yu, Ke; Wang, Xintao (September , 2018). "ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks". arXiv : 1809.00219 . Bibcode : 2018arXiv180900219W . ^ Allen, Eric Van (July , 2020). "An Infamous Zelda Creepypasta Saga Is Using Artificial Intelligence to Craft Its Finale" . USgamer . Archived from the original on November , 2022 . Retrieved November , 2022 . ^ arcadeattack (September 28, 2020). "Arcade Attack Podcast – September ( of ) 2020 - Alex Hall (Ben Drowned) - Interview" . Arcade Attack . Retrieved November , 2022 . ^ "Nvidia' AI recreates Pac-Man from scratch just by watching it being played" . The Verge . May 22, 2020. ^ Seung Wook Kim; Zhou, Yuhao; Philion, Jonah; Torralba, Antonio; Fidler, Sanja (2020). "Learning to Simulate Dynamic Environments with GameGAN". arXiv : 2005.12126 [ cs.CV ]. ^ Schawinski, Kevin; Zhang, Ce; Zhang, Hantian; Fowler, Lucas; Santhanam, Gokula Krishnan (February , 2017). "Generative Adversarial Networks recover features in astrophysical images of galaxies beyond the deconvolution limit" . Monthly Notices of the Royal Astronomical Society: Letters . 467 (): L110–L114. arXiv : 1702.00403 . Bibcode : 2017MNRAS.467L.110S . doi : 10.1093/mnrasl/slx008 . S2CID 7213940 . ^ Kincade, Kathy. "Researchers Train  Neural Network to Study Dark Matter" . & Magazine. ^ Kincade, Kathy (May 16, 2019). "CosmoGAN: Training  neural network to study dark matter" . Phys.org . ^ "Training  neural network to study dark matter" . Science Daily . May 16, 2019. ^ at 06:13, Katyanna Quach 20 May 2019. "Cosmoboffins use neural networks to build dark matter maps the easy way" . www.theregister.co.uk . Retrieved May 20, 2019 . {{ cite web }} : CS1 maint: numeric names: authors list ( link ) ^ Mustafa, Mustafa; Bard, Deborah; Bhimji, Wahid; Lukić, Zarija; Al-Rfou, Rami; Kratochvil, Jan . (May , 2019). "CosmoGAN: creating high-fidelity weak lensing convergence maps using Generative Adversarial Networks" . Computational Astrophysics and Cosmology .  (): . arXiv : 1706.02390 . Bibcode : 2019ComAC.......1M . doi : 10.1186/s40668-019-0029- . ISSN 2197-7909 . S2CID 126034204 . ^ Paganini, Michela; de Oliveira, Luke; Nachman, Benjamin (2017). "Learning Particle Physics by Example: Location-Aware Generative Adversarial Networks for Physics Synthesis". Computing and Software for Big Science .  : . arXiv : 1701.05927 . Bibcode : 2017arXiv170105927D . doi : 10.1007/s41781-017-0004- . S2CID 88514467 . ^ Paganini, Michela; de Oliveira, Luke; Nachman, Benjamin (2018). "Accelerating Science with Generative Adversarial Networks: An Application to 3D Particle Showers in Multi-Layer Calorimeters". Physical Review Letters . 120 (): 042003. arXiv : 1705.02355 . Bibcode : 2018PhRvL.120d2003P . doi : 10.1103/PhysRevLett.120.042003 . PMID 29437460 . S2CID 3330974 . ^ Paganini, Michela; de Oliveira, Luke; Nachman, Benjamin (2018). "CaloGAN: Simulating 3D High Energy Particle Showers in Multi-Layer Electromagnetic Calorimeters with Generative Adversarial Networks". Phys. Rev.  . 97 (): 014021. arXiv : 1712.10321 . Bibcode : 2018PhRvD..97a4021P . doi : 10.1103/PhysRevD.97.014021 . S2CID 41265836 . ^ Erdmann, Martin; Glombitza, Jonas; Quast, Thorben (2019). "Precise Simulation of Electromagnetic Calorimeter Showers Using  Wasserstein Generative Adversarial Network". Computing and Software for Big Science .  : . arXiv : 1807.01954 . doi : 10.1007/s41781-018-0019- . S2CID 54216502 . ^ Musella, Pasquale; Pandolfi, Francesco (2018). "Fast and Accurate Simulation of Particle Detectors Using Generative Adversarial Networks". Computing and Software for Big Science .  : . arXiv : 1805.00850 . Bibcode : 2018arXiv180500850M . doi : 10.1007/s41781-018-0015- . S2CID 119474793 . ^ "Deep generative models for fast shower simulation in ATLAS" . 2018. ^ SHiP, Collaboration (2019). "Fast simulation of muons produced at the SHiP experiment using Generative Adversarial Networks". Journal of Instrumentation . 14 (11): 11028. arXiv : 1909.04451 . Bibcode : 2019JInst..14P1028A . doi : 10.1088/1748-0221/14/11/P11028 . S2CID 202542604 . ^ Zhavoronkov, Alex (2019). "Deep learning enables rapid identification of potent DDR1 kinase inhibitors". Nature Biotechnology . 37 (): 1038–1040. doi : 10.1038/s41587-019-0224- . PMID 31477924 . S2CID 201716327 . ^ Barber, Gregory. " Molecule Designed By AI Exhibits "Druglike" Qualities" . Wired . ^ Nista, Ludovico; Pitsch, Heinz; Schumann, Christoph . .; Bode, Mathis; Grenga, Temistocle; MacArt, Jonathan .; Attili, Antonio (June , 2024). "Influence of adversarial training on super-resolution turbulence reconstruction" . Physical Review Fluids .  (): 064601. arXiv : 2308.16015 . doi : 10.1103/PhysRevFluids..064601 . ^ Nista, .; Schumann, . . .; Grenga, .; Attili, .; Pitsch, . (January , 2023). "Investigation of the generalization capability of  generative adversarial network for large eddy simulation of turbulent premixed reacting flows" . Proceedings of the Combustion Institute . 39 (): 5279–5288. doi : 10.1016/.proci.2022.07.244 . ISSN 1540-7489 . ^ Fukami, Kai; Fukagata, Koji; Taira, Kunihiko (August , 2020). "Assessment of supervised machine learning methods for fluid flows" . Theoretical and Computational Fluid Dynamics . 34 (): 497–519. doi : 10.1007/s00162-020-00518- . ISSN 1432-2250 . ^ Moradi, ; Demirel,  (2024). "Alzheimer' disease classification using 3D conditional progressive GAN-and LDA-based data selection". Signal, Image and Video Processing . 18 (): 1847–1861. doi : 10.1007/s11760-023-02878- . ^ Bisneto, Tomaz Ribeiro Viana; de Carvalho Filho, Antonio Oseas; Magalhães, Deborah Maria Vieira (February 2020). "Generative adversarial network and texture features applied to automatic glaucoma detection". Applied Soft Computing . 90 : 106165. doi : 10.1016/.asoc.2020.106165 . S2CID 214571484 . ^ Reconstruction of the Roman Emperors: Interview with Daniel Voshart , November 16, 2020 , retrieved June , 2022 ^ Yu, Yi; Canales, Simon (2021). "Conditional LSTM-GAN for Melody Generation from Lyrics". ACM Transactions on Multimedia Computing, Communications, and Applications . 17 : –20. arXiv : 1908.05551 . doi : 10.1145/3424116 . ISSN 1551-6857 . S2CID 199668828 . ^ msmash (February 14, 2019). " 'This Person Does Not Exist' Website Uses AI To Create Realistic Yet Horrifying Faces" . Slashdot . Retrieved February 16, 2019 . ^ Doyle, Michael (May 16, 2019). "John Beasley lives on Saddlehorse Drive in Evansville. Or does he?" . Courier and Press. ^ Targett, Ed (May 16, 2019). "California moves closer to making deepfake pornography illegal". Computer Business Review. ^ Mihalcik, Carrie (October , 2019). "California laws seek to crack down on deepfakes in politics and porn" . cnet.com . CNET . Retrieved October 13, 2019 . ^ Knight, Will (August , 2018). "The Defense Department has produced the first tools for catching deepfakes" . MIT Technology Review . ^ Antipov, Grigory; Baccouche, Moez; Dugelay, Jean-Luc (2017). "Face Aging With Conditional Generative Adversarial Networks". arXiv : 1702.01983 [ cs.CV ]. ^ "3D Generative Adversarial Network" . 3dgan.csail.mit.edu . ^ Achlioptas, Panos; Diamanti, Olga; Mitliagkas, Ioannis; Guibas, Leonidas (2018). "Learning Representations and Generative Models for 3D Point Clouds". arXiv : 1707.02392 [ cs.CV ]. ^ Vondrick, Carl; Pirsiavash, Hamed; Torralba, Antonio (2016). "Generating Videos with Scene Dynamics" . carlvondrick.com . arXiv : 1609.02612 . Bibcode : 2016arXiv160902612V . ^ Kang, Yuhao; Gao, Song; Roth, Rob (2019). "Transferring Multiscale Map Styles Using Generative Adversarial Networks" . International Journal of Cartography .  (–): 115–141. arXiv : 1905.02200 . Bibcode : 2019IJCar.....115K . doi : 10.1080/23729333.2019.1615729 . S2CID 146808465 . ^ Wijnands, Jasper; Nice, Kerry; Thompson, Jason; Zhao, Haifeng; Stevenson, Mark (2019). "Streetscape augmentation using generative adversarial networks: Insights related to health and wellbeing". Sustainable Cities and Society . 49 : 101602. arXiv : 1905.06464 . Bibcode : 2019SusCS..4901602W . doi : 10.1016/.scs.2019.101602 . S2CID 155100183 . ^ Ukkonen, Antti; Joona, Pyry; Ruotsalo, Tuukka (2020). "Generating Images Instead of Retrieving Them" . Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval . pp. 1329–1338. doi : 10.1145/3397271.3401129 . hdl : 10138/328471 . ISBN 9781450380164 . S2CID 220730163 . ^ "AI can show us the ravages of climate change" . MIT Technology Review . May 16, 2019. ^ Christian, Jon (May 28, 2019). "ASTOUNDING AI GUESSES WHAT YOU LOOK LIKE BASED ON YOUR VOICE" . Futurism. ^ Kulp, Patrick (May 23, 2019). "Samsung' AI Lab Can Create Fake Video Footage From  Single Headshot" . AdWeek . ^ Mohammad Navid Fekri; Ananda Mohon Ghosh; Katarina Grolinger (2020). "Generating Energy Data for Machine Learning with Recurrent Generative Adversarial Networks" . Energies . 13 (): 130. doi : 10.3390/en13010130 . ^ Schmidhuber, Jürgen (1991). " possibility for implementing curiosity and boredom in model-building neural controllers". Proc. SAB'1991 . MIT Press/Bradford Books. pp. 222–227. ^ Schmidhuber, Jürgen (2020). "Generative Adversarial Networks are Special Cases of Artificial Curiosity (1990) and also Closely Related to Predictability Minimization (1991)". Neural Networks . 127 : 58–66. arXiv : 1906.04493 . doi : 10.1016/.neunet.2020.04.008 . PMID 32334341 . S2CID 216056336 . ^ Niemitalo, Olli (February 24, 2010). " method for training artificial neural networks to generate missing data within  variable context" . Internet Archive (Wayback Machine) . Archived from the original on March 12, 2012 . Retrieved February 22, 2019 . ^ "GANs were invented in 2010?" . reddit /MachineLearning . 2019 . Retrieved May 28, 2019 . ^ Li, Wei; Gauci, Melvin; Gross, Roderich (July , 2013). "Proceeding of the fifteenth annual conference on Genetic and evolutionary computation conference - GECCO '13". Proceedings of the 15th Annual Conference on Genetic and Evolutionary Computation (GECCO 2013) . Amsterdam, the Netherlands: ACM. pp. 223–230. doi : 10.1145/2463372.2465801 . ISBN 9781450319638 . ^ Gutmann, Michael; Hyvärinen, Aapo. "Noise-Contrastive Estimation" (PDF) . International Conference on AI and Statistics . ^ Abu-Khalaf, Murad; Lewis, Frank .; Huang, Jie (July , 2008). "Neurodynamic Programming and Zero-Sum Games for Constrained Control Systems". IEEE Transactions on Neural Networks . 19 (): 1243–1252. doi : 10.1109/TNN.2008.2000204 . S2CID 15680448 . ^ Abu-Khalaf, Murad; Lewis, Frank .; Huang, Jie (December , 2006). "Policy Iterations on the Hamilton–Jacobi–Isaacs Equation for  ∞ State Feedback Control With Input Saturation". IEEE Transactions on Automatic Control . doi : 10.1109/TAC.2006.884959 . S2CID 1338976 . ^ Sajjadi, Mehdi . .; Schölkopf, Bernhard; Hirsch, Michael (December 23, 2016). "EnhanceNet: Single Image Super-Resolution Through Automated Texture Synthesis". arXiv : 1612.07919 [ cs.CV ]. ^ "This Person Does Not Exist: Neither Will Anything Eventually with AI" . March 20, 2019. ^ "ARTificial Intelligence enters the History of Art" . December 28, 2018. ^ Tom Février (February 17, 2019). "Le scandale de 'intelligence ARTificielle" . ^ "StyleGAN: Official TensorFlow Implementation" . March , 2019 – via GitHub. ^ Paez, Danny (February 13, 2019). "This Person Does Not Exist Is the Best One-Off Website of 2019" . Retrieved February 16, 2019 . ^ Beschizza, Rob (February 15, 2019). "This Person Does Not Exist" . Boing-Boing . Retrieved February 16, 2019 . ^ Horev, Rani (December 26, 2018). "Style-based GANs – Generating and Tuning Realistic Artificial Faces" . Lyrn.AI . Archived from the original on November , 2020 . Retrieved February 16, 2019 . ^ Elgammal, Ahmed; Liu, Bingchen; Elhoseiny, Mohamed; Mazzone, Marian (2017). "CAN: Creative Adversarial Networks, Generating "Art" by Learning About Styles and Deviating from Style Norms". arXiv : 1706.07068 [ cs.AI ]. ^ Cohn, Gabe (October 25, 2018). "AI Art at Christie' Sells for $432,500" . The New York Times . ^ Mazzone, Marian; Ahmed Elgammal (February 21, 2019). "Art, Creativity, and the Potential of Artificial Intelligence" . Arts .  : 26. doi : 10.3390/arts8010026 . External links [ edit ] Art portal Knight, Will. " Big Predictions for Artificial Intelligence in 2017" . MIT Technology Review . Retrieved January , 2017 . Karras, Tero; Laine, Samuli; Aila, Timo (2018). " Style-Based Generator Architecture for Generative Adversarial Networks". arXiv : 1812.04948 [ cs.NE ]. This Person Does Not Exist – photorealistic images of people who do not exist, generated by StyleGAN This Cat Does Not Exist Archived March , 2019, at the Wayback Machine – photorealistic images of cats who do not exist, generated by StyleGAN Wang, Zhengwei; She, Qi; Ward, Tomas . (2019). "Generative Adversarial Networks in Computer Vision:  Survey and Taxonomy". arXiv : 1906.01529 [ cs.LG ].    Generative AI Concepts Autoencoder Deep learning Generative adversarial network Generative pre-trained transformer Large language model Neural network Prompt engineering RAG RLHF Self-supervised learning Transformer Variational autoencoder Vision transformer Word embedding Models Text Claude Gemini GPT- GPT- GPT- LLaMA Images DALL- Midjourney Stable Diffusion Videos Sora Musics Suno AI Udio Companies Anthropic Google DeepMind Hugging Face OpenAI Meta AI Mistral AI Category    Differentiable computing General Differentiable programming Information geometry Statistical manifold Automatic differentiation Neuromorphic engineering Pattern recognition Tensor calculus Computational learning theory Inductive bias Concepts Gradient descent SGD Clustering Regression Overfitting Hallucination Adversary Attention Convolution Loss functions Backpropagation Batchnorm Activation Softmax Sigmoid Rectifier Regularization Datasets Augmentation Diffusion Autoregression Applications Machine learning In-context learning Artificial neural network Deep learning Scientific computing Artificial Intelligence Language model Large language model Hardware IPU TPU VPU Memristor SpiNNaker Software libraries TensorFlow PyTorch Keras Theano JAX Flux.jl MindSpore Implementations Audio–visual AlexNet WaveNet Human image synthesis HWR OCR Speech synthesis Speech recognition Facial recognition AlphaFold Text-to-image models DALL- Midjourney Stable Diffusion Text-to-video models Sora VideoPoet Whisper Verbal Word2vec Seq2seq BERT Gemini LaMDA Bard NMT Project Debater IBM Watson IBM Watsonx Granite GPT- GPT- GPT- GPT- ChatGPT GPT- Chinchilla AI PaLM BLOOM LLaMA PanGu- Decisional AlphaGo AlphaZero -learning SARSA OpenAI Five Self-driving car MuZero Action selection Auto-GPT Robot control People Yoshua Bengio Alex Graves Ian Goodfellow Stephen Grossberg Demis Hassabis Geoffrey Hinton Yann LeCun Fei-Fei Li Andrew Ng Jürgen Schmidhuber David Silver Ilya Sutskever Organizations Anthropic EleutherAI Google DeepMind Hugging Face OpenAI Meta AI Mila MIT CSAIL Huawei Architectures Neural Turing machine Differentiable neural computer Transformer Recurrent neural network (RNN) Long short-term memory (LSTM) Gated recurrent unit (GRU) Echo state network Multilayer perceptron (MLP) Convolutional neural network Residual neural network Mamba Autoencoder Variational autoencoder (VAE) Generative adversarial network (GAN) Graph neural network Portals Computer programming Technology Categories Artificial neural networks Machine learning Retrieved from " https://en.wikipedia.org//index.php?title=Generative_adversarial_network&oldid=1241071646 " Categories : Neural network architectures Cognitive science Unsupervised learning Generative artificial intelligence Hidden categories: CS1 errors: missing periodical CS1 maint: multiple names: authors list CS1 maint: numeric names: authors list Articles with short description Short description is different from Wikidata Use mdy dates from April 2021 All articles with unsourced statements Articles with unsourced statements from February 2018 Articles with unsourced statements from January 2020 Webarchive template wayback links Read more ## Adversarial machine learning Toggle the table of contents Adversarial machine learning  languages العربية Čeština Ελληνικά Español فارسی 한국어 Italiano Português 粵語 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Special pages Permanent link Page information Cite this page Get shortened URL Download QR code Wikidata item Print/export Download as PDF Printable version In other projects Appearance move to sidebar hide From Wikipedia, the free encyclopedia Research field that lies at the intersection of machine learning and computer security Not to be confused with Generative adversarial network . Part of  series on Machine learning and data mining Paradigms Supervised learning Unsupervised learning Semi-supervised learning Self-supervised learning Reinforcement learning Meta-learning Online learning Batch learning Curriculum learning Rule-based learning Neuro-symbolic AI Neuromorphic engineering Quantum machine learning Problems Classification Generative modeling Regression Clustering Dimensionality reduction Density estimation Anomaly detection Data cleaning AutoML Association rules Semantic analysis Structured prediction Feature engineering Feature learning Learning to rank Grammar induction Ontology learning Multimodal learning Supervised learning ( classification • regression ) Apprenticeship learning Decision trees Ensembles Bagging Boosting Random forest  -NN Linear regression Naive Bayes Artificial neural networks Logistic regression Perceptron Relevance vector machine (RVM) Support vector machine (SVM) Clustering BIRCH CURE Hierarchical  -means Fuzzy Expectation–maximization (EM) DBSCAN OPTICS Mean shift Dimensionality reduction Factor analysis CCA ICA LDA NMF PCA PGD -SNE SDL Structured prediction Graphical models Bayes net Conditional random field Hidden Markov Anomaly detection RANSAC  -NN Local outlier factor Isolation forest Artificial neural network Autoencoder Deep learning Feedforward neural network Recurrent neural network LSTM GRU ESN reservoir computing Boltzmann machine Restricted GAN Diffusion model SOM Convolutional neural network -Net LeNet AlexNet DeepDream Neural radiance field Transformer Vision Mamba Spiking neural network Memtransistor Electrochemical RAM (ECRAM) Reinforcement learning -learning SARSA Temporal difference (TD) Multi-agent Self-play Learning with humans Active learning Crowdsourcing Human-in-the-loop RLHF Model diagnostics Coefficient of determination Confusion matrix Learning curve ROC curve Mathematical foundations Kernel machines Bias–variance tradeoff Computational learning theory Empirical risk minimization Occam learning PAC learning Statistical learning VC theory Journals and conferences ECML PKDD NeurIPS ICML ICLR IJCAI ML JMLR Related articles Glossary of artificial intelligence List of datasets for machine-learning research List of datasets in computer vision and image processing Outline of machine learning    Adversarial machine learning is the study of the attacks on machine learning algorithms, and of the defenses against such attacks. [  ]  survey from May 2020 exposes the fact that practitioners report  dire need for better protecting machine learning systems in industrial applications. [  ] Most machine learning techniques are mostly designed to work on specific problem sets, under the assumption that the training and test data are generated from the same statistical distribution ( IID ). However, this assumption is often dangerously violated in practical high-stake applications, where users may intentionally supply fabricated data that violates the statistical assumption. Most common attacks in adversarial machine learning include evasion attacks , [  ] data poisoning attacks , [  ] Byzantine attacks [  ] and model extraction. [  ] History [ edit ] At the MIT Spam Conference in January 2004, John Graham-Cumming showed that  machine-learning spam filter could be used to defeat another machine-learning spam filter by automatically learning which words to add to  spam email to get the email classified as not spam. [  ] In 2004, Nilesh Dalvi and others noted that linear classifiers used in spam filters could be defeated by simple " evasion attacks" as spammers inserted "good words" into their spam emails. (Around 2007, some spammers added random noise to fuzz words within "image spam" in order to defeat OCR -based filters.) In 2006, Marco Barreno and others published "Can Machine Learning Be Secure?", outlining  broad taxonomy of attacks. As late as 2013 many researchers continued to hope that non-linear classifiers (such as support vector machines and neural networks ) might be robust to adversaries, until Battista Biggio and others demonstrated the first gradient-based attacks on such machine-learning models (2012 [  ] –2013 [  ] ). In 2012, deep neural networks began to dominate computer vision problems; starting in 2014, Christian Szegedy and others demonstrated that deep neural networks could be fooled by adversaries, again using  gradient-based attack to craft adversarial perturbations. [ 10 ] [ 11 ] Recently, it was observed that adversarial attacks are harder to produce in the practical world due to the different environmental constraints that cancel out the effect of noise. [ 12 ] [ 13 ] For example, any small rotation or slight illumination on an adversarial image can destroy the adversariality. In addition, researchers such as Google Brain' Nicholas Frosst point out that it is much easier to make self-driving cars [ 14 ] miss stop signs by physically removing the sign itself, rather than creating adversarial examples. [ 15 ] Frosst also believes that the adversarial machine learning community incorrectly assumes models trained on  certain data distribution will also perform well on  completely different data distribution. He suggests that  new approach to machine learning should be explored, and is currently working on  unique neural network that has characteristics more similar to human perception than state-of-the-art approaches. [ 15 ] While adversarial machine learning continues to be heavily rooted in academia, large tech companies such as Google, Microsoft, and IBM have begun curating documentation and open source code bases to allow others to concretely assess the robustness of machine learning models and minimize the risk of adversarial attacks. [ 16 ] [ 17 ] [ 18 ] Examples [ edit ] Examples include attacks in spam filtering , where spam messages are obfuscated through the misspelling of "bad" words or the insertion of "good" words; [ 19 ] [ 20 ] attacks in computer security , such as obfuscating malware code within network packets or modifying the characteristics of  network flow to mislead intrusion detection; [ 21 ] [ 22 ] attacks in biometric recognition where fake biometric traits may be exploited to impersonate  legitimate user; [ 23 ] or to compromise users' template galleries that adapt to updated traits over time. Researchers showed that by changing only one-pixel it was possible to fool deep learning algorithms. [ 24 ] Others - printed  toy turtle with  texture engineered to make Google' object detection AI classify it as  rifle regardless of the angle from which the turtle was viewed. [ 25 ] Creating the turtle required only low-cost commercially available - printing technology. [ 26 ]  machine-tweaked image of  dog was shown to look like  cat to both computers and humans. [ 27 ]  2019 study reported that humans can guess how machines will classify adversarial images. [ 28 ] Researchers discovered methods for perturbing the appearance of  stop sign such that an autonomous vehicle classified it as  merge or speed limit sign. [ 14 ] [ 29 ] McAfee attacked Tesla ' former Mobileye system, fooling it into driving 50 mph over the speed limit, simply by adding  two-inch strip of black tape to  speed limit sign. [ 30 ] [ 31 ] Adversarial patterns on glasses or clothing designed to deceive facial-recognition systems or license-plate readers, have led to  niche industry of "stealth streetwear". [ 32 ] An adversarial attack on  neural network can allow an attacker to inject algorithms into the target system. [ 33 ] Researchers can also create adversarial audio inputs to disguise commands to intelligent assistants in benign-seeming audio; [ 34 ]  parallel literature explores human perception of such stimuli. [ 35 ] [ 36 ] Clustering algorithms are used in security applications. Malware and computer virus analysis aims to identify malware families, and to generate specific detection signatures. [ 37 ] [ 38 ] Attack modalities [ edit ] Taxonomy [ edit ] Attacks against (supervised) machine learning algorithms have been categorized along three primary axes: [ 39 ] influence on the classifier, the security violation and their specificity. Classifier influence: An attack can influence the classifier by disrupting the classification phase. This may be preceded by an exploration phase to identify vulnerabilities. The attacker' capabilities might be restricted by the presence of data manipulation constraints. [ 40 ] Security violation: An attack can supply malicious data that gets classified as legitimate. Malicious data supplied during training can cause legitimate data to be rejected after training. Specificity:  targeted attack attempts to allow  specific intrusion/disruption. Alternatively, an indiscriminate attack creates general mayhem. This taxonomy has been extended into  more comprehensive threat model that allows explicit assumptions about the adversary' goal, knowledge of the attacked system, capability of manipulating the input data/system components, and on attack strategy. [ 41 ] [ 42 ] This taxonomy has further been extended to include dimensions for defense strategies against adversarial attacks. [ 43 ] Strategies [ edit ] Below are some of the most commonly encountered attack scenarios. Data poisoning [ edit ] Poisoning consists of contaminating the training dataset with data designed to increase errors in the output. Given that learning algorithms are shaped by their training datasets, poisoning can effectively reprogram algorithms with potentially malicious intent. Concerns have been raised especially for user-generated training data, .. for content recommendation or natural language models. The ubiquity of fake accounts offers many opportunities for poisoning. Facebook reportedly removes around  billion fake accounts per year. [ 44 ] [ 45 ] Poisoning has been reported as the leading concern for industrial applications. [  ] On social medias, disinformation campaigns attempt to bias recommendation and moderation algorithms, to push certain content over others.  particular case of data poisoning is the backdoor attack, [ 46 ] which aims to teach  specific behavior for inputs with  given trigger, ..  small defect on images, sounds, videos or texts. For instance, intrusion detection systems are often trained using collected data. An attacker may poison this data by injecting malicious samples during operation that subsequently disrupt retraining. [ 41 ] [ 42 ] [ 39 ] [ 47 ] [ 48 ] Data poisoning techniques can also be applied to text-to-image models to alter their output. [ 49 ] Data poisoning can also happen unintentionally through model collapse , where models are trained on synthetic data. [ 50 ] Byzantine attacks [ edit ] As machine learning is scaled, it often relies on multiple computing machines. In federated learning , for instance, edge devices collaborate with  central server, typically by sending gradients or model parameters. However, some of these devices may deviate from their expected behavior, .. to harm the central server' model [ 51 ] or to bias algorithms towards certain behaviors (.., amplifying the recommendation of disinformation content). On the other hand, if the training is performed on  single machine, then the model is very vulnerable to  failure of the machine, or an attack on the machine; the machine is  single point of failure . [ 52 ] In fact, the machine owner may themselves insert provably undetectable backdoors . [ 53 ] The current leading solutions to make (distributed) learning algorithms provably resilient to  minority of malicious (... Byzantine ) participants are based on robust gradient aggregation rules. [ 54 ] [ 55 ] [ 56 ] [ 57 ] [ 58 ] [ 59 ] The robust aggregation rules do not always work especially when the data across participants has  non-iid distribution. Nevertheless, in the context of heterogeneous honest participants, such as users with different consumption habits for recommendation algorithms or writing styles for language models, there are provable impossibility theorems on what any robust learning algorithm can guarantee. [  ] [ 60 ] Evasion [ edit ] Evasion attacks [  ] [ 41 ] [ 42 ] [ 61 ] consist of exploiting the imperfection of  trained model. For instance, spammers and hackers often attempt to evade detection by obfuscating the content of spam emails and malware . Samples are modified to evade detection; that is, to be classified as legitimate. This does not involve influence over the training data.  clear example of evasion is image-based spam in which the spam content is embedded within an attached image to evade textual analysis by anti-spam filters. Another example of evasion is given by spoofing attacks against biometric verification systems. [ 23 ] Evasion attacks can be generally split into two different categories: black box attacks and white box attacks . [ 17 ] Model extraction [ edit ] Model extraction involves an adversary probing  black box machine learning system in order to extract the data it was trained on. [ 62 ] [ 63 ] This can cause issues when either the training data or the model itself is sensitive and confidential. For example, model extraction could be used to extract  proprietary stock trading model which the adversary could then use for their own financial benefit. In the extreme case, model extraction can lead to model stealing , which corresponds to extracting  sufficient amount of data from the model to enable the complete reconstruction of the model. On the other hand, membership inference is  targeted model extraction attack, which infers the owner of  data point, often by leveraging the overfitting resulting from poor machine learning practices. [ 64 ] Concerningly, this is sometimes achievable even without knowledge or access to  target model' parameters, raising security concerns for models trained on sensitive data, including but not limited to medical records and/or personally identifiable information. With the emergence of transfer learning and public accessibility of many state of the art machine learning models, tech companies are increasingly drawn to create models based on public ones, giving attackers freely accessible information to the structure and type of model being used. [ 64 ] Categories [ edit ] Adversarial deep reinforcement learning [ edit ] Adversarial deep reinforcement learning is an active area of research in reinforcement learning focusing on vulnerabilities of learned policies. In this research area, some studies initially showed that reinforcement learning policies are susceptible to imperceptible adversarial manipulations. [ 65 ] [ 66 ] While some methods have been proposed to overcome these susceptibilities, in the most recent studies it has been shown that these proposed solutions are far from providing an accurate representation of current vulnerabilities of deep reinforcement learning policies. [ 67 ] Adversarial natural language processing [ edit ] Adversarial attacks on speech recognition have been introduced for speech-to-text applications, in particular for Mozilla' implementation of DeepSpeech. [ 68 ] Adversarial attacks and training in linear models [ edit ] There is  growing literature about adversarial attacks in linear models. Indeed, since the seminal work from Goodfellow at al. [ 69 ] studying these models in linear models has been an important tool to understand how adversarial attacks affect machine learning models. The analysis of these models is simplified because the computation of adversarial attacks can be simplified in linear regression and classification problems. Moreover, adversarial training is convex in this case. [ 70 ] Linear models allow for analytical analysis while still reproducing phenomena observed in state-of-the-art models. One prime example of that is how this model can be used to explain the trade-off between robustness and accuracy. [ 71 ] Diverse work indeed provides analysis of adversarial attacks in linear models, including asymptotic analysis for classification [ 72 ] and for linear regression. [ 73 ] [ 74 ] And, finite-sample analysis based on Rademacher complexity. [ 75 ] Specific attack types [ edit ] There are  large variety of different adversarial attacks that can be used against machine learning systems. Many of these work on both deep learning systems as well as traditional machine learning models such as SVMs [  ] and linear regression . [ 76 ]  high level sample of these attack types include: Adversarial Examples [ 77 ] Trojan Attacks / Backdoor Attacks [ 78 ] Model Inversion [ 79 ] Membership Inference [ 80 ] Adversarial examples [ edit ] An adversarial example refers to specially crafted input that is designed to look "normal" to humans but causes misclassification to  machine learning model. Often,  form of specially designed "noise" is used to elicit the misclassifications. Below are some current techniques for generating adversarial examples in the literature (by no means an exhaustive list). Gradient-based evasion attack [  ] Fast Gradient Sign Method (FGSM) [ 81 ] Projected Gradient Descent (PGD) [ 82 ] Carlini and Wagner (&) attack [ 83 ] Adversarial patch attack [ 84 ] Black box attacks [ edit ] Black box attacks in adversarial machine learning assume that the adversary can only get outputs for provided inputs and has no knowledge of the model structure or parameters. [ 17 ] [ 85 ] In this case, the adversarial example is generated either using  model created from scratch, or without any model at all (excluding the ability to query the original model). In either case, the objective of these attacks is to create adversarial examples that are able to transfer to the black box model in question. [ 86 ] Square Attack [ edit ] The Square Attack was introduced in 2020 as  black box evasion adversarial attack based on querying classification scores without the need of gradient information. [ 87 ] As  score based black box attack, this adversarial approach is able to query probability distributions across model output classes, but has no other access to the model itself. According to the paper' authors, the proposed Square Attack required fewer queries than when compared to state-of-the-art score-based black box attacks at the time. [ 87 ] To describe the function objective, the attack defines the classifier as  : [  ,  ]  →   {\textstyle :[,]^{}\rightarrow \mathbb {} ^{}} , with  {\textstyle } representing the dimensions of the input and  {\textstyle } as the total number of output classes.   (  ) {\textstyle f_{}()} returns the score (or  probability between  and ) that the input  {\textstyle } belongs to class  {\textstyle } , which allows the classifier' class output for any input  {\textstyle } to be defined as argmax  =  , . . . ,    (  ) {\textstyle {\text{argmax}}{=,...,}f_{}()} . The goal of this attack is as follows: [ 87 ] argmax  =  , . . . ,    (  ^ ) ≠  , | |  ^ −  | |  ≤  and  ^ ∈ [  ,  ]  {\displaystyle {\text{argmax}}{=,...,}f_{}({\hat {}})\neq ,||{\hat {}}-||{}\leq \epsilon {\text{ and }}{\hat {}}\in [,]^{}} In other words, finding some perturbed adversarial example  ^ {\textstyle {\hat {}}} such that the classifier incorrectly classifies it to some other class under the constraint that  ^ {\textstyle {\hat {}}} and  {\textstyle } are similar. The paper then defines loss  {\textstyle } as  (  (  ^ ) ,  ) =   (  ^ ) − max  ≠    (  ^ ) {\textstyle (({\hat {}}),)=f_{}({\hat {}})-\max {\neq }f_{}({\hat {}})} and proposes the solution to finding adversarial example  ^ {\textstyle {\hat {}}} as solving the below constrained optimization problem : [ 87 ] min  ^ ∈ [  ,  ]   (  (  ^ ) ,  ) , .. | |  ^ −  | |  ≤  {\displaystyle \min {{\hat {}}\in [,]^{}}(({\hat {}}),),{\text{ .. }}||{\hat {}}-||{}\leq \epsilon } The result in theory is an adversarial example that is highly confident in the incorrect class but is also very similar to the original image. To find such example, Square Attack utilizes the iterative random search technique to randomly perturb the image in hopes of improving the objective function. In each step, the algorithm perturbs only  small square section of pixels, hence the name Square Attack, which terminates as soon as an adversarial example is found in order to improve query efficiency. Finally, since the attack algorithm uses scores and not gradient information, the authors of the paper indicate that this approach is not affected by gradient masking,  common technique formerly used to prevent evasion attacks. [ 87 ] HopSkipJump Attack [ edit ] This black box attack was also proposed as  query efficient attack, but one that relies solely on access to any input' predicted output class. In other words, the HopSkipJump attack does not require the ability to calculate gradients or access to score values like the Square Attack, and will require just the model' class prediction output (for any given input). The proposed attack is split into two different settings, targeted and untargeted, but both are built from the general idea of adding minimal perturbations that leads to  different model output. In the targeted setting, the goal is to cause the model to misclassify the perturbed image to  specific target label (that is not the original label). In the untargeted setting, the goal is to cause the model to misclassify the perturbed image to any label that is not the original label. The attack objectives for both are as follows where  {\textstyle } is the original image,  ′ {\textstyle ^{\prime }} is the adversarial image,  {\textstyle } is  distance function between images,  ∗ {\textstyle ^{*}} is the target label, and  {\textstyle } is the model' classification class label function: [ 88 ] Targeted: min  ′  (  ′ ,  ) subject to  (  ′ ) =  ∗ {\displaystyle {\textbf {Targeted:}}\min {^{\prime }}(^{\prime },){\text{ subject to }}(^{\prime })=^{*}} Untargeted: min  ′  (  ′ ,  ) subject to  (  ′ ) ≠  (  ) {\displaystyle {\textbf {Untargeted:}}\min {^{\prime }}(^{\prime },){\text{ subject to }}(^{\prime })\neq ()} To solve this problem, the attack proposes the following boundary function  {\textstyle } for both the untargeted and targeted setting: [ 88 ]  (  ′ ) := { max  ≠  (  )  (  ′ )  −  (  ′ )  (  ) , (Untargeted)  (  ′ )  ∗ − max  ≠  ∗  (  ′ )  , (Targeted) {\displaystyle (^{\prime }):={\begin{cases}\max {\neq ()}{(^{\prime }){}}-(^{\prime }){()},&{\text{(Untargeted)}}\\(^{\prime }){^{*}}-\max {\neq ^{*}}{(^{\prime }){}},&{\text{(Targeted)}}\end{cases}}} This can be further simplified to better visualize the boundary between different potential adversarial examples: [ 88 ]  (  ′ ) >  ⟺ {         (  ′ ) ≠  (  ) , (Untargeted)         (  ′ ) =  ∗ , (Targeted) {\displaystyle (^{\prime })>\iff {\begin{cases}argmax_{}(^{\prime })\neq (),&{\text{(Untargeted)}}\\argmax_{}(^{\prime })=^{*},&{\text{(Targeted)}}\end{cases}}} With this boundary function, the attack then follows an iterative algorithm to find adversarial examples  ′ {\textstyle ^{\prime }} for  given image  {\textstyle } that satisfies the attack objectives. Initialize  {\textstyle } to some point where  (  ) >  {\textstyle ()>} Iterate below Boundary search Gradient update Compute the gradient Find the step size Boundary search uses  modified binary search to find the point in which the boundary (as defined by  {\textstyle } ) intersects with the line between  {\textstyle } and  ′ {\textstyle ^{\prime }} . The next step involves calculating the gradient for  {\textstyle } , and update the original  {\textstyle } using this gradient and  pre-chosen step size. HopSkipJump authors prove that this iterative algorithm will converge, leading  {\textstyle } to  point right along the boundary that is very close in distance to the original image. [ 88 ] However, since HopSkipJump is  proposed black box attack and the iterative algorithm above requires the calculation of  gradient in the second iterative step (which black box attacks do not have access to), the authors propose  solution to gradient calculation that requires only the model' output predictions alone. [ 88 ] By generating many random vectors in all directions, denoted as   {\textstyle u_{}} , an approximation of the gradient can be calculated using the average of these random vectors weighted by the sign of the boundary function on the image  ′ +    {\textstyle ^{\prime }+\delta {u_{}}} , where    {\textstyle \delta {u_{}}} is the size of the random vector perturbation: [ 88 ] ∇  (  ′ ,  ) ≈   ∑  =    (  ′ +    )   {\displaystyle \nabla (^{\prime },\delta )\approx {\frac {}{}}\sum {=}^{}\phi (^{\prime }+\delta {u_{}})u_{}} The result of the equation above gives  close approximation of the gradient required in step  of the iterative algorithm, completing HopSkipJump as  black box attack. [ 89 ] [ 90 ] [ 88 ] White box attacks [ edit ] White box attacks assumes that the adversary has access to model parameters on top of being able to get labels for provided inputs. [ 86 ] Fast gradient sign method [ edit ] One of the first proposed attacks for generating adversarial examples was proposed by Google researchers Ian . Goodfellow , Jonathon Shlens, and Christian Szegedy. [ 91 ] The attack was called fast gradient sign method (FGSM), and it consists of adding  linear amount of in-perceivable noise to the image and causing  model to incorrectly classify it. This noise is calculated by multiplying the sign of the gradient with respect to the image we want to perturb by  small constant epsilon. As epsilon increases, the model is more likely to be fooled, but the perturbations become easier to identify as well. Shown below is the equation to generate an adversarial example where  {\textstyle } is the original image,  {\textstyle \epsilon } is  very small number,   {\textstyle \Delta {}} is the gradient function,  {\textstyle } is the loss function,  {\textstyle \theta } is the model weights, and  {\textstyle } is the true label. [ 92 ]     =  +  ⋅     (    (  ,  ,  ) ) {\displaystyle adv_{}=+\epsilon \cdot sign(\Delta {}(\theta ,,))} One important property of this equation is that the gradient is calculated with respect to the input image since the goal is to generate an image that maximizes the loss for the original image of true label  {\textstyle } . In traditional gradient descent (for model training), the gradient is used to update the weights of the model since the goal is to minimize the loss for the model on  ground truth dataset. The Fast Gradient Sign Method was proposed as  fast way to generate adversarial examples to evade the model, based on the hypothesis that neural networks cannot resist even linear amounts of perturbation to the input. [ 93 ] [ 92 ] [ 91 ] FGSM has shown to be effective in adversarial attacks for image classification and skeletal action recognition. [ 94 ] Carlini & Wagner (&) [ edit ] In an effort to analyze existing adversarial attacks and defenses, researchers at the University of California, Berkeley, Nicholas Carlini and David Wagner in 2016 propose  faster and more robust method to generate adversarial examples. [ 95 ] The attack proposed by Carlini and Wagner begins with trying to solve  difficult non-linear optimization equation: [ 63 ] min ( | |  | |  ) subject to  (  +  ) =  ,  +  ∈ [  ,  ]  {\displaystyle \min(||\delta ||{}){\text{ subject to }}(+\delta )=,+\delta \in [,]^{}} Here the objective is to minimize the noise (  {\textstyle \delta } ), added to the original input  {\textstyle } , such that the machine learning algorithm (  {\textstyle } ) predicts the original input with delta (or  +  {\textstyle +\delta } ) as some other class  {\textstyle } . However instead of directly the above equation, Carlini and Wagner propose using  new function  {\textstyle } such that: [ 63 ]  (  +  ) =  ⟺  (  +  ) ≤  {\displaystyle (+\delta )=\iff (+\delta )\leq } This condenses the first equation to the problem below: [ 63 ] min ( | |  | |  ) subject to  (  +  ) ≤  ,  +  ∈ [  ,  ]  {\displaystyle \min(||\delta ||{}){\text{ subject to }}(+\delta )\leq ,+\delta \in [,]^{}} and even more to the equation below: [ 63 ] min ( | |  | |  +  ⋅  (  +  ) ) ,  +  ∈ [  ,  ]  {\displaystyle \min(||\delta ||{}+\cdot (+\delta )),+\delta \in [,]^{}} Carlini and Wagner then propose the use of the below function in place of  {\textstyle } using  {\textstyle } ,  function that determines class probabilities for given input  {\textstyle } . When substituted in, this equation can be thought of as finding  target class that is more confident than the next likeliest class by some constant amount: [ 63 ]  (  ) = ( [ max  ≠   (  )  ] −  (  )  ) + {\displaystyle ()=([\max {\neq }(){}]-(){})^{+}} When solved using gradient descent, this equation is able to produce stronger adversarial examples when compared to fast gradient sign method that is also able to bypass defensive distillation,  defense that was once proposed to be effective against adversarial examples. [ 96 ] [ 97 ] [ 95 ] [ 63 ] Defenses [ edit ] Conceptual representation of the proactive arms race [ 42 ] [ 38 ] Researchers have proposed  multi-step approach to protecting machine learning. [ 11 ] Threat modeling – Formalize the attackers goals and capabilities with respect to the target system. Attack simulation – Formalize the optimization problem the attacker tries to solve according to possible attack strategies. Attack impact evaluation Countermeasure design Noise detection (For evasion based attack) [ 98 ] Information laundering – Alter the information received by adversaries (for model stealing attacks) [ 63 ] Mechanisms [ edit ]  number of defense mechanisms against evasion, poisoning, and privacy attacks have been proposed, including: Secure learning algorithms [ 20 ] [ 99 ] [ 100 ] Byzantine-resilient algorithms [ 54 ] [  ] Multiple classifier systems [ 19 ] [ 101 ] AI-written algorithms. [ 33 ] AIs that explore the training environment; for example, in image recognition, actively navigating  3D environment rather than passively scanning  fixed set of 2D images. [ 33 ] Privacy-preserving learning [ 42 ] [ 102 ] Ladder algorithm for Kaggle -style competitions Game theoretic models [ 103 ] [ 104 ] [ 105 ] Sanitizing training data Adversarial training [ 81 ] [ 22 ] Backdoor detection algorithms [ 106 ] Gradient masking/obfuscation techniques: to prevent the adversary exploiting the gradient in white-box attacks. This family of defenses is deemed unreliable as these models are still vulnerable to black-box attacks or can be circumvented in other ways. [ 107 ] Ensembles of models have been proposed in the literature but caution should be applied when relying on them: usually ensembling weak classifiers results in  more accurate model but it does not seem to apply in the adversarial context. [ 108 ] See also [ edit ] Pattern recognition Fawkes (image cloaking software) Generative adversarial network References [ edit ] ^ Kianpour, Mazaher; Wen, Shao-Fang (2020). "Timing Attacks on Machine Learning: State of the Art". Intelligent Systems and Applications . Advances in Intelligent Systems and Computing. Vol. 1037. pp. 111–125. doi : 10.1007/978--030-29516-5_10 . ISBN 978--030-29515- . S2CID 201705926 . ^   Siva Kumar, Ram Shankar; Nyström, Magnus; Lambert, John; Marshall, Andrew; Goertzel, Mario; Comissoneru, Andi; Swann, Matt; Xia, Sharon (May 2020). "Adversarial Machine Learning-Industry Perspectives" . 2020 IEEE Security and Privacy Workshops (SPW) . pp. 69–75. doi : 10.1109/SPW50608.2020.00028 . ISBN 978--7281-9346- . S2CID 229357721 . ^ Goodfellow, Ian; McDaniel, Patrick; Papernot, Nicolas (25 June 2018). "Making machine learning robust against adversarial inputs" . Communications of the ACM . 61 (): 56–66. doi : 10.1145/3134599 . ISSN 0001-0782 . [ permanent dead link ] ^ Geiping, Jonas; Fowl, Liam .; Huang, . Ronny; Czaja, Wojciech; Taylor, Gavin; Moeller, Michael; Goldstein, Tom (2020-09-28). Witches' Brew: Industrial Scale Data Poisoning via Gradient Matching . International Conference on Learning Representations 2021 (Poster). ^    El-Mhamdi, El Mahdi; Farhadkhani, Sadegh; Guerraoui, Rachid; Guirguis, Arsany; Hoang, Lê-Nguyên; Rouault, Sébastien (2021-12-06). "Collaborative Learning in the Jungle (Decentralized, Byzantine, Heterogeneous, Asynchronous and Nonconvex Learning)" . Advances in Neural Information Processing Systems . 34 . arXiv : 2008.00742 . ^ Tramèr, Florian; Zhang, Fan; Juels, Ari; Reiter, Michael .; Ristenpart, Thomas (2016). Stealing Machine Learning Models via Prediction {APIs} . 25th USENIX Security Symposium. pp. 601–618. ISBN 978--931971-32- . ^ "How to beat an adaptive/Bayesian spam filter (2004)" . Retrieved 2023-07-05 . ^   Biggio, Battista; Nelson, Blaine; Laskov, Pavel (2013-03-25). "Poisoning Attacks against Support Vector Machines". arXiv : 1206.6389 [ cs.LG ]. ^    Biggio, Battista; Corona, Igino; Maiorca, Davide; Nelson, Blaine; Srndic, Nedim; Laskov, Pavel; Giacinto, Giorgio; Roli, Fabio (2013). "Evasion Attacks against Machine Learning at Test Time". Advanced Information Systems Engineering . Lecture Notes in Computer Science. Vol. 7908. Springer. pp. 387–402. arXiv : 1708.06131 . doi : 10.1007/978--642-40994-3_25 . ISBN 978--642-38708- . S2CID 18716873 . ^ Szegedy, Christian; Zaremba, Wojciech; Sutskever, Ilya; Bruna, Joan; Erhan, Dumitru; Goodfellow, Ian; Fergus, Rob (2014-02-19). "Intriguing properties of neural networks". arXiv : 1312.6199 [ cs.CV ]. ^   Biggio, Battista; Roli, Fabio (December 2018). "Wild patterns: Ten years after the rise of adversarial machine learning". Pattern Recognition . 84 : 317–331. arXiv : 1712.03141 . Bibcode : 2018PatRe..84..317B . doi : 10.1016/.patcog.2018.07.023 . S2CID 207324435 . ^ Kurakin, Alexey; Goodfellow, Ian; Bengio, Samy (2016). "Adversarial examples in the physical world". arXiv : 1607.02533 [ cs.CV ]. ^ Gupta, Kishor Datta, Dipankar Dasgupta, and Zahid Akhtar. "Applicability issues of Evasion-Based Adversarial Attacks and Mitigation Techniques." 2020 IEEE Symposium Series on Computational Intelligence (SSCI). 2020. ^   Lim, Hazel Si Min; Taeihagh, Araz (2019). "Algorithmic Decision-Making in AVs: Understanding Ethical and Technical Concerns for Smart Cities" . Sustainability . 11 (20): 5791. arXiv : 1910.13122 . Bibcode : 2019arXiv191013122L . doi : 10.3390/su11205791 . S2CID 204951009 . ^   "Google Brain' Nicholas Frosst on Adversarial Examples and Emotional Responses" . Synced . 2019-11-21 . Retrieved 2021-10-23 . ^ "Responsible AI practices" . Google AI . Retrieved 2021-10-23 . ^    Adversarial Robustness Toolbox (ART) v1. , Trusted-AI, 2021-10-23 , retrieved 2021-10-23 ^ amarshal. "Failure Modes in Machine Learning - Security documentation" . docs.microsoft.com . Retrieved 2021-10-23 . ^   Biggio, Battista; Fumera, Giorgio; Roli, Fabio (2010). "Multiple classifier systems for robust classifier design in adversarial environments" . International Journal of Machine Learning and Cybernetics .  (–): 27–41. doi : 10.1007/s13042-010-0007- . hdl : 11567/1087824 . ISSN 1868-8071 . S2CID 8729381 . Archived from the original on 2023-01-19 . Retrieved 2015-01-14 . ^   Brückner, Michael; Kanzow, Christian; Scheffer, Tobias (2012). "Static Prediction Games for Adversarial Learning Problems" (PDF) . Journal of Machine Learning Research . 13 (Sep): 2617–2654. ISSN 1533-7928 . ^ Apruzzese, Giovanni; Andreolini, Mauro; Ferretti, Luca; Marchetti, Mirco; Colajanni, Michele (2021-06-03). "Modeling Realistic Adversarial Attacks against Network Intrusion Detection Systems". Digital Threats: Research and Practice .  (): –19. arXiv : 2106.09380 . doi : 10.1145/3469659 . ISSN 2692-1626 . S2CID 235458519 . ^   Vitorino, João; Oliveira, Nuno; Praça, Isabel (March 2022). "Adaptative Perturbation Patterns: Realistic Adversarial Learning for Robust Intrusion Detection" . Future Internet . 14 (): 108. doi : 10.3390/fi14040108 . hdl : 10400.22/21851 . ISSN 1999-5903 . ^   Rodrigues, Ricardo .; Ling, Lee Luan; Govindaraju, Venu ( June 2009). "Robustness of multimodal biometric fusion methods against spoof attacks" (PDF) . Journal of Visual Languages & Computing . 20 (): 169–179. doi : 10.1016/.jvlc.2009.01.010 . ISSN 1045-926X . ^ Su, Jiawei; Vargas, Danilo Vasconcellos; Sakurai, Kouichi (October 2019). "One Pixel Attack for Fooling Deep Neural Networks". IEEE Transactions on Evolutionary Computation . 23 (): 828–841. arXiv : 1710.08864 . doi : 10.1109/TEVC.2019.2890858 . ISSN 1941-0026 . S2CID 2698863 . ^ "Single pixel change fools AI programs" . BBC News .  November 2017 . Retrieved 12 February 2018 . ^ Athalye, Anish; Engstrom, Logan; Ilyas, Andrew; Kwok, Kevin (2017). "Synthesizing Robust Adversarial Examples". arXiv : 1707.07397 [ cs.CV ]. ^ "AI Has  Hallucination Problem That' Proving Tough to Fix" . WIRED . 2018 . Retrieved 10 March 2018 . ^ Zhou, Zhenglong; Firestone, Chaz (2019). "Humans can decipher adversarial images" . Nature Communications . 10 (): 1334. arXiv : 1809.04120 . Bibcode : 2019NatCo..10.1334Z . doi : 10.1038/s41467-019-08931- . PMC 6430776 . PMID 30902973 . ^ Ackerman, Evan (2017-08-04). "Slight Street Sign Modifications Can Completely Fool Machine Learning Algorithms" . IEEE Spectrum: Technology, Engineering, and Science News . Retrieved 2019-07-15 . ^ " Tiny Piece of Tape Tricked Teslas Into Speeding Up 50 MPH" . Wired . 2020 . Retrieved 11 March 2020 . ^ "Model Hacking ADAS to Pave Safer Roads for Autonomous Vehicles" . McAfee Blogs . 2020-02-19 . Retrieved 2020-03-11 . ^ Seabrook, John (2020). "Dressing for the Surveillance Age" . The New Yorker . Retrieved  April 2020 . ^    Heaven, Douglas (October 2019). "Why deep-learning AIs are so easy to fool". Nature . 574 (7777): 163–166. Bibcode : 2019Natur.574..163H . doi : 10.1038/d41586-019-03013- . PMID 31597977 . S2CID 203928744 . ^ Hutson, Matthew (10 May 2019). "AI can now defend itself against malicious messages hidden in speech". Nature . doi : 10.1038/d41586-019-01510- . PMID 32385365 . S2CID 189666088 . ^ Lepori, Michael ; Firestone, Chaz (2020-03-27). "Can you hear me now? Sensitive comparisons of human and machine perception". arXiv : 2003.12362 [ eess.AS ]. ^ Vadillo, Jon; Santana, Roberto (2020-01-23). "On the human evaluation of audio adversarial examples". arXiv : 2001.08444 [ eess.AS ]. ^ . . Skillicorn. "Adversarial knowledge discovery". IEEE Intelligent Systems, 24:54–61, 2009. ^   . Biggio, . Fumera, and . Roli. " Pattern recognition systems under attack: Design issues and research challenges Archived 2022-05-20 at the Wayback Machine ". Int' . Patt. Recogn. Artif. Intell., 28():1460002, 2014. ^   Barreno, Marco; Nelson, Blaine; Joseph, Anthony .; Tygar, . . (2010). "The security of machine learning" (PDF) . Machine Learning . 81 (): 121–148. doi : 10.1007/s10994-010-5188- . S2CID 2304759 . ^ Sikos, Leslie . (2019). AI in Cybersecurity . Intelligent Systems Reference Library. Vol. 151. Cham: Springer. . 50. doi : 10.1007/978--319-98842- . ISBN 978--319-98841- . S2CID 259216663 . ^    . Biggio, . Fumera, and . Roli. " Security evaluation of pattern classifiers under attack Archived 2018-05-18 at the Wayback Machine ". IEEE Transactions on Knowledge and Data Engineering, 26():984–996, 2014. ^      Biggio, Battista; Corona, Igino; Nelson, Blaine; Rubinstein, Benjamin . .; Maiorca, Davide; Fumera, Giorgio; Giacinto, Giorgio; Roli, Fabio (2014). "Security Evaluation of Support Vector Machines in Adversarial Environments". Support Vector Machines Applications . Springer International Publishing. pp. 105–153. arXiv : 1401.7727 . doi : 10.1007/978--319-02300-7_4 . ISBN 978--319-02300- . S2CID 18666561 . ^ Heinrich, Kai; Graf, Johannes; Chen, Ji; Laurisch, Jakob; Zschech, Patrick (2020-06-15). "Fool Me Once, Shame On You, Fool Me Twice, Shame On Me:  Taxonomy of Attack and De-fense Patterns for AI Security" . ECIS 2020 Research Papers . ^ "Facebook removes 15 Billion fake accounts in two years" . Tech Digest . 2021-09-27 . Retrieved 2022-06-08 . ^ "Facebook removed  billion fake accounts in just  months" . New York Post . Associated Press. 2019-05-23 . Retrieved 2022-06-08 . ^ Schwarzschild, Avi; Goldblum, Micah; Gupta, Arjun; Dickerson, John .; Goldstein, Tom (2021-07-01). "Just How Toxic is Data Poisoning?  Unified Benchmark for Backdoor and Data Poisoning Attacks" . International Conference on Machine Learning . PMLR: 9389–9398. ^ . Biggio, . Nelson, and . Laskov. " Support vector machines under adversarial label noise Archived 2020-08-03 at the Wayback Machine ". In Journal of Machine Learning Research – Proc. 3rd Asian Conf. Machine Learning, volume 20, pp. 97–112, 2011. ^ . Kloft and . Laskov. " Security analysis of online centroid anomaly detection ". Journal of Machine Learning Research, 13:3647–3690, 2012. ^ Edwards, Benj (2023-10-25). "University of Chicago researchers seek to "poison" AI art generators with Nightshade" . Ars Technica . Retrieved 2023-10-27 . ^ Rao, Rahul. "AI-Generated Data Can Poison Future AI Models" . Scientific American . Retrieved 2024-06-22 . ^ Baruch, Gilad; Baruch, Moran; Goldberg, Yoav (2019). " Little Is Enough: Circumventing Defenses For Distributed Learning" . Advances in Neural Information Processing Systems . 32 . Curran Associates, Inc. arXiv : 1902.06156 . ^ El-Mhamdi, El-Mahdi; Guerraoui, Rachid; Guirguis, Arsany; Hoang, Lê-Nguyên; Rouault, Sébastien (2022-05-26). "Genuinely distributed Byzantine machine learning" . Distributed Computing . 35 (): 305–331. arXiv : 1905.03853 . doi : 10.1007/s00446-022-00427- . ISSN 1432-0452 . S2CID 249111966 . ^ Goldwasser, .; Kim, Michael .; Vaikuntanathan, .; Zamir, Or (2022). "Planting Undetectable Backdoors in Machine Learning Models". arXiv : 2204.06974 [ cs.LG ]. ^   Blanchard, Peva; El Mhamdi, El Mahdi; Guerraoui, Rachid; Stainer, Julien (2017). "Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent" . Advances in Neural Information Processing Systems . 30 . Curran Associates, Inc. ^ Chen, Lingjiao; Wang, Hongyi; Charles, Zachary; Papailiopoulos, Dimitris (2018-07-03). "DRACO: Byzantine-resilient Distributed Training via Redundant Gradients" . International Conference on Machine Learning . PMLR: 903–912. arXiv : 1803.09877 . ^ Mhamdi, El Mahdi El; Guerraoui, Rachid; Rouault, Sébastien (2018-07-03). "The Hidden Vulnerability of Distributed Learning in Byzantium" . International Conference on Machine Learning . PMLR: 3521–3530. arXiv : 1802.07927 . ^ Allen-Zhu, Zeyuan; Ebrahimianghazani, Faeze; Li, Jerry; Alistarh, Dan (2020-09-28). "Byzantine-Resilient Non-Convex Stochastic Gradient Descent". arXiv : 2012.14368 [ cs.LG ]. Review ^ Mhamdi, El Mahdi El; Guerraoui, Rachid; Rouault, Sébastien (2020-09-28). Distributed Momentum for Byzantine-resilient Stochastic Gradient Descent . 9th International Conference on Learning Representations (ICLR), May -, 2021 (virtual conference) . Retrieved 2022-10-20 . Review ^ Data, Deepesh; Diggavi, Suhas (2021-07-01). "Byzantine-Resilient High-Dimensional SGD with Local Iterations on Heterogeneous Data" . International Conference on Machine Learning . PMLR: 2478–2488. ^ Karimireddy, Sai Praneeth; He, Lie; Jaggi, Martin (2021-09-29). "Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing". arXiv : 2006.09365 [ cs.LG ]. Review ^ . Nelson, . . Rubinstein, . Huang, . . Joseph, . . Lee, . Rao, and . . Tygar. " Query strategies for evading convex-inducing classifiers ". . Mach. Learn. Res., 13:1293–1332, 2012 ^ "How to steal modern NLP systems with gibberish?" . cleverhans-blog . 2020-04-06 . Retrieved 2020-10-15 . ^         Wang, Xinran; Xiang, Yu; Gao, Jun; Ding, Jie (2020-09-13). "Information Laundering for Model Privacy". arXiv : 2009.06112 [ cs.CR ]. ^   Dickson, Ben (2021-04-23). "Machine learning: What are membership inference attacks?" . TechTalks . Retrieved 2021-11-07 . ^ Goodfellow, Ian; Shlens, Jonathan; Szegedy, Christian (2015). "Explaining and Harnessing Adversarial Examples". International Conference on Learning Representations . arXiv : 1412.6572 . ^ Pieter, Huang; Papernot, Sandy; Goodfellow, Nicolas; Duan, Ian; Abbeel, Yan (2017-02-07). Adversarial Attacks on Neural Network Policies . OCLC 1106256905 . ^ Korkmaz, Ezgi (2022). "Deep Reinforcement Learning Policies Learn Shared Adversarial Features Across MDPs". Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22) . 36 (): 7229–7238. arXiv : 2112.09025 . doi : 10.1609/aaai.v36i7.20684 . S2CID 245219157 . ^ Carlini, Nicholas; Wagner, David (2018). "Audio Adversarial Examples: Targeted Attacks on Speech-to-Text". 2018 IEEE Security and Privacy Workshops (SPW) . pp. –. arXiv : 1801.01944 . doi : 10.1109/SPW.2018.00009 . ISBN 978--5386-8276- . S2CID 4475201 . ^ Goodfellow, Ian .; Shlens, Jonathon; Szegedy, Christian (2015). Explaining and Harnessing Adversarial Examples . International Conference on Learning Representations (ICLR). ^ Ribeiro, Antonio .; Zachariah, Dave; Bach, Francis; Schön, Thomas . (2023). Regularization properties of adversarially-trained linear regression . Thirty-seventh Conference on Neural Information Processing Systems. ^ Tsipras, Dimitris; Santurkar, Shibani; Engstrom, Logan; Turner, Alexander; Ma, Aleksander (2019). Robustness May Be At Odds with Accuracy . International Conference for Learning Representations. ^ Dan, .; Wei, .; Ravikumar, . (2020). Sharp statistical guarantees for adversarially robust Gaussian classification . International Conference on Machine Learning. ^ Javanmard, .; Soltanolkotabi, .; Hassani, . (2020). Precise tradeoffs in adversarial training for linear regression . Conference on Learning Theory. ^ Ribeiro, . .; Schön, . . (2023). "Overparameterized Linear Regression under Adversarial Attacks". IEEE Transactions on Signal Processing . 71 : 601–614. arXiv : 2204.06274 . Bibcode : 2023ITSP...71..601R . doi : 10.1109/TSP.2023.3246228 . ^ Yin, .; Kannan, .; Bartlett, . (2019). Rademacher Complexity for Adversarially Robust Generalization . International Conference on Machine Learning. ^ Jagielski, Matthew; Oprea, Alina; Biggio, Battista; Liu, Chang; Nita-Rotaru, Cristina; Li, Bo (May 2018). "Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning". 2018 IEEE Symposium on Security and Privacy (SP) . IEEE. pp. 19–35. arXiv : 1804.00308 . doi : 10.1109/sp.2018.00057 . ISBN 978--5386-4353- . S2CID 4551073 . ^ "Attacking Machine Learning with Adversarial Examples" . OpenAI . 2017-02-24 . Retrieved 2020-10-15 . ^ Gu, Tianyu; Dolan-Gavitt, Brendan; Garg, Siddharth (2019-03-11). "BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain". arXiv : 1708.06733 [ cs.CR ]. ^ Veale, Michael; Binns, Reuben; Edwards, Lilian (2018-11-28). "Algorithms that remember: model inversion attacks and data protection law" . Philosophical Transactions. Series , Mathematical, Physical, and Engineering Sciences . 376 (2133). arXiv : 1807.04644 . Bibcode : 2018RSPTA.37680083V . doi : 10.1098/rsta.2018.0083 . ISSN 1364-503X . PMC 6191664 . PMID 30322998 . ^ Shokri, Reza; Stronati, Marco; Song, Congzheng; Shmatikov, Vitaly (2017-03-31). "Membership Inference Attacks against Machine Learning Models". arXiv : 1610.05820 [ cs.CR ]. ^   Goodfellow, Ian .; Shlens, Jonathon; Szegedy, Christian (2015-03-20). "Explaining and Harnessing Adversarial Examples". arXiv : 1412.6572 [ stat.ML ]. ^ Madry, Aleksander; Makelov, Aleksandar; Schmidt, Ludwig; Tsipras, Dimitris; Vladu, Adrian (2019-09-04). "Towards Deep Learning Models Resistant to Adversarial Attacks". arXiv : 1706.06083 [ stat.ML ]. ^ Carlini, Nicholas; Wagner, David (2017-03-22). "Towards Evaluating the Robustness of Neural Networks". arXiv : 1608.04644 [ cs.CR ]. ^ Brown, Tom .; Mané, Dandelion; Roy, Aurko; Abadi, Martín; Gilmer, Justin (2018-05-16). "Adversarial Patch". arXiv : 1712.09665 [ cs.CV ]. ^ Guo, Sensen; Zhao, Jinxiong; Li, Xiaoyu; Duan, Junhong; Mu, Dejun; Jing, Xiao (2021-04-24). " Black-Box Attack Method against Machine-Learning-Based Anomaly Network Flow Detection Models" . Security and Communication Networks . 2021 . e5578335. doi : 10.1155/2021/5578335 . ISSN 1939-0114 . ^   Gomes, Joao (2018-01-17). "Adversarial Attacks and Defences for Convolutional Neural Networks" . Onfido Tech . Retrieved 2021-10-23 . ^      Andriushchenko, Maksym; Croce, Francesco; Flammarion, Nicolas; Hein, Matthias (2020). "Square Attack:  Query-Efficient Black-Box Adversarial Attack via Random Search" . In Vedaldi, Andrea; Bischof, Horst; Brox, Thomas; Frahm, Jan-Michael (eds.). Computer Vision – ECCV 2020 . Lecture Notes in Computer Science. Vol. 12368. Cham: Springer International Publishing. pp. 484–501. arXiv : 1912.00049 . doi : 10.1007/978--030-58592-1_29 . ISBN 978--030-58592- . S2CID 208527215 . ^        Chen, Jianbo; Jordan, Michael .; Wainwright, Martin . (2019), HopSkipJumpAttack:  Query-Efficient Decision-Based Attack , arXiv : 1904.02144 , retrieved 2021-10-25 ^ Andriushchenko, Maksym; Croce, Francesco; Flammarion, Nicolas; Hein, Matthias (2020-07-29). "Square Attack:  query-efficient black-box adversarial attack via random search". arXiv : 1912.00049 [ cs.LG ]. ^ "Black-box decision-based attacks on images" . KejiTech . 2020-06-21 . Retrieved 2021-10-25 . ^   Goodfellow, Ian .; Shlens, Jonathon; Szegedy, Christian (2015-03-20). "Explaining and Harnessing Adversarial Examples". arXiv : 1412.6572 [ stat.ML ]. ^   "Adversarial example using FGSM | TensorFlow Core" . TensorFlow . Retrieved 2021-10-24 . ^ Tsui, Ken (2018-08-22). "Perhaps the Simplest Introduction of Adversarial Examples Ever" . Medium . Retrieved 2021-10-24 . ^ Corona-Figueroa, Abril; Bond-Taylor, Sam; Bhowmik, Neelanjan; Gaus, Yona Falinie .; Breckon, Toby .; Shum, Hubert . .; Willcocks, Chris . (2023). Unaligned 2D to 3D Translation with Conditional Vector-Quantized Code Diffusion using Transformers . IEEE/CVF. arXiv : 2308.14152 . ^   Carlini, Nicholas; Wagner, David (2017-03-22). "Towards Evaluating the Robustness of Neural Networks". arXiv : 1608.04644 [ cs.CR ]. ^ "carlini wagner attack" . richardjordan.com . Retrieved 2021-10-23 . ^ Plotz, Mike (2018-11-26). "Paper Summary: Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods" . Medium . Retrieved 2021-10-23 . ^ Kishor Datta Gupta; Akhtar, Zahid; Dasgupta, Dipankar (2021). "Determining Sequence of Image Processing Technique (IPT) to Detect Adversarial Attacks". SN Computer Science .  (): 383. arXiv : 2007.00337 . doi : 10.1007/s42979-021-00773- . ISSN 2662-995X . S2CID 220281087 . ^ . Dekel, . Shamir, and . Xiao. " Learning to classify with missing and corrupted features ". Machine Learning, 81:149–178, 2010. ^ Liu, Wei; Chawla, Sanjay (2010). "Mining adversarial patterns via regularized loss minimization" (PDF) . Machine Learning . 81 : 69–83. doi : 10.1007/s10994-010-5199- . S2CID 17497168 . ^ . Biggio, . Fumera, and . Roli. " Evade hard multiple classifier systems Archived 2015-01-15 at the Wayback Machine ". In . Okun and . Valentini, editors, Supervised and Unsupervised Ensemble Methods and Their Applications, volume 245 of Studies in Computational Intelligence, pages 15–38. Springer Berlin / Heidelberg, 2009. ^ . . . Rubinstein, . . Bartlett, . Huang, and . Taft. " Learning in  large function space: Privacy- preserving mechanisms for svm learning ". Journal of Privacy and Confidentiality, ():65–100, 2012. ^ . Kantarcioglu, . Xi, . Clifton. "Classifier Evaluation and Attribute Selection against Active Adversaries" . Data Min. Knowl. Discov., 22:291–335, January 2011. ^ Chivukula, Aneesh; Yang, Xinghao; Liu, Wei; Zhu, Tianqing; Zhou, Wanlei (2020). "Game Theoretical Adversarial Deep Learning with Variational Adversaries" . IEEE Transactions on Knowledge and Data Engineering . 33 (11): 3568–3581. doi : 10.1109/TKDE.2020.2972320 . hdl : 10453/145751 . ISSN 1558-2191 . S2CID 213845560 . ^ Chivukula, Aneesh Sreevallabh; Liu, Wei (2019). "Adversarial Deep Learning Models with Multiple Adversaries" . IEEE Transactions on Knowledge and Data Engineering . 31 (): 1066–1079. doi : 10.1109/TKDE.2018.2851247 . hdl : 10453/136227 . ISSN 1558-2191 . S2CID 67024195 . ^ "TrojAI" . www.iarpa.gov . Retrieved 2020-10-14 . ^ Athalye, Anish; Carlini, Nicholas; Wagner, David (2018-02-01). "Obfuscated Gradients Give  False Sense of Security: Circumventing Defenses to Adversarial Example". arXiv : 1802.00420v1 [ cs.LG ]. ^ He, Warren; Wei, James; Chen, Xinyun; Carlini, Nicholas; Song, Dawn (2017-06-15). "Adversarial Example Defenses: Ensembles of Weak Defenses are not Strong". arXiv : 1706.04701 [ cs.LG ]. External links [ edit ] MITRE ATLAS: Adversarial Threat Landscape for Artificial-Intelligence Systems NIST 8269 Draft:  Taxonomy and Terminology of Adversarial Machine Learning NIPS 2007 Workshop on Machine Learning in Adversarial Environments for Computer Security AlfaSVMLib Archived 2020-09-24 at the Wayback Machine – Adversarial Label Flip Attacks against Support Vector Machines Laskov, Pavel; Lippmann, Richard (2010). "Machine learning in adversarial environments". Machine Learning . 81 (): 115–119. doi : 10.1007/s10994-010-5207- . S2CID 12567278 . Dagstuhl Perspectives Workshop on " Machine Learning Methods for Computer Security " Workshop on Artificial Intelligence and Security , (AISec) Series    Differentiable computing General Differentiable programming Information geometry Statistical manifold Automatic differentiation Neuromorphic engineering Pattern recognition Tensor calculus Computational learning theory Inductive bias Concepts Gradient descent SGD Clustering Regression Overfitting Hallucination Adversary Attention Convolution Loss functions Backpropagation Batchnorm Activation Softmax Sigmoid Rectifier Regularization Datasets Augmentation Diffusion Autoregression Applications Machine learning In-context learning Artificial neural network Deep learning Scientific computing Artificial Intelligence Language model Large language model Hardware IPU TPU VPU Memristor SpiNNaker Software libraries TensorFlow PyTorch Keras Theano JAX Flux.jl MindSpore Implementations Audio–visual AlexNet WaveNet Human image synthesis HWR OCR Speech synthesis Speech recognition Facial recognition AlphaFold Text-to-image models DALL- Midjourney Stable Diffusion Text-to-video models Sora VideoPoet Whisper Verbal Word2vec Seq2seq BERT Gemini LaMDA Bard NMT Project Debater IBM Watson IBM Watsonx Granite GPT- GPT- GPT- GPT- ChatGPT GPT- Chinchilla AI PaLM BLOOM LLaMA PanGu- Decisional AlphaGo AlphaZero -learning SARSA OpenAI Five Self-driving car MuZero Action selection Auto-GPT Robot control People Yoshua Bengio Alex Graves Ian Goodfellow Stephen Grossberg Demis Hassabis Geoffrey Hinton Yann LeCun Fei-Fei Li Andrew Ng Jürgen Schmidhuber David Silver Ilya Sutskever Organizations Anthropic EleutherAI Google DeepMind Hugging Face OpenAI Meta AI Mila MIT CSAIL Huawei Architectures Neural Turing machine Differentiable neural computer Transformer Recurrent neural network (RNN) Long short-term memory (LSTM) Gated recurrent unit (GRU) Echo state network Multilayer perceptron (MLP) Convolutional neural network Residual neural network Mamba Autoencoder Variational autoencoder (VAE) Generative adversarial network (GAN) Graph neural network Portals Computer programming Technology Categories Artificial neural networks Machine learning Retrieved from " https://en.wikipedia.org//index.php?title=Adversarial_machine_learning&oldid=1240906035 " Categories : Machine learning Computer security AI safety Hidden categories: All articles with dead external links Articles with dead external links from February 2022 Articles with permanently dead external links Webarchive template wayback links Articles with short description Short description is different from Wikidata Read more ## Ian Goodfellow Toggle the table of contents Ian Goodfellow 16 languages Afrikaans العربية Deutsch فارسی Français Galego 한국어 Italiano עברית مصرى Nederlands 日本語 Türkçe Українська Tiếng Việt 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Special pages Permanent link Page information Cite this page Get shortened URL Download QR code Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Appearance move to sidebar hide From Wikipedia, the free encyclopedia American computer scientist Ian Goodfellow Born November 18th, 1987 [  ] Nationality American Alma mater Stanford University Université de Montréal Known for Generative adversarial networks , Adversarial examples Scientific career Fields Computer science Institutions Apple Inc. Google Brain OpenAI DeepMind Google DeepMind Thesis Deep Learning of Representations and its Application to Computer Vision (2014) Doctoral advisor Yoshua Bengio Aaron Courville Website www .iangoodfellow .com Ian . Goodfellow (born 1987 [  ] ) is an American computer scientist , engineer , and executive , most noted for his work on artificial neural networks and deep learning . He was previously employed as  research scientist at Google Brain and director of machine learning at Apple and has made several important contributions to the field of deep learning including the invention of the generative adversarial network (GAN). Goodfellow co-wrote, as the first author, the textbook Deep Learning (2016) [  ] and wrote the chapter on deep learning in the authoritative textbook of the field of artificial intelligence, Artificial Intelligence:  Modern Approach [  ] [  ] (used in more than ,500 universities in 135 countries). [  ] . He is currently  Research Scientist at Deepmind. [  ] Education [ edit ] Goodfellow obtained his .. and .. in computer science from Stanford University under the supervision of Andrew Ng (co-founder and head of Google Brain ), and his Ph.. in machine learning from the Université de Montréal in April 2014, under the supervision of Yoshua Bengio and Aaron Courville. [  ] [  ] Goodfellow' thesis is titled Deep learning of representations and its application to computer vision . [  ] [ 10 ] Career [ edit ] After graduation, Goodfellow joined Google as part of the Google Brain research team. [ 11 ] In March 2016 he left Google to join the newly founded OpenAI research laboratory. [ 12 ] Barely 11 months later, in March 2017, Goodfellow returned to Google Research [ 13 ] but left again in 2019. [ 14 ] In 2019 Goodfellow joined Apple as director of machine learning in the Special Projects Group. [ 14 ] He resigned from Apple in April 2022 to protest Apple' plan to require in-person work for its employees. [ 15 ] Goodfellow then joined DeepMind as  research scientist. [ 16 ] Research [ edit ] Goodfellow is best known for inventing generative adversarial networks (GAN), using deep learning to generate images. This approach uses two neural networks to competitively improve an image' quality.  “generator” network creates  synthetic image based on an initial set of images such as  collection of faces.  “discriminator” network tries to detect whether or not the generator' output is real or fake. Then the generate-detect cycle is repeated. For each iteration, the generator and the discriminator use the other' feedback to improve or detect the generated images, until the discriminator can no longer distinguish between the fakes generated by its opponent and the real thing. The ability to create high quality generated imagery has increased rapidly. Unfortunately, so has its malicious use, to create deepfakes and generate video-based disinformation . [ 17 ] [ 18 ] At Google, Goodfellow developed  system enabling Google Maps to automatically transcribe addresses from photos taken by Street View cars [ 19 ] [ 20 ] and demonstrated security vulnerabilities of machine learning systems. [ 21 ] [ 22 ] Recognition [ edit ] In 2017, Goodfellow was cited in MIT Technology Review ' 35 Innovators Under 35. [ 23 ] In 2019, he was included in Foreign Policy ' list of 100 Global Thinkers. [ 24 ] References [ edit ] ^   "Katalog der Deutschen Nationalbibliothek" . portal.dnb.de . ^ Goodfellow, Ian; Bengio, Yoshua; Courville, Aaron (2016). Deep Learning . Cambridge, Massachusetts: MIT Press. ^ "Artificial Intelligence:  Modern Approach - The Definitive AI Book" . How to Learn Machine Learning . 2020 . Retrieved 19 December 2022 . ^ Goodfellow, Ian (28 April 2020). "Chapter 21: Deep Learning". Artificial intelligence :  modern approach (PDF) . By Russell, Stuart .; Norvig, Peter (Fourth ed.). Hoboken, NJ: Pearson. ISBN 978-0134610993 . ^ "Nobel Week Dialogue" . NobelPrize.org . Retrieved 19 December 2022 . ^ Wayt, Theo. "Apple engineer who quit over return-to-office policy joins Google" . New York Post . New York Post . Retrieved 31 August 2024 . ^ "Top 12 AI Leaders and Researchers you Should Know in 2022" . Great Learning Blog: Free Resources what Matters to shape your Career! .  May 2022 . Retrieved 19 December 2022 . ^ La Barbera, Steve (27 March 2019). "Montreal' Yoshua Bengio Honored with the 'Nobel Prize' of Computing" . Montreal in Technology . Archived from the original on 19 December 2022 . Retrieved 19 December 2022 . ^ Goodfellow, Ian (18 February 2015). Deep learning of representations and its application to computer vision (Thesis). hdl : 1866/11674 . ^ "Ian Goodfellow PhD Defense Presentation" . Universite de Montreal.  September 2014 . Retrieved 27 October 2020 . ^ Metz, Cade (15 February 2022). Genius Makers: The Mavericks Who Brought AI to Google, Facebook, and the World . Penguin. pp. 203–213. ISBN 978--5247-4269- . Retrieved 19 December 2022 . ^ Metz, Cade (27 April 2016). "Inside OpenAI, Elon Musk' Wild Plan to Set Artificial Intelligence Free" . Wired . Retrieved 31 July 2016 . ^ Metz, Cade (19 April 2018). ".. Researchers Are Making More Than $ Million, Even at  Nonprofit" . The New York Times . Retrieved 19 December 2022 . ^   Novet, Jordan ( April 2019). "Apple hires AI expert Ian Goodfellow from Google" . www.cnbc.com . Retrieved  April 2019 . ^ "Apple' Director of Machine Learning Resigns Due to Return to Office Work" . MacRumors .  May 2022 . Retrieved  May 2022 . ^ Greene, Tristan (19 May 2022). "Losing Ian Goodfellow to DeepMind is the dumbest thing Apple' ever done" . TNW | Neural . Retrieved 11 June 2022 . ^ Waldrop, . Mitchell (16 March 2020). "Synthetic media: The real trouble with deepfakes" . Knowable Magazine . Annual Reviews. doi : 10.1146/knowable-031320- . S2CID 215882738 . Retrieved 19 December 2022 . ^ Goodfellow, Ian .; Pouget-Abadie, Jean; Mirza, Mehdi; Xu, Bing; Warde-Farley, David; Ozair, Sherjil; Courville, Aaron; Bengio, Yoshua (2014). "Generative Adversarial Networks". arXiv : 1406.2661 [ stat.ML ]. ^ "How Google Cracked House Number Identification in Street View" . MIT Technology Review .  January 2014 . Retrieved 31 July 2016 . ^ Ibarz, Julian; Banerjee, Sujoy ( May 2017). "Updating Google Maps with Deep Learning and Street View" . Research Blog . Retrieved  May 2017 . ^ Gershgorn, Dave (30 March 2016). "Fooling the Machine" . Popular Science . Retrieved 31 July 2016 . ^ Gershgorn, Dave (27 July 2016). "Researchers Have Successfully Tricked .. Into Seeing The Wrong Things" . Popular Science . Retrieved 31 July 2016 . ^ Knight, Will (16 August 2017). "Ian Goodfellow" . MIT Technology Review . ^ " decade of Global Thinkers" . Foreign Policy . 2019.    Differentiable computing General Differentiable programming Information geometry Statistical manifold Automatic differentiation Neuromorphic engineering Pattern recognition Tensor calculus Computational learning theory Inductive bias Concepts Gradient descent SGD Clustering Regression Overfitting Hallucination Adversary Attention Convolution Loss functions Backpropagation Batchnorm Activation Softmax Sigmoid Rectifier Regularization Datasets Augmentation Diffusion Autoregression Applications Machine learning In-context learning Artificial neural network Deep learning Scientific computing Artificial Intelligence Language model Large language model Hardware IPU TPU VPU Memristor SpiNNaker Software libraries TensorFlow PyTorch Keras Theano JAX Flux.jl MindSpore Implementations Audio–visual AlexNet WaveNet Human image synthesis HWR OCR Speech synthesis Speech recognition Facial recognition AlphaFold Text-to-image models DALL- Midjourney Stable Diffusion Text-to-video models Sora VideoPoet Whisper Verbal Word2vec Seq2seq BERT Gemini LaMDA Bard NMT Project Debater IBM Watson IBM Watsonx Granite GPT- GPT- GPT- GPT- ChatGPT GPT- Chinchilla AI PaLM BLOOM LLaMA PanGu- Decisional AlphaGo AlphaZero -learning SARSA OpenAI Five Self-driving car MuZero Action selection Auto-GPT Robot control People Yoshua Bengio Alex Graves Ian Goodfellow Stephen Grossberg Demis Hassabis Geoffrey Hinton Yann LeCun Fei-Fei Li Andrew Ng Jürgen Schmidhuber David Silver Ilya Sutskever Organizations Anthropic EleutherAI Google DeepMind Hugging Face OpenAI Meta AI Mila MIT CSAIL Huawei Architectures Neural Turing machine Differentiable neural computer Transformer Recurrent neural network (RNN) Long short-term memory (LSTM) Gated recurrent unit (GRU) Echo state network Multilayer perceptron (MLP) Convolutional neural network Residual neural network Mamba Autoencoder Variational autoencoder (VAE) Generative adversarial network (GAN) Graph neural network Portals Computer programming Technology Categories Artificial neural networks Machine learning Authority control databases International VIAF WorldCat National Germany Israel United States Czech Republic Poland Academics Association for Computing Machinery DBLP Google Scholar MathSciNet Mathematics Genealogy Project ORCID Scopus Other IdRef Retrieved from " https://en.wikipedia.org//index.php?title=Ian_Goodfellow&oldid=1243274511 " Categories : American computer scientists American artificial intelligence researchers Google employees Living people Machine learning researchers Scientists from San Francisco Stanford University School of Engineering alumni Université de Montréal alumni Apple Inc. employees 1987 births Hidden categories: Articles with short description Short description matches Wikidata Use dmy dates from December 2022 Articles with hCards Place of birth missing (living people) Read more ## Markov kernel Toggle the table of contents Markov kernel  language Català Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Special pages Permanent link Page information Cite this page Get shortened URL Download QR code Wikidata item Print/export Download as PDF Printable version Appearance move to sidebar hide From Wikipedia, the free encyclopedia Concept in probability theory In probability theory ,  Markov kernel (also known as  stochastic kernel or probability kernel ) is  map that in the general theory of Markov processes plays the role that the transition matrix does in the theory of Markov processes with  finite state space . [  ] Formal definition [ edit ] Let (  ,  ) {\displaystyle (,{\mathcal {}})} and (  ,  ) {\displaystyle (,{\mathcal {}})} be measurable spaces .  Markov kernel with source (  ,  ) {\displaystyle (,{\mathcal {}})} and target (  ,  ) {\displaystyle (,{\mathcal {}})} , sometimes written as  : (  ,  ) → (  ,  ) {\displaystyle \kappa :(,{\mathcal {}})\to (,{\mathcal {}})} , is  function  :  ×  → [  ,  ] {\displaystyle \kappa :{\mathcal {}}\times \to [,]} with the following properties: For every (fixed)   ∈  {\displaystyle B_{}\in {\mathcal {}}} , the map  ↦  (   ,  ) {\displaystyle \mapsto \kappa (B_{},)} is  {\displaystyle {\mathcal {}}} - measurable For every (fixed)   ∈  {\displaystyle x_{}\in } , the map  ↦  (  ,   ) {\displaystyle \mapsto \kappa (,x_{})} is  probability measure on (  ,  ) {\displaystyle (,{\mathcal {}})} In other words it associates to each point  ∈  {\displaystyle \in }  probability measure  (   |  ) :  ↦  (  ,  ) {\displaystyle \kappa (dy|):\mapsto \kappa (,)} on (  ,  ) {\displaystyle (,{\mathcal {}})} such that, for every measurable set  ∈  {\displaystyle \in {\mathcal {}}} , the map  ↦  (  ,  ) {\displaystyle \mapsto \kappa (,)} is measurable with respect to the  {\displaystyle \sigma } -algebra  {\displaystyle {\mathcal {}}} . [  ] Examples [ edit ] Simple random walk on the integers [ edit ] Take  =  =  {\displaystyle ==\mathbb {} } , and  =  =  (  ) {\displaystyle {\mathcal {}}={\mathcal {}}={\mathcal {}}(\mathbb {} )} (the power set of  {\displaystyle \mathbb {} } ). Then  Markov kernel is fully determined by the probability it assigns to singletons {  } ,  ∈  =  {\displaystyle \{\},\,\in =\mathbb {} } for each  ∈  =  {\displaystyle \in =\mathbb {} } :  (  |  ) = ∑  ∈   ( {  } |  ) , ∀  ∈  , ∀  ∈  {\displaystyle \kappa (|)=\sum {\in }\kappa (\{\}|),\qquad \forall \in \mathbb {} ,\,\forall \in {\mathcal {}}} . Now the random walk  {\displaystyle \kappa } that goes to the right with probability  {\displaystyle } and to the left with probability  −  {\displaystyle -} is defined by  ( {  } |  ) =    ,  +  + (  −  )   ,  −  , ∀  ,  ∈  {\displaystyle \kappa (\{\}|)=\delta {,+}+(-)\delta {,-},\quad \forall ,\in \mathbb {} } where  {\displaystyle \delta } is the Kronecker delta . The transition probabilities  (  |  ) =  ( {  } |  ) {\displaystyle (|)=\kappa (\{\}|)} for the random walk are equivalent to the Markov kernel. General Markov processes with countable state space [ edit ] More generally take  {\displaystyle } and  {\displaystyle } both countable and  =  (  ) ,  =  (  ) {\displaystyle {\mathcal {}}={\mathcal {}}(),\ {\mathcal {}}={\mathcal {}}()} . Again  Markov kernel is defined by the probability it assigns to singleton sets for each  ∈  {\displaystyle \in }  (  |  ) = ∑  ∈   ( {  } |  ) , ∀  ∈  , ∀  ∈  {\displaystyle \kappa (|)=\sum {\in }\kappa (\{\}|),\qquad \forall \in ,\,\forall \in {\mathcal {}}} , We define  Markov process by defining  transition probability  (  |  ) =    {\displaystyle (|)=K_{ji}} where the numbers    {\displaystyle K_{ji}} define  (countable) stochastic matrix (    ) {\displaystyle (K_{ji})} ..    ≥  , ∀ (  ,  ) ∈  ×  , ∑  ∈     =  , ∀  ∈  . {\displaystyle {\begin{aligned}K_{ji}&\geq ,\qquad &\forall (,)\in \times ,\\\sum {\in }K_{ji}&=,\qquad &\forall \in .\\\end{aligned}}} We then define  ( {  } |  ) =    =  (  |  ) , ∀  ∈  , ∀  ∈  {\displaystyle \kappa (\{\}|)=K_{ji}=(|),\qquad \forall \in ,\quad \forall \in {\mathcal {}}} . Again the transition probability, the stochastic matrix and the Markov kernel are equivalent reformulations. Markov kernel defined by  kernel function and  measure [ edit ] Let  {\displaystyle \nu } be  measure on (  ,  ) {\displaystyle (,{\mathcal {}})} , and  :  ×  → [  , ∞ ] {\displaystyle :\times \to [,\infty ]}  measurable function with respect to the product  {\displaystyle \sigma } -algebra  ⊗  {\displaystyle {\mathcal {}}\otimes {\mathcal {}}} such that ∫   (  ,  )  (   ) =  , ∀  ∈  {\displaystyle \int {}(,)\nu (\mathrm {} )=,\qquad \forall \in } , then  (   |  ) =  (  ,  )  (   ) {\displaystyle \kappa (dy|)=(,)\nu (dy)} .. the mapping {  :  ×  → [  ,  ]  (  |  ) = ∫   (  ,  )  (   ) {\displaystyle {\begin{cases}\kappa :{\mathcal {}}\times \to [,]\\\kappa (|)=\int {}(,)\nu (\mathrm {} )\end{cases}}} defines  Markov kernel. [  ] This example generalises the countable Markov process example where  {\displaystyle \nu } was the counting measure . Moreover it encompasses other important examples such as the convolution kernels, in particular the Markov kernels defined by the heat equation. The latter example includes the Gaussian kernel on  =  =  {\displaystyle ==\mathbb {} } with  (   ) =   {\displaystyle \nu (dx)=dx} standard Lebesgue measure and   (  ,  ) =      − (  −  )  / (    ) {\displaystyle k_{}(,)={\frac {}{{\sqrt {\pi }}}}^{-(-)^{}/(2t^{})}} . Measurable functions [ edit ] Take (  ,  ) {\displaystyle (,{\mathcal {}})} and (  ,  ) {\displaystyle (,{\mathcal {}})} arbitrary measurable spaces, and let  :  →  {\displaystyle :\to } be  measurable function. Now define  (   |  ) =   (  ) (   ) {\displaystyle \kappa (dy|)=\delta {()}(dy)} ..  (  |  ) =   (  (  ) ) =   −  (  ) (  ) = {  if  (  ) ∈   otherwise {\displaystyle \kappa (|)=\mathbf {} {}(())=\mathbf {} {^{-}()}()={\begin{cases}&{\text{if }}()\in \\&{\text{otherwise}}\end{cases}}} for all  ∈  {\displaystyle \in {\mathcal {}}} . Note that the indicator function   −  (  ) {\displaystyle \mathbf {} {^{-}()}} is  {\displaystyle {\mathcal {}}} -measurable for all  ∈  {\displaystyle \in {\mathcal {}}} iff  {\displaystyle } is measurable. This example allows us to think of  Markov kernel as  generalised function with  (in general) random rather than certain value. That is, it is  multivalued function where the values are not equally weighted. Galton–Watson process [ edit ] As  less obvious example, take  =  ,  =  (  ) {\displaystyle =\mathbb {} ,{\mathcal {}}={\mathcal {}}(\mathbb {} )} , and (  ,  ) {\displaystyle (,{\mathcal {}})} the real numbers  {\displaystyle \mathbb {} } with the standard sigma algebra of Borel sets . Then  (  |  ) = {   (  )  =  Pr (   + ⋯ +   ∈  )  ≠  {\displaystyle \kappa (|)={\begin{cases}\mathbf {} {}()&=\\\Pr(\xi {}+\cdots +\xi {}\in )&\neq \\\end{cases}}} where  {\displaystyle } is the number of element at the state  {\displaystyle } ,   {\displaystyle \xi {}} are ... random variables (usually with mean ) and where   {\displaystyle \mathbf {} {}} is the indicator function. For the simple case of coin flips this models the different levels of  Galton board . Composition of Markov Kernels [ edit ] Given measurable spaces (  ,  ) {\displaystyle (,{\mathcal {}})} , (  ,  ) {\displaystyle (,{\mathcal {}})} we consider  Markov kernel  :  ×  → [  ,  ] {\displaystyle \kappa :{\mathcal {}}\times \to [,]} as  morphism  :  →  {\displaystyle \kappa :\to } . Intuitively, rather than assigning to each  ∈  {\displaystyle \in }  sharply defined point  ∈  {\displaystyle \in } the kernel assigns  "fuzzy" point in  {\displaystyle } which is only known with some level of uncertainty, much like actual physical measurements. If we have  third measurable space (  ,  ) {\displaystyle (,{\mathcal {}})} , and probability kernels  :  →  {\displaystyle \kappa :\to } and  :  →  {\displaystyle \lambda :\to } , we can define  composition  ∘  :  →  {\displaystyle \lambda \circ \kappa :\to } by the Chapman-Kolmogorov equation (  ∘  ) (   |  ) = ∫   (   |  )  (   |  ) {\displaystyle (\lambda \circ \kappa )(dz|)=\int {}\lambda (dz|)\kappa (dy|)} . The composition is associative by the Monotone Convergence Theorem and the identity function considered as  Markov kernel (.. the delta measure   (   ′ |  ) =   (   ′ ) {\displaystyle \kappa {}(dx'|)=\delta {}(dx')} ) is the unit for this composition. This composition defines the structure of  category on the measurable spaces with Markov kernels as morphisms, first defined by Lawvere, [  ] the category of Markov kernels . Probability Space defined by Probability Distribution and  Markov Kernel [ edit ]  composition of  probability space (  ,  ,   ) {\displaystyle (,{\mathcal {}},P_{})} and  probability kernel  : (  ,  ) → (  ,  ) {\displaystyle \kappa :(,{\mathcal {}})\to (,{\mathcal {}})} defines  probability space (  ,  ,   =  ∘   ) {\displaystyle (,{\mathcal {}},P_{}=\kappa \circ P_{})} , where the probability measure is given by   (  ) = ∫  ∫   (   |  )   (   ) = ∫   (  |  )   (   ) =     (  | ⋅ ) . {\displaystyle P_{}()=\int {}\int {}\kappa (dy|)P_{}(dx)=\int {}\kappa (|)P_{}(dx)=\mathbb {} {P_{}}\kappa (|\cdot ).} Properties [ edit ] Semidirect product [ edit ] Let (  ,  ,  ) {\displaystyle (,{\mathcal {}},)} be  probability space and  {\displaystyle \kappa }  Markov kernel from (  ,  ) {\displaystyle (,{\mathcal {}})} to some (  ,  ) {\displaystyle (,{\mathcal {}})} . Then there exists  unique measure  {\displaystyle } on (  ×  ,  ⊗  ) {\displaystyle (\times ,{\mathcal {}}\otimes {\mathcal {}})} , such that:  (  ×  ) = ∫   (  |  )  (   ) , ∀  ∈  , ∀  ∈  . {\displaystyle (\times )=\int {}\kappa (|)\,(dx),\quad \forall \in {\mathcal {}},\quad \forall \in {\mathcal {}}.} Regular conditional distribution [ edit ] Let (  ,  ) {\displaystyle (,)} be  Borel space ,  {\displaystyle }  (  ,  ) {\displaystyle (,)} -valued random variable on the measure space (  ,  ,  ) {\displaystyle (\Omega ,{\mathcal {}},)} and  ⊆  {\displaystyle {\mathcal {}}\subseteq {\mathcal {}}}  sub-  {\displaystyle \sigma } -algebra. Then there exists  Markov kernel  {\displaystyle \kappa } from (  ,  ) {\displaystyle (\Omega ,{\mathcal {}})} to (  ,  ) {\displaystyle (,)} , such that  ( ⋅ ,  ) {\displaystyle \kappa (\cdot ,)} is  version of the conditional expectation  [  {  ∈  } ∣  ] {\displaystyle \mathbb {} [\mathbf {} {\{\in \}}\mid {\mathcal {}}]} for every  ∈  {\displaystyle \in } , ..  (  ∈  ∣  ) =  [  {  ∈  } ∣  ] =  ( ⋅ ,  ) ,  -.. ∀  ∈  . {\displaystyle (\in \mid {\mathcal {}})=\mathbb {} \left[\mathbf {} {\{\in \}}\mid {\mathcal {}}\right]=\kappa (\cdot ,),\qquad {\text{-..}}\,\,\forall \in {\mathcal {}}.} It is called regular conditional distribution of  {\displaystyle } given  {\displaystyle {\mathcal {}}} and is not uniquely defined. Generalizations [ edit ] Transition kernels generalize Markov kernels in the sense that for all  ∈  {\displaystyle \in } , the map  ↦  (  |  ) {\displaystyle \mapsto \kappa (|)} can be any type of (non negative) measure, not necessarily  probability measure. External links [ edit ] Markov kernel in nLab . References [ edit ] ^ Reiss, . . (1993).  Course on Point Processes . Springer Series in Statistics. doi : 10.1007/978--4613-9308- . ISBN 978--4613-9310- . ^ Klenke, Achim (2014). Probability Theory:  Comprehensive Course . Universitext ( ed.). Springer. . 180. doi : 10.1007/978--4471-5361- . ISBN 978--4471-5360- . ^ Erhan, Cinlar (2011). Probability and Stochastics . New York: Springer. pp. 37–38. ISBN 978--387-87858- . ^ . . Lawvere (1962). "The Category of Probabilistic Mappings" (PDF) . Bauer, Heinz (1996), Probability Theory , de Gruyter, ISBN -11-013935- §36. Kernels and semigroups of kernels See also [ edit ] Category of Markov kernels Retrieved from " https://en.wikipedia.org//index.php?title=Markov_kernel&oldid=1236950192 " Category : Markov processes Hidden categories: Articles with short description Short description is different from Wikidata Read more ## Generative Adversarial Network (GAN) Open In App Share Your Experiences Deep Learning Tutorial Introduction to Deep Learning Introduction to Deep Learning Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning Basic Neural Network Difference between ANN and BNN Single Layer Perceptron in TensorFlow Multi-Layer Perceptron Learning in Tensorflow Deep Neural net with forward and back propagation from scratch - Python Understanding Multi-Layer Feed Forward Networks List of Deep Learning Layers Activation Functions Activation Functions Types Of Activation Function in ANN Activation Functions in Pytorch Understanding Activation Functions in Depth Artificial Neural Network Artificial Neural Networks and its Applications Gradient Descent Optimization in Tensorflow Choose Optimal Number of Epochs to Train  Neural Network in Keras Classification Python | Classify Handwritten Digits with Tensorflow Train  Deep Learning Model With Pytorch Regression Linear Regression using PyTorch Linear Regression Using Tensorflow Hyperparameter tuning Hyperparameter tuning Introduction to Convolution Neural Network Introduction to Convolution Neural Network Digital Image Processing Basics Difference between Image Processing and Computer Vision CNN | Introduction to Pooling Layer CIFAR-10 Image Classification in TensorFlow Implementation of  CNN based Image Classifier using PyTorch Convolutional Neural Network (CNN) Architectures Object Detection vs Object Recognition vs Image Segmentation YOLO v2 - Object Detection Recurrent Neural Network Natural Language Processing (NLP) Tutorial Introduction to NLTK: Tokenization, Stemming, Lemmatization, POS Tagging Word Embeddings in NLP Introduction to Recurrent Neural Network Recurrent Neural Networks Explanation Sentiment Analysis with an Recurrent Neural Networks (RNN) Short term Memory What is LSTM - Long Short Term Memory? Long Short Term Memory Networks Explanation LSTM - Derivation of Back propagation through time Text Generation using Recurrent Long Short Term Memory Network Gated Recurrent Unit Networks Gated Recurrent Unit Networks ML | Text Generation using Gated Recurrent Unit Networks Generative Learning Autoencoders -Machine Learning How Autoencoders works ? Variational AutoEncoders Contractive Autoencoder (CAE) ML | AutoEncoder with TensorFlow . Implementing an Autoencoder in PyTorch Generative adversarial networks Basics of Generative Adversarial Networks (GANs) Generative Adversarial Network (GAN) Use Cases of Generative Adversarial Networks Building  Generative Adversarial Network using Keras Cycle Generative Adversarial Network (CycleGAN) StyleGAN - Style Generative Adversarial Networks Reinforcement Learning Understanding Reinforcement Learning in-depth Introduction to Thompson Sampling | Reinforcement Learning Markov Decision Process Bellman Equation Meta-Learning in Machine Learning -Learning in Python -Learning ML | Reinforcement Learning Algorithm : Python Implementation using -learning Deep  Learning Deep -Learning Implementing Deep -Learning using Tensorflow AI Driven Snake Game using Deep  Learning Deep Learning Interview Questions Machine Learning & Data Science Course Generative Adversarial Network (GAN) Last Updated : 09 Aug, 2024 Comments Improve Summarize Suggest changes Like Article Like Save Share Report Follow GAN (Generative Adversarial Network) represents  cutting-edge approach to generative modeling within deep learning, often leveraging architectures like convolutional neural networks . The goal of generative modeling is to autonomously identify patterns in input data, enabling the model to produce new examples that feasibly resemble the original dataset. This article covers everything you need to know about GAN, the Architecture of GAN, the Workings of GAN, and types of GAN Models, and so on. Table of Content What is  Generative Adversarial Network? Types of GANs Architecture of GANs How does  GAN work? Implementation of  GAN Application Of Generative Adversarial Networks (GANs) Advantages of GAN Disadvantages of GAN GAN(Generative Adversarial Network)- FAQs What is  Generative Adversarial Network? Generative Adversarial Networks (GANs) are  powerful class of neural networks that are used for an unsupervised learning . GANs are made up of two neural networks ,  discriminator and  generator. They use adversarial training to produce artificial data that is identical to actual data. The Generator attempts to fool the Discriminator, which is tasked with accurately distinguishing between produced and genuine data, by producing random noise samples. Realistic, high-quality samples are produced as  result of this competitive interaction, which drives both networks toward advancement. GANs are proving to be highly versatile artificial intelligence tools, as evidenced by their extensive use in image synthesis, style transfer, and text-to-image synthesis. They have also revolutionized generative modeling. Through adversarial training, these models engage in  competitive interplay until the generator becomes adept at creating realistic samples, fooling the discriminator approximately half the time. Generative Adversarial Networks (GANs) can be broken down into three parts: Generative: To learn  generative model, which describes how data is generated in terms of  probabilistic model. Adversarial: The word adversarial refers to setting one thing up against another. This means that, in the context of GANs, the generative result is compared with the actual images in the data set.  mechanism known as  discriminator is used to apply  model that attempts to distinguish between real and fake images. Networks: Use deep neural networks as artificial intelligence (AI) algorithms for training purposes. Types of GANs Vanilla GAN: This is the simplest type of GAN. Here, the Generator and the Discriminator are simple  basic multi-layer perceptrons . In vanilla GAN, the algorithm is really simple, it tries to optimize the mathematical equation using stochastic gradient descent. Conditional GAN (CGAN): CGAN can be described as  deep learning method in which some conditional parameters are put into place . In CGAN, an additional parameter ‘’ is added to the Generator for generating the corresponding data. Labels are also put into the input to the Discriminator in order for the Discriminator to help distinguish the real data from the fake generated data. Deep Convolutional GAN (DCGAN): DCGAN is one of the most popular and also the most successful implementations of GAN. It is composed of ConvNets in place of multi-layer perceptrons . The ConvNets are implemented without max pooling, which is in fact replaced by convolutional stride. Also, the layers are not fully connected. Laplacian Pyramid GAN (LAPGAN): The Laplacian pyramid is  linear invertible image representation consisting of  set of band-pass images, spaced an octave apart, plus  low-frequency residual. This approach uses multiple numbers of Generator and Discriminator networks and different levels of the Laplacian Pyramid. This approach is mainly used because it produces very high-quality images. The image is down-sampled at first at each layer of the pyramid and then it is again up-scaled at each layer in  backward pass where the image acquires some noise from the Conditional GAN at these layers until it reaches its original size. Super Resolution GAN (SRGAN): SRGAN as the name suggests is  way of designing  GAN in which  deep neural network is used along with an adversarial network in order to produce higher-resolution images. This type of GAN is particularly useful in optimally up-scaling native low-resolution images to enhance their details minimizing errors while doing so. Architecture of GANs  Generative Adversarial Network (GAN) is composed of two primary parts, which are the Generator and the Discriminator. Generator Model  key element responsible for creating fresh, accurate data in  Generative Adversarial Network (GAN) is the generator model. The generator takes random noise as input and converts it into complex data samples, such text or images. It is commonly depicted as  deep neural network. The training data’ underlying distribution is captured by layers of learnable parameters in its design through training. The generator adjusts its output to produce samples that closely mimic real data as it is being trained by using backpropagation to fine-tune its parameters. The generator’ ability to generate high-quality, varied samples that can fool the discriminator is what makes it successful. Generator Loss The objective of the generator in  GAN is to produce synthetic samples that are realistic enough to fool the discriminator. The generator achieves this by minimizing its loss function [Tex]J_G[/Tex] ​. The loss is minimized when the log probability is maximized, .., when the discriminator is highly likely to classify the generated samples as real. The following equation is given below: [Tex]J_{} = -\frac{}{} \Sigma^ {=} log ((z_{})) [/Tex] Where, [Tex]J_G[/Tex] measure how well the generator is fooling the discriminator. log [Tex]((z_i) )[/Tex] represents log probability of the discriminator being correct for generated samples. The generator aims to minimize this loss, encouraging the production of samples that the discriminator classifies as real [Tex](log ((z_i))[/Tex] , close to . Discriminator Model An artificial neural network called  discriminator model is used in Generative Adversarial Networks (GANs) to differentiate between generated and actual input. By evaluating input samples and allocating probability of authenticity, the discriminator functions as  binary classifier. Over time, the discriminator learns to differentiate between genuine data from the dataset and artificial samples created by the generator. This allows it to progressively hone its parameters and increase its level of proficiency. Convolutional layers or pertinent structures for other modalities are usually used in its architecture when dealing with picture data. Maximizing the discriminator’ capacity to accurately identify generated samples as fraudulent and real samples as authentic is the aim of the adversarial training procedure. The discriminator grows increasingly discriminating as  result of the generator and discriminator’ interaction, which helps the GAN produce extremely realistic-looking synthetic data overall. Discriminator Loss The discriminator reduces the negative log likelihood of correctly classifying both produced and real samples. This loss incentivizes the discriminator to accurately categorize generated samples as fake and real samples with the following equation: [Tex]J_{} = -\frac{}{} \Sigma_{=}^ log\; (x_{}) – \frac{}{}\Sigma_{=}^ log( – ((z_{})) [/Tex] [Tex]J_D[/Tex] assesses the discriminator’ ability to discern between produced and actual samples. The log likelihood that the discriminator will accurately categorize real data is represented by [Tex]logD(x_i)[/Tex] . The log chance that the discriminator would correctly categorize generated samples as fake is represented by [Tex]log⁡(-((z_i)))[/Tex] . The discriminator aims to reduce this loss by accurately identifying artificial and real samples. MinMax Loss In  Generative Adversarial Network (GAN), the minimax loss formula is provided by: [Tex]min_{}\;max_{}(,) = [\mathbb{}{∼p_{data}}[log\;()] + \mathbb{}{∼p_{}()}[log( – (()))] [/Tex] Where,  is generator network and is  is the discriminator network Actual data samples obtained from the true data distribution [Tex]p_{data}() [/Tex] are represented by . Random noise sampled from  previous distribution [Tex]p_z() [/Tex] (usually  normal or uniform distribution) is represented by . () represents the discriminator’ likelihood of correctly identifying actual data as real. (()) is the likelihood that the discriminator will identify generated data coming from the generator as authentic. How does  GAN work? The steps involved in how  GAN works: Initialization: Two neural networks are created:  Generator () and  Discriminator ().  is tasked with creating new data, like images or text, that closely resembles real data.  acts as  critic, trying to distinguish between real data (from  training dataset) and the data generated by . Generator’ First Move:  takes  random noise vector as input. This noise vector contains random values and acts as the starting point for ’ creation process. Using its internal layers and learned patterns,  transforms the noise vector into  new data sample, like  generated image. Discriminator’ Turn:  receives two kinds of inputs: Real data samples from the training dataset. The data samples generated by  in the previous step. ’ job is to analyze each input and determine whether it’ real data or something  cooked up. It outputs  probability score between  and .  score of  indicates the data is likely real, and  suggests it’ fake. The Learning Process: Now, the adversarial part comes in: If  correctly identifies real data as real (score close to ) and generated data as fake (score close to ), both  and  are rewarded to  small degree. This is because they’re both doing their jobs well. However, the key is to continuously improve. If  consistently identifies everything correctly, it won’ learn much. So, the goal is for  to eventually trick . Generator’ Improvement: When  mistakenly labels ’ creation as real (score close to ), it’  sign that  is on the right track. In this case,  receives  significant positive update, while  receives  penalty for being fooled. This feedback helps  improve its generation process to create more realistic data. Discriminator’ Adaptation: Conversely, if  correctly identifies ’ fake data (score close to ), but  receives no reward,  is further strengthened in its discrimination abilities. This ongoing duel between  and  refines both networks over time. As training progresses,  gets better at generating realistic data, making it harder for  to tell the difference. Ideally,  becomes so adept that  can’ reliably distinguish real from fake data. At this point,  is considered well-trained and can be used to generate new, realistic data samples. Implementation of Generative Adversarial Network (GAN) We will follow and understand the steps to understand how GAN is implemented: Step1 : Importing the required libraries Python import torch import torch.nn as nn import torch.optim as optim import torchvision from torchvision import datasets , transforms import matplotlib.pyplot as plt import numpy as np # Set device device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) For training on the CIFAR-10 image dataset, this PyTorch module creates  Generative Adversarial Network (GAN), switching between generator and discriminator training. Visualization of the generated images occurs every tenth epoch, and the development of the GAN is tracked. Step : Defining  Transform The code uses PyTorch’ transforms to define  simple picture transforms.Compose. It normalizes and transforms photos into tensors. Python # Define  basic transform transform = transforms . Compose ([ transforms . ToTensor (), transforms . Normalize (( . , . , . ), ( . , . , . )) ]) Step : Loading the Dataset  CIFAR-10 dataset is created for training with below code, which also specifies  root directory, turns on train mode, downloads if needed, and applies the specified transform. Subsequently, it generates  32-batch DataLoader and shuffles the training set of data. Python train_dataset = datasets . CIFAR10 ( root = './data' , \ train = True , download = True , transform = transform ) dataloader = torch . utils . data . DataLoader ( train_dataset , \ batch_size = 32 , shuffle = True ) Step : Defining parameters to be used in later processes  Generative Adversarial Network (GAN) is used with specified hyperparameters. The latent space’ dimensionality is represented by latent_dim. lr is the optimizer’ learning rate. The coefficients for the Adam optimizer are beta1 and beta2. To find the total number of training epochs, use num_epochs. Python # Hyperparameters latent_dim = 100 lr = .0002 beta1 = . beta2 = .999 num_epochs = 10 Step : Defining  Utility Class to Build the Generator The generator architecture for  GAN in PyTorch is defined with below code. From nn.Module , the Generator class inherits. It is comprised of  sequential model with Tanh, linear, convolutional, batch normalization, reshaping, and upsampling layers. The neural network synthesizes an image (img) from  latent vector (), which is the generator’ output. The architecture uses  series of learned transformations to turn the initial random noise in the latent space into  meaningful image. Python # Define the generator class Generator ( nn . Module ): def __init__ ( self , latent_dim ): super ( Generator , self ) . __init__ () self . model = nn . Sequential ( nn . Linear ( latent_dim , 128 *  *  ), nn . ReLU (), nn . Unflatten (  , ( 128 ,  ,  )), nn . Upsample ( scale_factor =  ), nn . Conv2d ( 128 , 128 , kernel_size =  , padding =  ), nn . BatchNorm2d ( 128 , momentum = .78 ), nn . ReLU (), nn . Upsample ( scale_factor =  ), nn . Conv2d ( 128 , 64 , kernel_size =  , padding =  ), nn . BatchNorm2d ( 64 , momentum = .78 ), nn . ReLU (), nn . Conv2d ( 64 ,  , kernel_size =  , padding =  ), nn . Tanh () ) def forward ( self ,  ): img = self . model (  ) return img Step : Defining  Utility Class to Build the Discriminator The PyTorch code describes the discriminator architecture for  GAN. The class Discriminator is descended from nn.Module. It is composed of linear layers, batch normalization, dropout , convolutional, LeakyReLU , and sequential layers. An image (img) is the discriminator’ input, and its validity—the probability that the input image is real as opposed to artificial—is its output. Python # Define the discriminator class Discriminator ( nn . Module ): def __init__ ( self ): super ( Discriminator , self ) . __init__ () self . model = nn . Sequential ( nn . Conv2d (  , 32 , kernel_size =  , stride =  , padding =  ), nn . LeakyReLU ( . ), nn . Dropout ( .25 ), nn . Conv2d ( 32 , 64 , kernel_size =  , stride =  , padding =  ), nn . ZeroPad2d ((  ,  ,  ,  )), nn . BatchNorm2d ( 64 , momentum = .82 ), nn . LeakyReLU ( .25 ), nn . Dropout ( .25 ), nn . Conv2d ( 64 , 128 , kernel_size =  , stride =  , padding =  ), nn . BatchNorm2d ( 128 , momentum = .82 ), nn . LeakyReLU ( . ), nn . Dropout ( .25 ), nn . Conv2d ( 128 , 256 , kernel_size =  , stride =  , padding =  ), nn . BatchNorm2d ( 256 , momentum = . ), nn . LeakyReLU ( .25 ), nn . Dropout ( .25 ), nn . Flatten (), nn . Linear ( 256 *  *  ,  ), nn . Sigmoid () ) def forward ( self , img ): validity = self . model ( img ) return validity Step : Building the Generative Adversarial Network The code snippet defines and initializes  discriminator (Discriminator) and  generator (Generator). The designated device (GPU if available) receives both models. Binary Cross Entropy Loss, which is frequently used for GANs, is selected as the loss function (adversarial_loss). For the generator (optimizer_G) and discriminator (optimizer_D), distinct Adam optimizers with predetermined learning rates and betas are also defined. Python # Define the generator and discriminator # Initialize generator and discriminator generator = Generator ( latent_dim ) . to ( device ) discriminator = Discriminator () . to ( device ) # Loss function adversarial_loss = nn . BCELoss () # Optimizers optimizer_G = optim . Adam ( generator . parameters () \ , lr = lr , betas = ( beta1 , beta2 )) optimizer_D = optim . Adam ( discriminator . parameters () \ , lr = lr , betas = ( beta1 , beta2 )) Step : Training the Generative Adversarial Network For  Generative Adversarial Network (GAN), the code implements the training loop. The training data batches are iterated through during each epoch. Whereas the generator (optimizer_G) is trained to generate realistic images that trick the discriminator, the discriminator (optimizer_D) is trained to distinguish between real and phony images. The generator and discriminator’ adversarial losses are computed. Model parameters are updated by means of Adam optimizers and the losses are backpropagated. Discriminator printing and generator losses are used to track progress. For  visual assessment of the training process, generated images are additionally saved and shown every 10 epochs. Python # Training loop for epoch in range ( num_epochs ): for  , batch in enumerate ( dataloader ): # Convert list to tensor real_images = batch [  ] . to ( device ) # Adversarial ground truths valid = torch . ones ( real_images . size (  ),  , device = device ) fake = torch . zeros ( real_images . size (  ),  , device = device ) # Configure input real_images = real_images . to ( device ) # --------------------- # Train Discriminator # --------------------- optimizer_D . zero_grad () # Sample noise as generator input  = torch . randn ( real_images . size (  ), latent_dim , device = device ) # Generate  batch of images fake_images = generator (  ) # Measure discriminator' ability # to classify real and fake images real_loss = adversarial_loss ( discriminator \ ( real_images ), valid ) fake_loss = adversarial_loss ( discriminator \ ( fake_images . detach ()), fake ) d_loss = ( real_loss + fake_loss ) /  # Backward pass and optimize d_loss . backward () optimizer_D . step () # ----------------- # Train Generator # ----------------- optimizer_G . zero_grad () # Generate  batch of images gen_images = generator (  ) # Adversarial loss g_loss = adversarial_loss ( discriminator ( gen_images ), valid ) # Backward pass and optimize g_loss . backward () optimizer_G . step () # --------------------- # Progress Monitoring # --------------------- if (  +  ) % 100 ==  : print (  "Epoch [ { epoch +  } / { num_epochs } ] \ Batch {  +  } / { len ( dataloader ) } "  "Discriminator Loss: { d_loss . item () : .4f } "  "Generator Loss: { g_loss . item () : .4f } " ) # Save generated images for every epoch if ( epoch +  ) % 10 ==  : with torch . no_grad ():  = torch . randn ( 16 , latent_dim , device = device ) generated = generator (  ) . detach () . cpu () grid = torchvision . utils . make_grid ( generated , \ nrow =  , normalize = True ) plt . imshow ( np . transpose ( grid , (  ,  ,  ))) plt . axis ( "off" ) plt . show () Output: Epoch [10/10] Batch 1300/1563 Discriminator Loss: .4473 Generator Loss: .9555 Epoch [10/10] Batch 1400/1563 Discriminator Loss: .6643 Generator Loss: .0215 Epoch [10/10] Batch 1500/1563 Discriminator Loss: .4720 Generator Loss: .5027 GAN Output Application Of Generative Adversarial Networks (GANs) GANs, or Generative Adversarial Networks, have many uses in many different fields. Here are some of the widely recognized uses of GANs: Image Synthesis and Generation : GANs are often used for picture synthesis and generation tasks, They may create fresh, lifelike pictures that mimic training data by learning the distribution that explains the dataset. The development of lifelike avatars, high-resolution photographs, and fresh artwork have all been facilitated by these types of generative networks. Image-to-Image Translation : GANs may be used for problems involving image-to-image translation, where the objective is to convert an input picture from one domain to another while maintaining its key features. GANs may be used, for instance, to change pictures from day to night, transform drawings into realistic images, or change the creative style of an image. Text-to-Image Synthesis : GANs have been used to create visuals from descriptions in text. GANs may produce pictures that translate to  description given  text input, such as  phrase or  caption. This application might have an impact on how realistic visual material is produced using text-based instructions. Data Augmentation : GANs can augment present data and increase the robustness and generalizability of machine-learning models by creating synthetic data samples. Data Generation for Training : GANs can enhance the resolution and quality of low-resolution images. By training on pairs of low-resolution and high-resolution images, GANs can generate high-resolution images from low-resolution inputs, enabling improved image quality in various applications such as medical imaging, satellite imaging, and video enhancement. Advantages of GAN The advantages of the GANs are as follows: Synthetic data generation : GANs can generate new, synthetic data that resembles some known data distribution, which can be useful for data augmentation, anomaly detection, or creative applications. High-quality results : GANs can produce high-quality, photorealistic results in image synthesis, video synthesis, music synthesis, and other tasks. Unsupervised learning : GANs can be trained without labeled data, making them suitable for unsupervised learning tasks, where labeled data is scarce or difficult to obtain. Versatility : GANs can be applied to  wide range of tasks, including image synthesis, text-to-image synthesis, image-to-image translation, anomaly detection , data augmentation , and others. Disadvantages of GAN The disadvantages of the GANs are as follows: Training Instability : GANs can be difficult to train, with the risk of instability, mode collapse, or failure to converge. Computational Cost : GANs can require  lot of computational resources and can be slow to train, especially for high-resolution images or large datasets. Overfitting : GANs can overfit the training data, producing synthetic data that is too similar to the training data and lacking diversity. Bias and Fairness : GANs can reflect the biases and unfairness present in the training data, leading to discriminatory or biased synthetic data. Interpretability and Accountability : GANs can be opaque and difficult to interpret or explain, making it challenging to ensure accountability, transparency, or fairness in their applications. Generative Adversarial Network (GAN) – FAQs What is  Generative Adversarial Network(GAN)? An artificial intelligence model known as  GAN is made up of two neural networks— discriminator and  generator—that were developed in tandem using adversarial training. The discriminator assesses the new data instances for authenticity, while the generator produces new ones. What are the main applications of GAN? Generating images and videos, transferring styles, enhancing data, translating images to other images, producing realistic synthetic data for machine learning model training, and super-resolution are just  few of the many uses for GANs. What challenges do GAN face? GANs encounter difficulties such training instability, mode collapse (when the generator generates  limited range of samples), and striking the correct balance between the discriminator and generator. It’ frequently necessary to carefully build the model architecture and tune the hyperparameters. How are GAN evaluated? The produced samples’ quality, diversity, and resemblance to real data are the main criteria used to assess GANs. For quantitative assessment, metrics like the Fréchet Inception Distance (FID) and Inception Score are frequently employed. Can GAN be used for tasks other than image generation ? Yes, different tasks can be assigned to GANs. Text, music, 3D models, and other things have all been generated with them. The usefulness of conditional GANs is expanded by enabling the creation of specific content under certain input conditions. What are some famous architectures of GANs ?  few well-known GAN architectures are Progressive GAN (PGAN), Wasserstein GAN (WGAN), Conditional GAN (cGAN), Deep Convolutional GAN (DCGAN), and Vanilla GAN. Each has special qualities and works best with particular kinds of data and tasks.  Rahul_Roy Follow Improve Previous Article Basics of Generative Adversarial Networks (GANs) Next Article Use Cases of Generative Adversarial Networks Please Login to comment... Read More Similar Reads What is so special about Generative Adversarial Network (GAN) Fans are ecstatic for  variety of reasons, including the fact that GANs were the first generative algorithms to produce convincingly good results, as well as the fact that they have opened up many new research directions. In the last several years, GANs are considered to be the most prominent machine learning research, and since then, GANs have re  min read Selection of GAN vs Adversarial Autoencoder models In this article, we are going to see the selection of GAN vs Adversarial Autoencoder models. Generative Adversarial Network (GAN)The Generative Adversarial Network, or GAN, is one of the most prominent deep generative modeling methodologies right now. The primary distinction between GAN and VAE is that GAN seeks to match the pixel level distributio  min read Building  Generative Adversarial Network using Keras Prerequisites: Generative Adversarial Network This article will demonstrate how to build  Generative Adversarial Network using the Keras library. The dataset which is used is the CIFAR10 Image dataset which is preloaded into Keras. You can read about the dataset here. Step : Importing the required libraries import numpy as np import matplotlib.py  min read Conditional Generative Adversarial Network Imagine  situation where you can generate images of cats that match your ideal vision or  landscape that adheres to  specific artistic style. CGANs is  neural network that enables the generation of data that aligns with specific properties, which can be class labels, textual descriptions, or other traits, by harnessing the power of conditions. 13 min read Generative Adversarial Networks (GANs) | An Introduction Generative Adversarial Networks (GANs) was first introduced by Ian Goodfellow in 2014. GANs are  powerful class of neural networks that are used for unsupervised learning. GANs can create anything whatever you feed to them, as it Learn-Generate-Improve. To understand GANs first you must have little understanding of Convolutional Neural Networks.   min read Wasserstein Generative Adversarial Networks (WGANs) Convergence and Optimization Wasserstein Generative Adversarial Network (WGANs) is  modification of Deep Learning GAN with few changes in the algorithm. GAN, or Generative Adversarial Network, is  way to build an accurate generative model. This network was introduced by Martin Arjovsky, Soumith Chintala, and Léon Bottou in 2017. It is widely used to generate realistic images  min read Generative Adversarial Networks (GANs) in PyTorch The aim of the article is to implement GANs architecture using PyTorch framework. The article provides comprehensive understanding of GANs in PyTorch along with in-depth explanation of the code. Generative Adversarial Networks (GANs) are  class of artificial intelligence algorithms used in unsupervised machine learning. They consist of two neural  min read Image Generation using Generative Adversarial Networks (GANs) Generative Adversarial Networks (GANs) represent  revolutionary approach to, artificial intelligence, particularly for generating images. Introduced in 2014, GANs have significantly advanced the ability to create realistic and high-quality images from random noise. In this article, we are going to train GANs model on MNIST dataset for generating   min read Architecture of Super-Resolution Generative Adversarial Networks (SRGANs) Super-Resolution Generative Adversarial Networks (SRGANs) are advanced deep learning models designed to upscale low-resolution images to high-resolution outputs with remarkable detail. This article aims to provide  comprehensive overview of SRGANs, focusing on their architecture, key components, and training techniques to enhance image quality. Ta  min read Generative Adversarial Networks (GANs) with  Generative Adversarial Networks (GANs) are  type of neural network architecture introduced by Ian Goodfellow and his colleagues in 2014. GANs are designed to generate new data samples that resemble  given dataset. They can produce high-quality synthetic data across various domains. Working of GANsGANs consist of two neural networks. first is the 15 min read Generative Adversarial Networks (GANs) vs Diffusion Models Generative Adversarial Networks (GANs) and Diffusion Models are powerful generative models designed to produce synthetic data that closely resembles real-world data. Each model has distinct architectures, strengths, and limitations, making them uniquely suited for various applications. This article aims to provide  comprehensive comparison between  min read Mastering Adversarial Attacks: How One Pixel Can Fool  Neural Network Neural networks are among the best tools for classification tasks. They power everything from image recognition to natural language processing, providing incredible accuracy and versatility. But what if  told you that you could completely undermine  neural network or trick it into making mistakes? Intrigued? Let' explore adversarial attacks and  min read Deep Convolutional GAN with Keras Deep Convolutional GAN (DCGAN) was proposed by  researcher from MIT and Facebook AI research. It is widely used in many convolution-based generation-based techniques. The focus of this paper was to make training GANs stable. Hence, they proposed some architectural changes in the computer vision problems. In this article, we will be using DCGAN on  min read Understanding Auxiliary Classifier : GAN Prerequisite: GANs(General Adversarial Networks) In this article, we will be discussing  special class conditional GAN or -GAN known as Auxiliary Classifier GAN or AC-GAN. Before getting into that, it is important to understand what  class conditional GAN is. Class-Conditional GAN (-GANs): -GAN can be understood as  GAN with some conditional  min read Building an Auxiliary GAN using Keras and Tensorflow Prerequisites: Generative Adversarial Network This article will demonstrate how to build an Auxiliary Generative Adversarial Network using the Keras and TensorFlow libraries. The dataset which is used is the MNIST Image dataset pre-loaded into Keras. Step : Setting up the environment Step  : Open Anaconda prompt in Administrator mode. Step  : Cr  min read Difference between GAN vs DCGAN. Answer: GAN is  broader class of generative models, while DCGAN specifically refers to  type of GAN that utilizes deep convolutional neural networks for image generation.Below is  detailed comparison between GAN (Generative Adversarial Network) and DCGAN (Deep Convolutional Generative Adversarial Network): FeatureGANDCGANArchitectureGeneric arch  min read Adversarial Search Algorithms Adversarial search algorithms are the backbone of strategic decision-making in artificial intelligence, it enables the agents to navigate competitive scenarios effectively. This article offers concise yet comprehensive advantages of these algorithms from their foundational principles to practical applications. Let' uncover the strategies that driv 15+ min read Alpha-Beta pruning in Adversarial Search Algorithms In artificial intelligence, particularly in game playing and decision-making, adversarial search algorithms are used to model and solve problems where two or more players compete against each other. One of the most well-known techniques in this domain is alpha-beta pruning. This article explores the concept of alpha-beta pruning, its implementation  min read Explain the role of minimax algorithm in adversarial search for optimal decision-making? In the realm of artificial intelligence (AI), particularly in game theory and decision-making scenarios involving competition, the ability to predict and counteract an opponent' moves is paramount. This is where adversarial search algorithms come into play. Among the most prominent and foundational of these algorithms is the Minimax algorithm. It 11 min read Pandas AI: The Generative AI Python Library In the age of AI, many of our tasks have been automated especially after the launch of ChatGPT. One such tool that uses the power of ChatGPT to ease data manipulation task in Python is PandasAI. It leverages the power of ChatGPT to generate Python code and executes it. The output of the generated code is returned. Pandas AI helps performing tasks   min read The Difference Between Generative and Discriminative Machine Learning Algorithms Machine learning algorithms allow computers to learn from data and make predictions or judgments, machine learning algorithms have revolutionized  number of sectors. Generic and discriminative algorithms are two essential strategies with various applications in the field of machine learning. We will examine the core distinctions between generative  min read What is Language Revitalization in Generative AI? Imagine  world where ancient tongues, on the brink of fading into silence, are reborn. Where stories whispered through generations find  digital echo and cultural knowledge carried in every syllable is amplified across the internet. This is the promise of language revitalization in generative AI,  revolutionary field that seeks to leverage the   min read Differences between Conversational AI and Generative AI Artificial intelligence has evolved significantly in the past few years, making day-to-day tasks easy and efficient. Conversational AI and Generative AI are the two subsets of artificial intelligence that rapidly advancing the field of AI and have become prominent and transformative. Both technologies make use of machine learning and natural langua  min read 10 Best Generative AI Tools to Refine Your Content Strategy Many of us struggle with content creation and strategy. We're good at the creative, artful side, like writing compelling stories. But the analytical, strategic part is harder. Even when we do get strategic, we spend lots of time on keyword research, topic selection, and tracking performance. AI content tools can give you an advantage on the science  min read  Top Generative AI Design Tools in 2024 [Free & Paid] Are you ready to level up your design game? Gone are the days when designers had to sit and design creatives from scratch. With the rise of artificial intelligence and its integration with different domains, you can save  lot of time and still come up with quality output. You can use these tools in generating base designs and even assist the whole  min read What is Generative AI? Nowadays as we all know the power of Artificial Intelligence is developing day by day, and after the introduction of Generative AI is taking creativity to the next level Generative AI is  subset of Deep learning that is again  part of Artificial Intelligence. In this article, we will explore, What is Generative AI? Examples, Definition, Models 12 min read What is the difference between Generative and Discriminative algorithm? Answer: Generative algorithms model the joint probability distribution of input features and target labels, while discriminative algorithms directly learn the decision boundary between classes.Generative algorithms focus on modeling the joint probability distribution of both input features and target labels. By capturing statistical dependencies wi  min read  Best Generative AI Tools for Developers [2024] In the rapidly evolving world of technology, generative Artificial intelligence (AI) tools for developers have become indispensable assets for innovation and efficiency. These cutting-edge tools harness the power of advanced algorithms and machine learning techniques to autonomously generate content, designs, and code, transforming the development  min read Generative Modeling in TensorFlow Generative modeling is the process of learning the underlying structure of  dataset to generate new samples that mimic the distribution of the original data. The article aims to provide  comprehensive overview of generative modelling along with the implementation leveraging the TensorFlow framework. Table of Content What are generative models and 14 min read AI-Coustics: Fights Noisy Audio With Generative AI Have you ever been troubled by noisy audio during  video call or interview? The constant hum of traffic, the rustle of wind, or even  bustling room can significantly degrade audio quality. For content creators, journalists, and anyone relying on clean audio recording and speech clarity in videos, these challenges can be  major source of frustrat  min read Article Tags : AI-ML-DS Deep Learning Python Python-Quizzes Technical Scripter python + More Practice Tags : python python Like 285k+ interested Geeks Data Structures & Algorithms in Python - Self Paced Explore 198k+ interested Geeks Python Full Course Online - Complete Beginner to Advanced Explore 927k+ interested Geeks Complete Interview Preparation Explore Explore More Read more ## Generative Adversarial Network (GAN) Open In App Share Your Experiences Deep Learning Tutorial Introduction to Deep Learning Introduction to Deep Learning Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning Basic Neural Network Difference between ANN and BNN Single Layer Perceptron in TensorFlow Multi-Layer Perceptron Learning in Tensorflow Deep Neural net with forward and back propagation from scratch - Python Understanding Multi-Layer Feed Forward Networks List of Deep Learning Layers Activation Functions Activation Functions Types Of Activation Function in ANN Activation Functions in Pytorch Understanding Activation Functions in Depth Artificial Neural Network Artificial Neural Networks and its Applications Gradient Descent Optimization in Tensorflow Choose Optimal Number of Epochs to Train  Neural Network in Keras Classification Python | Classify Handwritten Digits with Tensorflow Train  Deep Learning Model With Pytorch Regression Linear Regression using PyTorch Linear Regression Using Tensorflow Hyperparameter tuning Hyperparameter tuning Introduction to Convolution Neural Network Introduction to Convolution Neural Network Digital Image Processing Basics Difference between Image Processing and Computer Vision CNN | Introduction to Pooling Layer CIFAR-10 Image Classification in TensorFlow Implementation of  CNN based Image Classifier using PyTorch Convolutional Neural Network (CNN) Architectures Object Detection vs Object Recognition vs Image Segmentation YOLO v2 - Object Detection Recurrent Neural Network Natural Language Processing (NLP) Tutorial Introduction to NLTK: Tokenization, Stemming, Lemmatization, POS Tagging Word Embeddings in NLP Introduction to Recurrent Neural Network Recurrent Neural Networks Explanation Sentiment Analysis with an Recurrent Neural Networks (RNN) Short term Memory What is LSTM - Long Short Term Memory? Long Short Term Memory Networks Explanation LSTM - Derivation of Back propagation through time Text Generation using Recurrent Long Short Term Memory Network Gated Recurrent Unit Networks Gated Recurrent Unit Networks ML | Text Generation using Gated Recurrent Unit Networks Generative Learning Autoencoders -Machine Learning How Autoencoders works ? Variational AutoEncoders Contractive Autoencoder (CAE) ML | AutoEncoder with TensorFlow . Implementing an Autoencoder in PyTorch Generative adversarial networks Basics of Generative Adversarial Networks (GANs) Generative Adversarial Network (GAN) Use Cases of Generative Adversarial Networks Building  Generative Adversarial Network using Keras Cycle Generative Adversarial Network (CycleGAN) StyleGAN - Style Generative Adversarial Networks Reinforcement Learning Understanding Reinforcement Learning in-depth Introduction to Thompson Sampling | Reinforcement Learning Markov Decision Process Bellman Equation Meta-Learning in Machine Learning -Learning in Python -Learning ML | Reinforcement Learning Algorithm : Python Implementation using -learning Deep  Learning Deep -Learning Implementing Deep -Learning using Tensorflow AI Driven Snake Game using Deep  Learning Deep Learning Interview Questions Machine Learning & Data Science Course Generative Adversarial Network (GAN) Last Updated : 09 Aug, 2024 Comments Improve Summarize Suggest changes Like Article Like Save Share Report Follow GAN (Generative Adversarial Network) represents  cutting-edge approach to generative modeling within deep learning, often leveraging architectures like convolutional neural networks . The goal of generative modeling is to autonomously identify patterns in input data, enabling the model to produce new examples that feasibly resemble the original dataset. This article covers everything you need to know about GAN, the Architecture of GAN, the Workings of GAN, and types of GAN Models, and so on. Table of Content What is  Generative Adversarial Network? Types of GANs Architecture of GANs How does  GAN work? Implementation of  GAN Application Of Generative Adversarial Networks (GANs) Advantages of GAN Disadvantages of GAN GAN(Generative Adversarial Network)- FAQs What is  Generative Adversarial Network? Generative Adversarial Networks (GANs) are  powerful class of neural networks that are used for an unsupervised learning . GANs are made up of two neural networks ,  discriminator and  generator. They use adversarial training to produce artificial data that is identical to actual data. The Generator attempts to fool the Discriminator, which is tasked with accurately distinguishing between produced and genuine data, by producing random noise samples. Realistic, high-quality samples are produced as  result of this competitive interaction, which drives both networks toward advancement. GANs are proving to be highly versatile artificial intelligence tools, as evidenced by their extensive use in image synthesis, style transfer, and text-to-image synthesis. They have also revolutionized generative modeling. Through adversarial training, these models engage in  competitive interplay until the generator becomes adept at creating realistic samples, fooling the discriminator approximately half the time. Generative Adversarial Networks (GANs) can be broken down into three parts: Generative: To learn  generative model, which describes how data is generated in terms of  probabilistic model. Adversarial: The word adversarial refers to setting one thing up against another. This means that, in the context of GANs, the generative result is compared with the actual images in the data set.  mechanism known as  discriminator is used to apply  model that attempts to distinguish between real and fake images. Networks: Use deep neural networks as artificial intelligence (AI) algorithms for training purposes. Types of GANs Vanilla GAN: This is the simplest type of GAN. Here, the Generator and the Discriminator are simple  basic multi-layer perceptrons . In vanilla GAN, the algorithm is really simple, it tries to optimize the mathematical equation using stochastic gradient descent. Conditional GAN (CGAN): CGAN can be described as  deep learning method in which some conditional parameters are put into place . In CGAN, an additional parameter ‘’ is added to the Generator for generating the corresponding data. Labels are also put into the input to the Discriminator in order for the Discriminator to help distinguish the real data from the fake generated data. Deep Convolutional GAN (DCGAN): DCGAN is one of the most popular and also the most successful implementations of GAN. It is composed of ConvNets in place of multi-layer perceptrons . The ConvNets are implemented without max pooling, which is in fact replaced by convolutional stride. Also, the layers are not fully connected. Laplacian Pyramid GAN (LAPGAN): The Laplacian pyramid is  linear invertible image representation consisting of  set of band-pass images, spaced an octave apart, plus  low-frequency residual. This approach uses multiple numbers of Generator and Discriminator networks and different levels of the Laplacian Pyramid. This approach is mainly used because it produces very high-quality images. The image is down-sampled at first at each layer of the pyramid and then it is again up-scaled at each layer in  backward pass where the image acquires some noise from the Conditional GAN at these layers until it reaches its original size. Super Resolution GAN (SRGAN): SRGAN as the name suggests is  way of designing  GAN in which  deep neural network is used along with an adversarial network in order to produce higher-resolution images. This type of GAN is particularly useful in optimally up-scaling native low-resolution images to enhance their details minimizing errors while doing so. Architecture of GANs  Generative Adversarial Network (GAN) is composed of two primary parts, which are the Generator and the Discriminator. Generator Model  key element responsible for creating fresh, accurate data in  Generative Adversarial Network (GAN) is the generator model. The generator takes random noise as input and converts it into complex data samples, such text or images. It is commonly depicted as  deep neural network. The training data’ underlying distribution is captured by layers of learnable parameters in its design through training. The generator adjusts its output to produce samples that closely mimic real data as it is being trained by using backpropagation to fine-tune its parameters. The generator’ ability to generate high-quality, varied samples that can fool the discriminator is what makes it successful. Generator Loss The objective of the generator in  GAN is to produce synthetic samples that are realistic enough to fool the discriminator. The generator achieves this by minimizing its loss function [Tex]J_G[/Tex] ​. The loss is minimized when the log probability is maximized, .., when the discriminator is highly likely to classify the generated samples as real. The following equation is given below: [Tex]J_{} = -\frac{}{} \Sigma^ {=} log ((z_{})) [/Tex] Where, [Tex]J_G[/Tex] measure how well the generator is fooling the discriminator. log [Tex]((z_i) )[/Tex] represents log probability of the discriminator being correct for generated samples. The generator aims to minimize this loss, encouraging the production of samples that the discriminator classifies as real [Tex](log ((z_i))[/Tex] , close to . Discriminator Model An artificial neural network called  discriminator model is used in Generative Adversarial Networks (GANs) to differentiate between generated and actual input. By evaluating input samples and allocating probability of authenticity, the discriminator functions as  binary classifier. Over time, the discriminator learns to differentiate between genuine data from the dataset and artificial samples created by the generator. This allows it to progressively hone its parameters and increase its level of proficiency. Convolutional layers or pertinent structures for other modalities are usually used in its architecture when dealing with picture data. Maximizing the discriminator’ capacity to accurately identify generated samples as fraudulent and real samples as authentic is the aim of the adversarial training procedure. The discriminator grows increasingly discriminating as  result of the generator and discriminator’ interaction, which helps the GAN produce extremely realistic-looking synthetic data overall. Discriminator Loss The discriminator reduces the negative log likelihood of correctly classifying both produced and real samples. This loss incentivizes the discriminator to accurately categorize generated samples as fake and real samples with the following equation: [Tex]J_{} = -\frac{}{} \Sigma_{=}^ log\; (x_{}) – \frac{}{}\Sigma_{=}^ log( – ((z_{})) [/Tex] [Tex]J_D[/Tex] assesses the discriminator’ ability to discern between produced and actual samples. The log likelihood that the discriminator will accurately categorize real data is represented by [Tex]logD(x_i)[/Tex] . The log chance that the discriminator would correctly categorize generated samples as fake is represented by [Tex]log⁡(-((z_i)))[/Tex] . The discriminator aims to reduce this loss by accurately identifying artificial and real samples. MinMax Loss In  Generative Adversarial Network (GAN), the minimax loss formula is provided by: [Tex]min_{}\;max_{}(,) = [\mathbb{}{∼p_{data}}[log\;()] + \mathbb{}{∼p_{}()}[log( – (()))] [/Tex] Where,  is generator network and is  is the discriminator network Actual data samples obtained from the true data distribution [Tex]p_{data}() [/Tex] are represented by . Random noise sampled from  previous distribution [Tex]p_z() [/Tex] (usually  normal or uniform distribution) is represented by . () represents the discriminator’ likelihood of correctly identifying actual data as real. (()) is the likelihood that the discriminator will identify generated data coming from the generator as authentic. How does  GAN work? The steps involved in how  GAN works: Initialization: Two neural networks are created:  Generator () and  Discriminator ().  is tasked with creating new data, like images or text, that closely resembles real data.  acts as  critic, trying to distinguish between real data (from  training dataset) and the data generated by . Generator’ First Move:  takes  random noise vector as input. This noise vector contains random values and acts as the starting point for ’ creation process. Using its internal layers and learned patterns,  transforms the noise vector into  new data sample, like  generated image. Discriminator’ Turn:  receives two kinds of inputs: Real data samples from the training dataset. The data samples generated by  in the previous step. ’ job is to analyze each input and determine whether it’ real data or something  cooked up. It outputs  probability score between  and .  score of  indicates the data is likely real, and  suggests it’ fake. The Learning Process: Now, the adversarial part comes in: If  correctly identifies real data as real (score close to ) and generated data as fake (score close to ), both  and  are rewarded to  small degree. This is because they’re both doing their jobs well. However, the key is to continuously improve. If  consistently identifies everything correctly, it won’ learn much. So, the goal is for  to eventually trick . Generator’ Improvement: When  mistakenly labels ’ creation as real (score close to ), it’  sign that  is on the right track. In this case,  receives  significant positive update, while  receives  penalty for being fooled. This feedback helps  improve its generation process to create more realistic data. Discriminator’ Adaptation: Conversely, if  correctly identifies ’ fake data (score close to ), but  receives no reward,  is further strengthened in its discrimination abilities. This ongoing duel between  and  refines both networks over time. As training progresses,  gets better at generating realistic data, making it harder for  to tell the difference. Ideally,  becomes so adept that  can’ reliably distinguish real from fake data. At this point,  is considered well-trained and can be used to generate new, realistic data samples. Implementation of Generative Adversarial Network (GAN) We will follow and understand the steps to understand how GAN is implemented: Step1 : Importing the required libraries Python import torch import torch.nn as nn import torch.optim as optim import torchvision from torchvision import datasets , transforms import matplotlib.pyplot as plt import numpy as np # Set device device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) For training on the CIFAR-10 image dataset, this PyTorch module creates  Generative Adversarial Network (GAN), switching between generator and discriminator training. Visualization of the generated images occurs every tenth epoch, and the development of the GAN is tracked. Step : Defining  Transform The code uses PyTorch’ transforms to define  simple picture transforms.Compose. It normalizes and transforms photos into tensors. Python # Define  basic transform transform = transforms . Compose ([ transforms . ToTensor (), transforms . Normalize (( . , . , . ), ( . , . , . )) ]) Step : Loading the Dataset  CIFAR-10 dataset is created for training with below code, which also specifies  root directory, turns on train mode, downloads if needed, and applies the specified transform. Subsequently, it generates  32-batch DataLoader and shuffles the training set of data. Python train_dataset = datasets . CIFAR10 ( root = './data' , \ train = True , download = True , transform = transform ) dataloader = torch . utils . data . DataLoader ( train_dataset , \ batch_size = 32 , shuffle = True ) Step : Defining parameters to be used in later processes  Generative Adversarial Network (GAN) is used with specified hyperparameters. The latent space’ dimensionality is represented by latent_dim. lr is the optimizer’ learning rate. The coefficients for the Adam optimizer are beta1 and beta2. To find the total number of training epochs, use num_epochs. Python # Hyperparameters latent_dim = 100 lr = .0002 beta1 = . beta2 = .999 num_epochs = 10 Step : Defining  Utility Class to Build the Generator The generator architecture for  GAN in PyTorch is defined with below code. From nn.Module , the Generator class inherits. It is comprised of  sequential model with Tanh, linear, convolutional, batch normalization, reshaping, and upsampling layers. The neural network synthesizes an image (img) from  latent vector (), which is the generator’ output. The architecture uses  series of learned transformations to turn the initial random noise in the latent space into  meaningful image. Python # Define the generator class Generator ( nn . Module ): def __init__ ( self , latent_dim ): super ( Generator , self ) . __init__ () self . model = nn . Sequential ( nn . Linear ( latent_dim , 128 *  *  ), nn . ReLU (), nn . Unflatten (  , ( 128 ,  ,  )), nn . Upsample ( scale_factor =  ), nn . Conv2d ( 128 , 128 , kernel_size =  , padding =  ), nn . BatchNorm2d ( 128 , momentum = .78 ), nn . ReLU (), nn . Upsample ( scale_factor =  ), nn . Conv2d ( 128 , 64 , kernel_size =  , padding =  ), nn . BatchNorm2d ( 64 , momentum = .78 ), nn . ReLU (), nn . Conv2d ( 64 ,  , kernel_size =  , padding =  ), nn . Tanh () ) def forward ( self ,  ): img = self . model (  ) return img Step : Defining  Utility Class to Build the Discriminator The PyTorch code describes the discriminator architecture for  GAN. The class Discriminator is descended from nn.Module. It is composed of linear layers, batch normalization, dropout , convolutional, LeakyReLU , and sequential layers. An image (img) is the discriminator’ input, and its validity—the probability that the input image is real as opposed to artificial—is its output. Python # Define the discriminator class Discriminator ( nn . Module ): def __init__ ( self ): super ( Discriminator , self ) . __init__ () self . model = nn . Sequential ( nn . Conv2d (  , 32 , kernel_size =  , stride =  , padding =  ), nn . LeakyReLU ( . ), nn . Dropout ( .25 ), nn . Conv2d ( 32 , 64 , kernel_size =  , stride =  , padding =  ), nn . ZeroPad2d ((  ,  ,  ,  )), nn . BatchNorm2d ( 64 , momentum = .82 ), nn . LeakyReLU ( .25 ), nn . Dropout ( .25 ), nn . Conv2d ( 64 , 128 , kernel_size =  , stride =  , padding =  ), nn . BatchNorm2d ( 128 , momentum = .82 ), nn . LeakyReLU ( . ), nn . Dropout ( .25 ), nn . Conv2d ( 128 , 256 , kernel_size =  , stride =  , padding =  ), nn . BatchNorm2d ( 256 , momentum = . ), nn . LeakyReLU ( .25 ), nn . Dropout ( .25 ), nn . Flatten (), nn . Linear ( 256 *  *  ,  ), nn . Sigmoid () ) def forward ( self , img ): validity = self . model ( img ) return validity Step : Building the Generative Adversarial Network The code snippet defines and initializes  discriminator (Discriminator) and  generator (Generator). The designated device (GPU if available) receives both models. Binary Cross Entropy Loss, which is frequently used for GANs, is selected as the loss function (adversarial_loss). For the generator (optimizer_G) and discriminator (optimizer_D), distinct Adam optimizers with predetermined learning rates and betas are also defined. Python # Define the generator and discriminator # Initialize generator and discriminator generator = Generator ( latent_dim ) . to ( device ) discriminator = Discriminator () . to ( device ) # Loss function adversarial_loss = nn . BCELoss () # Optimizers optimizer_G = optim . Adam ( generator . parameters () \ , lr = lr , betas = ( beta1 , beta2 )) optimizer_D = optim . Adam ( discriminator . parameters () \ , lr = lr , betas = ( beta1 , beta2 )) Step : Training the Generative Adversarial Network For  Generative Adversarial Network (GAN), the code implements the training loop. The training data batches are iterated through during each epoch. Whereas the generator (optimizer_G) is trained to generate realistic images that trick the discriminator, the discriminator (optimizer_D) is trained to distinguish between real and phony images. The generator and discriminator’ adversarial losses are computed. Model parameters are updated by means of Adam optimizers and the losses are backpropagated. Discriminator printing and generator losses are used to track progress. For  visual assessment of the training process, generated images are additionally saved and shown every 10 epochs. Python # Training loop for epoch in range ( num_epochs ): for  , batch in enumerate ( dataloader ): # Convert list to tensor real_images = batch [  ] . to ( device ) # Adversarial ground truths valid = torch . ones ( real_images . size (  ),  , device = device ) fake = torch . zeros ( real_images . size (  ),  , device = device ) # Configure input real_images = real_images . to ( device ) # --------------------- # Train Discriminator # --------------------- optimizer_D . zero_grad () # Sample noise as generator input  = torch . randn ( real_images . size (  ), latent_dim , device = device ) # Generate  batch of images fake_images = generator (  ) # Measure discriminator' ability # to classify real and fake images real_loss = adversarial_loss ( discriminator \ ( real_images ), valid ) fake_loss = adversarial_loss ( discriminator \ ( fake_images . detach ()), fake ) d_loss = ( real_loss + fake_loss ) /  # Backward pass and optimize d_loss . backward () optimizer_D . step () # ----------------- # Train Generator # ----------------- optimizer_G . zero_grad () # Generate  batch of images gen_images = generator (  ) # Adversarial loss g_loss = adversarial_loss ( discriminator ( gen_images ), valid ) # Backward pass and optimize g_loss . backward () optimizer_G . step () # --------------------- # Progress Monitoring # --------------------- if (  +  ) % 100 ==  : print (  "Epoch [ { epoch +  } / { num_epochs } ] \ Batch {  +  } / { len ( dataloader ) } "  "Discriminator Loss: { d_loss . item () : .4f } "  "Generator Loss: { g_loss . item () : .4f } " ) # Save generated images for every epoch if ( epoch +  ) % 10 ==  : with torch . no_grad ():  = torch . randn ( 16 , latent_dim , device = device ) generated = generator (  ) . detach () . cpu () grid = torchvision . utils . make_grid ( generated , \ nrow =  , normalize = True ) plt . imshow ( np . transpose ( grid , (  ,  ,  ))) plt . axis ( "off" ) plt . show () Output: Epoch [10/10] Batch 1300/1563 Discriminator Loss: .4473 Generator Loss: .9555 Epoch [10/10] Batch 1400/1563 Discriminator Loss: .6643 Generator Loss: .0215 Epoch [10/10] Batch 1500/1563 Discriminator Loss: .4720 Generator Loss: .5027 GAN Output Application Of Generative Adversarial Networks (GANs) GANs, or Generative Adversarial Networks, have many uses in many different fields. Here are some of the widely recognized uses of GANs: Image Synthesis and Generation : GANs are often used for picture synthesis and generation tasks, They may create fresh, lifelike pictures that mimic training data by learning the distribution that explains the dataset. The development of lifelike avatars, high-resolution photographs, and fresh artwork have all been facilitated by these types of generative networks. Image-to-Image Translation : GANs may be used for problems involving image-to-image translation, where the objective is to convert an input picture from one domain to another while maintaining its key features. GANs may be used, for instance, to change pictures from day to night, transform drawings into realistic images, or change the creative style of an image. Text-to-Image Synthesis : GANs have been used to create visuals from descriptions in text. GANs may produce pictures that translate to  description given  text input, such as  phrase or  caption. This application might have an impact on how realistic visual material is produced using text-based instructions. Data Augmentation : GANs can augment present data and increase the robustness and generalizability of machine-learning models by creating synthetic data samples. Data Generation for Training : GANs can enhance the resolution and quality of low-resolution images. By training on pairs of low-resolution and high-resolution images, GANs can generate high-resolution images from low-resolution inputs, enabling improved image quality in various applications such as medical imaging, satellite imaging, and video enhancement. Advantages of GAN The advantages of the GANs are as follows: Synthetic data generation : GANs can generate new, synthetic data that resembles some known data distribution, which can be useful for data augmentation, anomaly detection, or creative applications. High-quality results : GANs can produce high-quality, photorealistic results in image synthesis, video synthesis, music synthesis, and other tasks. Unsupervised learning : GANs can be trained without labeled data, making them suitable for unsupervised learning tasks, where labeled data is scarce or difficult to obtain. Versatility : GANs can be applied to  wide range of tasks, including image synthesis, text-to-image synthesis, image-to-image translation, anomaly detection , data augmentation , and others. Disadvantages of GAN The disadvantages of the GANs are as follows: Training Instability : GANs can be difficult to train, with the risk of instability, mode collapse, or failure to converge. Computational Cost : GANs can require  lot of computational resources and can be slow to train, especially for high-resolution images or large datasets. Overfitting : GANs can overfit the training data, producing synthetic data that is too similar to the training data and lacking diversity. Bias and Fairness : GANs can reflect the biases and unfairness present in the training data, leading to discriminatory or biased synthetic data. Interpretability and Accountability : GANs can be opaque and difficult to interpret or explain, making it challenging to ensure accountability, transparency, or fairness in their applications. Generative Adversarial Network (GAN) – FAQs What is  Generative Adversarial Network(GAN)? An artificial intelligence model known as  GAN is made up of two neural networks— discriminator and  generator—that were developed in tandem using adversarial training. The discriminator assesses the new data instances for authenticity, while the generator produces new ones. What are the main applications of GAN? Generating images and videos, transferring styles, enhancing data, translating images to other images, producing realistic synthetic data for machine learning model training, and super-resolution are just  few of the many uses for GANs. What challenges do GAN face? GANs encounter difficulties such training instability, mode collapse (when the generator generates  limited range of samples), and striking the correct balance between the discriminator and generator. It’ frequently necessary to carefully build the model architecture and tune the hyperparameters. How are GAN evaluated? The produced samples’ quality, diversity, and resemblance to real data are the main criteria used to assess GANs. For quantitative assessment, metrics like the Fréchet Inception Distance (FID) and Inception Score are frequently employed. Can GAN be used for tasks other than image generation ? Yes, different tasks can be assigned to GANs. Text, music, 3D models, and other things have all been generated with them. The usefulness of conditional GANs is expanded by enabling the creation of specific content under certain input conditions. What are some famous architectures of GANs ?  few well-known GAN architectures are Progressive GAN (PGAN), Wasserstein GAN (WGAN), Conditional GAN (cGAN), Deep Convolutional GAN (DCGAN), and Vanilla GAN. Each has special qualities and works best with particular kinds of data and tasks.  Rahul_Roy Follow Improve Previous Article Basics of Generative Adversarial Networks (GANs) Next Article Use Cases of Generative Adversarial Networks Please Login to comment... Read More Similar Reads What is so special about Generative Adversarial Network (GAN) Fans are ecstatic for  variety of reasons, including the fact that GANs were the first generative algorithms to produce convincingly good results, as well as the fact that they have opened up many new research directions. In the last several years, GANs are considered to be the most prominent machine learning research, and since then, GANs have re  min read Selection of GAN vs Adversarial Autoencoder models In this article, we are going to see the selection of GAN vs Adversarial Autoencoder models. Generative Adversarial Network (GAN)The Generative Adversarial Network, or GAN, is one of the most prominent deep generative modeling methodologies right now. The primary distinction between GAN and VAE is that GAN seeks to match the pixel level distributio  min read Building  Generative Adversarial Network using Keras Prerequisites: Generative Adversarial Network This article will demonstrate how to build  Generative Adversarial Network using the Keras library. The dataset which is used is the CIFAR10 Image dataset which is preloaded into Keras. You can read about the dataset here. Step : Importing the required libraries import numpy as np import matplotlib.py  min read Conditional Generative Adversarial Network Imagine  situation where you can generate images of cats that match your ideal vision or  landscape that adheres to  specific artistic style. CGANs is  neural network that enables the generation of data that aligns with specific properties, which can be class labels, textual descriptions, or other traits, by harnessing the power of conditions. 13 min read Generative Adversarial Networks (GANs) | An Introduction Generative Adversarial Networks (GANs) was first introduced by Ian Goodfellow in 2014. GANs are  powerful class of neural networks that are used for unsupervised learning. GANs can create anything whatever you feed to them, as it Learn-Generate-Improve. To understand GANs first you must have little understanding of Convolutional Neural Networks.   min read Wasserstein Generative Adversarial Networks (WGANs) Convergence and Optimization Wasserstein Generative Adversarial Network (WGANs) is  modification of Deep Learning GAN with few changes in the algorithm. GAN, or Generative Adversarial Network, is  way to build an accurate generative model. This network was introduced by Martin Arjovsky, Soumith Chintala, and Léon Bottou in 2017. It is widely used to generate realistic images  min read Generative Adversarial Networks (GANs) in PyTorch The aim of the article is to implement GANs architecture using PyTorch framework. The article provides comprehensive understanding of GANs in PyTorch along with in-depth explanation of the code. Generative Adversarial Networks (GANs) are  class of artificial intelligence algorithms used in unsupervised machine learning. They consist of two neural  min read Image Generation using Generative Adversarial Networks (GANs) Generative Adversarial Networks (GANs) represent  revolutionary approach to, artificial intelligence, particularly for generating images. Introduced in 2014, GANs have significantly advanced the ability to create realistic and high-quality images from random noise. In this article, we are going to train GANs model on MNIST dataset for generating   min read Architecture of Super-Resolution Generative Adversarial Networks (SRGANs) Super-Resolution Generative Adversarial Networks (SRGANs) are advanced deep learning models designed to upscale low-resolution images to high-resolution outputs with remarkable detail. This article aims to provide  comprehensive overview of SRGANs, focusing on their architecture, key components, and training techniques to enhance image quality. Ta  min read Generative Adversarial Networks (GANs) with  Generative Adversarial Networks (GANs) are  type of neural network architecture introduced by Ian Goodfellow and his colleagues in 2014. GANs are designed to generate new data samples that resemble  given dataset. They can produce high-quality synthetic data across various domains. Working of GANsGANs consist of two neural networks. first is the 15 min read Generative Adversarial Networks (GANs) vs Diffusion Models Generative Adversarial Networks (GANs) and Diffusion Models are powerful generative models designed to produce synthetic data that closely resembles real-world data. Each model has distinct architectures, strengths, and limitations, making them uniquely suited for various applications. This article aims to provide  comprehensive comparison between  min read Mastering Adversarial Attacks: How One Pixel Can Fool  Neural Network Neural networks are among the best tools for classification tasks. They power everything from image recognition to natural language processing, providing incredible accuracy and versatility. But what if  told you that you could completely undermine  neural network or trick it into making mistakes? Intrigued? Let' explore adversarial attacks and  min read Deep Convolutional GAN with Keras Deep Convolutional GAN (DCGAN) was proposed by  researcher from MIT and Facebook AI research. It is widely used in many convolution-based generation-based techniques. The focus of this paper was to make training GANs stable. Hence, they proposed some architectural changes in the computer vision problems. In this article, we will be using DCGAN on  min read Understanding Auxiliary Classifier : GAN Prerequisite: GANs(General Adversarial Networks) In this article, we will be discussing  special class conditional GAN or -GAN known as Auxiliary Classifier GAN or AC-GAN. Before getting into that, it is important to understand what  class conditional GAN is. Class-Conditional GAN (-GANs): -GAN can be understood as  GAN with some conditional  min read Building an Auxiliary GAN using Keras and Tensorflow Prerequisites: Generative Adversarial Network This article will demonstrate how to build an Auxiliary Generative Adversarial Network using the Keras and TensorFlow libraries. The dataset which is used is the MNIST Image dataset pre-loaded into Keras. Step : Setting up the environment Step  : Open Anaconda prompt in Administrator mode. Step  : Cr  min read Difference between GAN vs DCGAN. Answer: GAN is  broader class of generative models, while DCGAN specifically refers to  type of GAN that utilizes deep convolutional neural networks for image generation.Below is  detailed comparison between GAN (Generative Adversarial Network) and DCGAN (Deep Convolutional Generative Adversarial Network): FeatureGANDCGANArchitectureGeneric arch  min read Adversarial Search Algorithms Adversarial search algorithms are the backbone of strategic decision-making in artificial intelligence, it enables the agents to navigate competitive scenarios effectively. This article offers concise yet comprehensive advantages of these algorithms from their foundational principles to practical applications. Let' uncover the strategies that driv 15+ min read Alpha-Beta pruning in Adversarial Search Algorithms In artificial intelligence, particularly in game playing and decision-making, adversarial search algorithms are used to model and solve problems where two or more players compete against each other. One of the most well-known techniques in this domain is alpha-beta pruning. This article explores the concept of alpha-beta pruning, its implementation  min read Explain the role of minimax algorithm in adversarial search for optimal decision-making? In the realm of artificial intelligence (AI), particularly in game theory and decision-making scenarios involving competition, the ability to predict and counteract an opponent' moves is paramount. This is where adversarial search algorithms come into play. Among the most prominent and foundational of these algorithms is the Minimax algorithm. It 11 min read Pandas AI: The Generative AI Python Library In the age of AI, many of our tasks have been automated especially after the launch of ChatGPT. One such tool that uses the power of ChatGPT to ease data manipulation task in Python is PandasAI. It leverages the power of ChatGPT to generate Python code and executes it. The output of the generated code is returned. Pandas AI helps performing tasks   min read The Difference Between Generative and Discriminative Machine Learning Algorithms Machine learning algorithms allow computers to learn from data and make predictions or judgments, machine learning algorithms have revolutionized  number of sectors. Generic and discriminative algorithms are two essential strategies with various applications in the field of machine learning. We will examine the core distinctions between generative  min read What is Language Revitalization in Generative AI? Imagine  world where ancient tongues, on the brink of fading into silence, are reborn. Where stories whispered through generations find  digital echo and cultural knowledge carried in every syllable is amplified across the internet. This is the promise of language revitalization in generative AI,  revolutionary field that seeks to leverage the   min read Differences between Conversational AI and Generative AI Artificial intelligence has evolved significantly in the past few years, making day-to-day tasks easy and efficient. Conversational AI and Generative AI are the two subsets of artificial intelligence that rapidly advancing the field of AI and have become prominent and transformative. Both technologies make use of machine learning and natural langua  min read 10 Best Generative AI Tools to Refine Your Content Strategy Many of us struggle with content creation and strategy. We're good at the creative, artful side, like writing compelling stories. But the analytical, strategic part is harder. Even when we do get strategic, we spend lots of time on keyword research, topic selection, and tracking performance. AI content tools can give you an advantage on the science  min read  Top Generative AI Design Tools in 2024 [Free & Paid] Are you ready to level up your design game? Gone are the days when designers had to sit and design creatives from scratch. With the rise of artificial intelligence and its integration with different domains, you can save  lot of time and still come up with quality output. You can use these tools in generating base designs and even assist the whole  min read What is Generative AI? Nowadays as we all know the power of Artificial Intelligence is developing day by day, and after the introduction of Generative AI is taking creativity to the next level Generative AI is  subset of Deep learning that is again  part of Artificial Intelligence. In this article, we will explore, What is Generative AI? Examples, Definition, Models 12 min read What is the difference between Generative and Discriminative algorithm? Answer: Generative algorithms model the joint probability distribution of input features and target labels, while discriminative algorithms directly learn the decision boundary between classes.Generative algorithms focus on modeling the joint probability distribution of both input features and target labels. By capturing statistical dependencies wi  min read  Best Generative AI Tools for Developers [2024] In the rapidly evolving world of technology, generative Artificial intelligence (AI) tools for developers have become indispensable assets for innovation and efficiency. These cutting-edge tools harness the power of advanced algorithms and machine learning techniques to autonomously generate content, designs, and code, transforming the development  min read Generative Modeling in TensorFlow Generative modeling is the process of learning the underlying structure of  dataset to generate new samples that mimic the distribution of the original data. The article aims to provide  comprehensive overview of generative modelling along with the implementation leveraging the TensorFlow framework. Table of Content What are generative models and 14 min read AI-Coustics: Fights Noisy Audio With Generative AI Have you ever been troubled by noisy audio during  video call or interview? The constant hum of traffic, the rustle of wind, or even  bustling room can significantly degrade audio quality. For content creators, journalists, and anyone relying on clean audio recording and speech clarity in videos, these challenges can be  major source of frustrat  min read Article Tags : AI-ML-DS Deep Learning Python Python-Quizzes Technical Scripter python + More Practice Tags : python python Like 285k+ interested Geeks Data Structures & Algorithms in Python - Self Paced Explore 198k+ interested Geeks Python Full Course Online - Complete Beginner to Advanced Explore 927k+ interested Geeks Complete Interview Preparation Explore Explore More Read more ## Generative Adversarial Network (GAN) Open In App Share Your Experiences Deep Learning Tutorial Introduction to Deep Learning Introduction to Deep Learning Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning Basic Neural Network Difference between ANN and BNN Single Layer Perceptron in TensorFlow Multi-Layer Perceptron Learning in Tensorflow Deep Neural net with forward and back propagation from scratch - Python Understanding Multi-Layer Feed Forward Networks List of Deep Learning Layers Activation Functions Activation Functions Types Of Activation Function in ANN Activation Functions in Pytorch Understanding Activation Functions in Depth Artificial Neural Network Artificial Neural Networks and its Applications Gradient Descent Optimization in Tensorflow Choose Optimal Number of Epochs to Train  Neural Network in Keras Classification Python | Classify Handwritten Digits with Tensorflow Train  Deep Learning Model With Pytorch Regression Linear Regression using PyTorch Linear Regression Using Tensorflow Hyperparameter tuning Hyperparameter tuning Introduction to Convolution Neural Network Introduction to Convolution Neural Network Digital Image Processing Basics Difference between Image Processing and Computer Vision CNN | Introduction to Pooling Layer CIFAR-10 Image Classification in TensorFlow Implementation of  CNN based Image Classifier using PyTorch Convolutional Neural Network (CNN) Architectures Object Detection vs Object Recognition vs Image Segmentation YOLO v2 - Object Detection Recurrent Neural Network Natural Language Processing (NLP) Tutorial Introduction to NLTK: Tokenization, Stemming, Lemmatization, POS Tagging Word Embeddings in NLP Introduction to Recurrent Neural Network Recurrent Neural Networks Explanation Sentiment Analysis with an Recurrent Neural Networks (RNN) Short term Memory What is LSTM - Long Short Term Memory? Long Short Term Memory Networks Explanation LSTM - Derivation of Back propagation through time Text Generation using Recurrent Long Short Term Memory Network Gated Recurrent Unit Networks Gated Recurrent Unit Networks ML | Text Generation using Gated Recurrent Unit Networks Generative Learning Autoencoders -Machine Learning How Autoencoders works ? Variational AutoEncoders Contractive Autoencoder (CAE) ML | AutoEncoder with TensorFlow . Implementing an Autoencoder in PyTorch Generative adversarial networks Basics of Generative Adversarial Networks (GANs) Generative Adversarial Network (GAN) Use Cases of Generative Adversarial Networks Building  Generative Adversarial Network using Keras Cycle Generative Adversarial Network (CycleGAN) StyleGAN - Style Generative Adversarial Networks Reinforcement Learning Understanding Reinforcement Learning in-depth Introduction to Thompson Sampling | Reinforcement Learning Markov Decision Process Bellman Equation Meta-Learning in Machine Learning -Learning in Python -Learning ML | Reinforcement Learning Algorithm : Python Implementation using -learning Deep  Learning Deep -Learning Implementing Deep -Learning using Tensorflow AI Driven Snake Game using Deep  Learning Deep Learning Interview Questions Machine Learning & Data Science Course Generative Adversarial Network (GAN) Last Updated : 09 Aug, 2024 Comments Improve Summarize Suggest changes Like Article Like Save Share Report Follow GAN (Generative Adversarial Network) represents  cutting-edge approach to generative modeling within deep learning, often leveraging architectures like convolutional neural networks . The goal of generative modeling is to autonomously identify patterns in input data, enabling the model to produce new examples that feasibly resemble the original dataset. This article covers everything you need to know about GAN, the Architecture of GAN, the Workings of GAN, and types of GAN Models, and so on. Table of Content What is  Generative Adversarial Network? Types of GANs Architecture of GANs How does  GAN work? Implementation of  GAN Application Of Generative Adversarial Networks (GANs) Advantages of GAN Disadvantages of GAN GAN(Generative Adversarial Network)- FAQs What is  Generative Adversarial Network? Generative Adversarial Networks (GANs) are  powerful class of neural networks that are used for an unsupervised learning . GANs are made up of two neural networks ,  discriminator and  generator. They use adversarial training to produce artificial data that is identical to actual data. The Generator attempts to fool the Discriminator, which is tasked with accurately distinguishing between produced and genuine data, by producing random noise samples. Realistic, high-quality samples are produced as  result of this competitive interaction, which drives both networks toward advancement. GANs are proving to be highly versatile artificial intelligence tools, as evidenced by their extensive use in image synthesis, style transfer, and text-to-image synthesis. They have also revolutionized generative modeling. Through adversarial training, these models engage in  competitive interplay until the generator becomes adept at creating realistic samples, fooling the discriminator approximately half the time. Generative Adversarial Networks (GANs) can be broken down into three parts: Generative: To learn  generative model, which describes how data is generated in terms of  probabilistic model. Adversarial: The word adversarial refers to setting one thing up against another. This means that, in the context of GANs, the generative result is compared with the actual images in the data set.  mechanism known as  discriminator is used to apply  model that attempts to distinguish between real and fake images. Networks: Use deep neural networks as artificial intelligence (AI) algorithms for training purposes. Types of GANs Vanilla GAN: This is the simplest type of GAN. Here, the Generator and the Discriminator are simple  basic multi-layer perceptrons . In vanilla GAN, the algorithm is really simple, it tries to optimize the mathematical equation using stochastic gradient descent. Conditional GAN (CGAN): CGAN can be described as  deep learning method in which some conditional parameters are put into place . In CGAN, an additional parameter ‘’ is added to the Generator for generating the corresponding data. Labels are also put into the input to the Discriminator in order for the Discriminator to help distinguish the real data from the fake generated data. Deep Convolutional GAN (DCGAN): DCGAN is one of the most popular and also the most successful implementations of GAN. It is composed of ConvNets in place of multi-layer perceptrons . The ConvNets are implemented without max pooling, which is in fact replaced by convolutional stride. Also, the layers are not fully connected. Laplacian Pyramid GAN (LAPGAN): The Laplacian pyramid is  linear invertible image representation consisting of  set of band-pass images, spaced an octave apart, plus  low-frequency residual. This approach uses multiple numbers of Generator and Discriminator networks and different levels of the Laplacian Pyramid. This approach is mainly used because it produces very high-quality images. The image is down-sampled at first at each layer of the pyramid and then it is again up-scaled at each layer in  backward pass where the image acquires some noise from the Conditional GAN at these layers until it reaches its original size. Super Resolution GAN (SRGAN): SRGAN as the name suggests is  way of designing  GAN in which  deep neural network is used along with an adversarial network in order to produce higher-resolution images. This type of GAN is particularly useful in optimally up-scaling native low-resolution images to enhance their details minimizing errors while doing so. Architecture of GANs  Generative Adversarial Network (GAN) is composed of two primary parts, which are the Generator and the Discriminator. Generator Model  key element responsible for creating fresh, accurate data in  Generative Adversarial Network (GAN) is the generator model. The generator takes random noise as input and converts it into complex data samples, such text or images. It is commonly depicted as  deep neural network. The training data’ underlying distribution is captured by layers of learnable parameters in its design through training. The generator adjusts its output to produce samples that closely mimic real data as it is being trained by using backpropagation to fine-tune its parameters. The generator’ ability to generate high-quality, varied samples that can fool the discriminator is what makes it successful. Generator Loss The objective of the generator in  GAN is to produce synthetic samples that are realistic enough to fool the discriminator. The generator achieves this by minimizing its loss function [Tex]J_G[/Tex] ​. The loss is minimized when the log probability is maximized, .., when the discriminator is highly likely to classify the generated samples as real. The following equation is given below: [Tex]J_{} = -\frac{}{} \Sigma^ {=} log ((z_{})) [/Tex] Where, [Tex]J_G[/Tex] measure how well the generator is fooling the discriminator. log [Tex]((z_i) )[/Tex] represents log probability of the discriminator being correct for generated samples. The generator aims to minimize this loss, encouraging the production of samples that the discriminator classifies as real [Tex](log ((z_i))[/Tex] , close to . Discriminator Model An artificial neural network called  discriminator model is used in Generative Adversarial Networks (GANs) to differentiate between generated and actual input. By evaluating input samples and allocating probability of authenticity, the discriminator functions as  binary classifier. Over time, the discriminator learns to differentiate between genuine data from the dataset and artificial samples created by the generator. This allows it to progressively hone its parameters and increase its level of proficiency. Convolutional layers or pertinent structures for other modalities are usually used in its architecture when dealing with picture data. Maximizing the discriminator’ capacity to accurately identify generated samples as fraudulent and real samples as authentic is the aim of the adversarial training procedure. The discriminator grows increasingly discriminating as  result of the generator and discriminator’ interaction, which helps the GAN produce extremely realistic-looking synthetic data overall. Discriminator Loss The discriminator reduces the negative log likelihood of correctly classifying both produced and real samples. This loss incentivizes the discriminator to accurately categorize generated samples as fake and real samples with the following equation: [Tex]J_{} = -\frac{}{} \Sigma_{=}^ log\; (x_{}) – \frac{}{}\Sigma_{=}^ log( – ((z_{})) [/Tex] [Tex]J_D[/Tex] assesses the discriminator’ ability to discern between produced and actual samples. The log likelihood that the discriminator will accurately categorize real data is represented by [Tex]logD(x_i)[/Tex] . The log chance that the discriminator would correctly categorize generated samples as fake is represented by [Tex]log⁡(-((z_i)))[/Tex] . The discriminator aims to reduce this loss by accurately identifying artificial and real samples. MinMax Loss In  Generative Adversarial Network (GAN), the minimax loss formula is provided by: [Tex]min_{}\;max_{}(,) = [\mathbb{}{∼p_{data}}[log\;()] + \mathbb{}{∼p_{}()}[log( – (()))] [/Tex] Where,  is generator network and is  is the discriminator network Actual data samples obtained from the true data distribution [Tex]p_{data}() [/Tex] are represented by . Random noise sampled from  previous distribution [Tex]p_z() [/Tex] (usually  normal or uniform distribution) is represented by . () represents the discriminator’ likelihood of correctly identifying actual data as real. (()) is the likelihood that the discriminator will identify generated data coming from the generator as authentic. How does  GAN work? The steps involved in how  GAN works: Initialization: Two neural networks are created:  Generator () and  Discriminator ().  is tasked with creating new data, like images or text, that closely resembles real data.  acts as  critic, trying to distinguish between real data (from  training dataset) and the data generated by . Generator’ First Move:  takes  random noise vector as input. This noise vector contains random values and acts as the starting point for ’ creation process. Using its internal layers and learned patterns,  transforms the noise vector into  new data sample, like  generated image. Discriminator’ Turn:  receives two kinds of inputs: Real data samples from the training dataset. The data samples generated by  in the previous step. ’ job is to analyze each input and determine whether it’ real data or something  cooked up. It outputs  probability score between  and .  score of  indicates the data is likely real, and  suggests it’ fake. The Learning Process: Now, the adversarial part comes in: If  correctly identifies real data as real (score close to ) and generated data as fake (score close to ), both  and  are rewarded to  small degree. This is because they’re both doing their jobs well. However, the key is to continuously improve. If  consistently identifies everything correctly, it won’ learn much. So, the goal is for  to eventually trick . Generator’ Improvement: When  mistakenly labels ’ creation as real (score close to ), it’  sign that  is on the right track. In this case,  receives  significant positive update, while  receives  penalty for being fooled. This feedback helps  improve its generation process to create more realistic data. Discriminator’ Adaptation: Conversely, if  correctly identifies ’ fake data (score close to ), but  receives no reward,  is further strengthened in its discrimination abilities. This ongoing duel between  and  refines both networks over time. As training progresses,  gets better at generating realistic data, making it harder for  to tell the difference. Ideally,  becomes so adept that  can’ reliably distinguish real from fake data. At this point,  is considered well-trained and can be used to generate new, realistic data samples. Implementation of Generative Adversarial Network (GAN) We will follow and understand the steps to understand how GAN is implemented: Step1 : Importing the required libraries Python import torch import torch.nn as nn import torch.optim as optim import torchvision from torchvision import datasets , transforms import matplotlib.pyplot as plt import numpy as np # Set device device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) For training on the CIFAR-10 image dataset, this PyTorch module creates  Generative Adversarial Network (GAN), switching between generator and discriminator training. Visualization of the generated images occurs every tenth epoch, and the development of the GAN is tracked. Step : Defining  Transform The code uses PyTorch’ transforms to define  simple picture transforms.Compose. It normalizes and transforms photos into tensors. Python # Define  basic transform transform = transforms . Compose ([ transforms . ToTensor (), transforms . Normalize (( . , . , . ), ( . , . , . )) ]) Step : Loading the Dataset  CIFAR-10 dataset is created for training with below code, which also specifies  root directory, turns on train mode, downloads if needed, and applies the specified transform. Subsequently, it generates  32-batch DataLoader and shuffles the training set of data. Python train_dataset = datasets . CIFAR10 ( root = './data' , \ train = True , download = True , transform = transform ) dataloader = torch . utils . data . DataLoader ( train_dataset , \ batch_size = 32 , shuffle = True ) Step : Defining parameters to be used in later processes  Generative Adversarial Network (GAN) is used with specified hyperparameters. The latent space’ dimensionality is represented by latent_dim. lr is the optimizer’ learning rate. The coefficients for the Adam optimizer are beta1 and beta2. To find the total number of training epochs, use num_epochs. Python # Hyperparameters latent_dim = 100 lr = .0002 beta1 = . beta2 = .999 num_epochs = 10 Step : Defining  Utility Class to Build the Generator The generator architecture for  GAN in PyTorch is defined with below code. From nn.Module , the Generator class inherits. It is comprised of  sequential model with Tanh, linear, convolutional, batch normalization, reshaping, and upsampling layers. The neural network synthesizes an image (img) from  latent vector (), which is the generator’ output. The architecture uses  series of learned transformations to turn the initial random noise in the latent space into  meaningful image. Python # Define the generator class Generator ( nn . Module ): def __init__ ( self , latent_dim ): super ( Generator , self ) . __init__ () self . model = nn . Sequential ( nn . Linear ( latent_dim , 128 *  *  ), nn . ReLU (), nn . Unflatten (  , ( 128 ,  ,  )), nn . Upsample ( scale_factor =  ), nn . Conv2d ( 128 , 128 , kernel_size =  , padding =  ), nn . BatchNorm2d ( 128 , momentum = .78 ), nn . ReLU (), nn . Upsample ( scale_factor =  ), nn . Conv2d ( 128 , 64 , kernel_size =  , padding =  ), nn . BatchNorm2d ( 64 , momentum = .78 ), nn . ReLU (), nn . Conv2d ( 64 ,  , kernel_size =  , padding =  ), nn . Tanh () ) def forward ( self ,  ): img = self . model (  ) return img Step : Defining  Utility Class to Build the Discriminator The PyTorch code describes the discriminator architecture for  GAN. The class Discriminator is descended from nn.Module. It is composed of linear layers, batch normalization, dropout , convolutional, LeakyReLU , and sequential layers. An image (img) is the discriminator’ input, and its validity—the probability that the input image is real as opposed to artificial—is its output. Python # Define the discriminator class Discriminator ( nn . Module ): def __init__ ( self ): super ( Discriminator , self ) . __init__ () self . model = nn . Sequential ( nn . Conv2d (  , 32 , kernel_size =  , stride =  , padding =  ), nn . LeakyReLU ( . ), nn . Dropout ( .25 ), nn . Conv2d ( 32 , 64 , kernel_size =  , stride =  , padding =  ), nn . ZeroPad2d ((  ,  ,  ,  )), nn . BatchNorm2d ( 64 , momentum = .82 ), nn . LeakyReLU ( .25 ), nn . Dropout ( .25 ), nn . Conv2d ( 64 , 128 , kernel_size =  , stride =  , padding =  ), nn . BatchNorm2d ( 128 , momentum = .82 ), nn . LeakyReLU ( . ), nn . Dropout ( .25 ), nn . Conv2d ( 128 , 256 , kernel_size =  , stride =  , padding =  ), nn . BatchNorm2d ( 256 , momentum = . ), nn . LeakyReLU ( .25 ), nn . Dropout ( .25 ), nn . Flatten (), nn . Linear ( 256 *  *  ,  ), nn . Sigmoid () ) def forward ( self , img ): validity = self . model ( img ) return validity Step : Building the Generative Adversarial Network The code snippet defines and initializes  discriminator (Discriminator) and  generator (Generator). The designated device (GPU if available) receives both models. Binary Cross Entropy Loss, which is frequently used for GANs, is selected as the loss function (adversarial_loss). For the generator (optimizer_G) and discriminator (optimizer_D), distinct Adam optimizers with predetermined learning rates and betas are also defined. Python # Define the generator and discriminator # Initialize generator and discriminator generator = Generator ( latent_dim ) . to ( device ) discriminator = Discriminator () . to ( device ) # Loss function adversarial_loss = nn . BCELoss () # Optimizers optimizer_G = optim . Adam ( generator . parameters () \ , lr = lr , betas = ( beta1 , beta2 )) optimizer_D = optim . Adam ( discriminator . parameters () \ , lr = lr , betas = ( beta1 , beta2 )) Step : Training the Generative Adversarial Network For  Generative Adversarial Network (GAN), the code implements the training loop. The training data batches are iterated through during each epoch. Whereas the generator (optimizer_G) is trained to generate realistic images that trick the discriminator, the discriminator (optimizer_D) is trained to distinguish between real and phony images. The generator and discriminator’ adversarial losses are computed. Model parameters are updated by means of Adam optimizers and the losses are backpropagated. Discriminator printing and generator losses are used to track progress. For  visual assessment of the training process, generated images are additionally saved and shown every 10 epochs. Python # Training loop for epoch in range ( num_epochs ): for  , batch in enumerate ( dataloader ): # Convert list to tensor real_images = batch [  ] . to ( device ) # Adversarial ground truths valid = torch . ones ( real_images . size (  ),  , device = device ) fake = torch . zeros ( real_images . size (  ),  , device = device ) # Configure input real_images = real_images . to ( device ) # --------------------- # Train Discriminator # --------------------- optimizer_D . zero_grad () # Sample noise as generator input  = torch . randn ( real_images . size (  ), latent_dim , device = device ) # Generate  batch of images fake_images = generator (  ) # Measure discriminator' ability # to classify real and fake images real_loss = adversarial_loss ( discriminator \ ( real_images ), valid ) fake_loss = adversarial_loss ( discriminator \ ( fake_images . detach ()), fake ) d_loss = ( real_loss + fake_loss ) /  # Backward pass and optimize d_loss . backward () optimizer_D . step () # ----------------- # Train Generator # ----------------- optimizer_G . zero_grad () # Generate  batch of images gen_images = generator (  ) # Adversarial loss g_loss = adversarial_loss ( discriminator ( gen_images ), valid ) # Backward pass and optimize g_loss . backward () optimizer_G . step () # --------------------- # Progress Monitoring # --------------------- if (  +  ) % 100 ==  : print (  "Epoch [ { epoch +  } / { num_epochs } ] \ Batch {  +  } / { len ( dataloader ) } "  "Discriminator Loss: { d_loss . item () : .4f } "  "Generator Loss: { g_loss . item () : .4f } " ) # Save generated images for every epoch if ( epoch +  ) % 10 ==  : with torch . no_grad ():  = torch . randn ( 16 , latent_dim , device = device ) generated = generator (  ) . detach () . cpu () grid = torchvision . utils . make_grid ( generated , \ nrow =  , normalize = True ) plt . imshow ( np . transpose ( grid , (  ,  ,  ))) plt . axis ( "off" ) plt . show () Output: Epoch [10/10] Batch 1300/1563 Discriminator Loss: .4473 Generator Loss: .9555 Epoch [10/10] Batch 1400/1563 Discriminator Loss: .6643 Generator Loss: .0215 Epoch [10/10] Batch 1500/1563 Discriminator Loss: .4720 Generator Loss: .5027 GAN Output Application Of Generative Adversarial Networks (GANs) GANs, or Generative Adversarial Networks, have many uses in many different fields. Here are some of the widely recognized uses of GANs: Image Synthesis and Generation : GANs are often used for picture synthesis and generation tasks, They may create fresh, lifelike pictures that mimic training data by learning the distribution that explains the dataset. The development of lifelike avatars, high-resolution photographs, and fresh artwork have all been facilitated by these types of generative networks. Image-to-Image Translation : GANs may be used for problems involving image-to-image translation, where the objective is to convert an input picture from one domain to another while maintaining its key features. GANs may be used, for instance, to change pictures from day to night, transform drawings into realistic images, or change the creative style of an image. Text-to-Image Synthesis : GANs have been used to create visuals from descriptions in text. GANs may produce pictures that translate to  description given  text input, such as  phrase or  caption. This application might have an impact on how realistic visual material is produced using text-based instructions. Data Augmentation : GANs can augment present data and increase the robustness and generalizability of machine-learning models by creating synthetic data samples. Data Generation for Training : GANs can enhance the resolution and quality of low-resolution images. By training on pairs of low-resolution and high-resolution images, GANs can generate high-resolution images from low-resolution inputs, enabling improved image quality in various applications such as medical imaging, satellite imaging, and video enhancement. Advantages of GAN The advantages of the GANs are as follows: Synthetic data generation : GANs can generate new, synthetic data that resembles some known data distribution, which can be useful for data augmentation, anomaly detection, or creative applications. High-quality results : GANs can produce high-quality, photorealistic results in image synthesis, video synthesis, music synthesis, and other tasks. Unsupervised learning : GANs can be trained without labeled data, making them suitable for unsupervised learning tasks, where labeled data is scarce or difficult to obtain. Versatility : GANs can be applied to  wide range of tasks, including image synthesis, text-to-image synthesis, image-to-image translation, anomaly detection , data augmentation , and others. Disadvantages of GAN The disadvantages of the GANs are as follows: Training Instability : GANs can be difficult to train, with the risk of instability, mode collapse, or failure to converge. Computational Cost : GANs can require  lot of computational resources and can be slow to train, especially for high-resolution images or large datasets. Overfitting : GANs can overfit the training data, producing synthetic data that is too similar to the training data and lacking diversity. Bias and Fairness : GANs can reflect the biases and unfairness present in the training data, leading to discriminatory or biased synthetic data. Interpretability and Accountability : GANs can be opaque and difficult to interpret or explain, making it challenging to ensure accountability, transparency, or fairness in their applications. Generative Adversarial Network (GAN) – FAQs What is  Generative Adversarial Network(GAN)? An artificial intelligence model known as  GAN is made up of two neural networks— discriminator and  generator—that were developed in tandem using adversarial training. The discriminator assesses the new data instances for authenticity, while the generator produces new ones. What are the main applications of GAN? Generating images and videos, transferring styles, enhancing data, translating images to other images, producing realistic synthetic data for machine learning model training, and super-resolution are just  few of the many uses for GANs. What challenges do GAN face? GANs encounter difficulties such training instability, mode collapse (when the generator generates  limited range of samples), and striking the correct balance between the discriminator and generator. It’ frequently necessary to carefully build the model architecture and tune the hyperparameters. How are GAN evaluated? The produced samples’ quality, diversity, and resemblance to real data are the main criteria used to assess GANs. For quantitative assessment, metrics like the Fréchet Inception Distance (FID) and Inception Score are frequently employed. Can GAN be used for tasks other than image generation ? Yes, different tasks can be assigned to GANs. Text, music, 3D models, and other things have all been generated with them. The usefulness of conditional GANs is expanded by enabling the creation of specific content under certain input conditions. What are some famous architectures of GANs ?  few well-known GAN architectures are Progressive GAN (PGAN), Wasserstein GAN (WGAN), Conditional GAN (cGAN), Deep Convolutional GAN (DCGAN), and Vanilla GAN. Each has special qualities and works best with particular kinds of data and tasks.  Rahul_Roy Follow Improve Previous Article Basics of Generative Adversarial Networks (GANs) Next Article Use Cases of Generative Adversarial Networks Please Login to comment... Read More Similar Reads What is so special about Generative Adversarial Network (GAN) Fans are ecstatic for  variety of reasons, including the fact that GANs were the first generative algorithms to produce convincingly good results, as well as the fact that they have opened up many new research directions. In the last several years, GANs are considered to be the most prominent machine learning research, and since then, GANs have re  min read Selection of GAN vs Adversarial Autoencoder models In this article, we are going to see the selection of GAN vs Adversarial Autoencoder models. Generative Adversarial Network (GAN)The Generative Adversarial Network, or GAN, is one of the most prominent deep generative modeling methodologies right now. The primary distinction between GAN and VAE is that GAN seeks to match the pixel level distributio  min read Building  Generative Adversarial Network using Keras Prerequisites: Generative Adversarial Network This article will demonstrate how to build  Generative Adversarial Network using the Keras library. The dataset which is used is the CIFAR10 Image dataset which is preloaded into Keras. You can read about the dataset here. Step : Importing the required libraries import numpy as np import matplotlib.py  min read Conditional Generative Adversarial Network Imagine  situation where you can generate images of cats that match your ideal vision or  landscape that adheres to  specific artistic style. CGANs is  neural network that enables the generation of data that aligns with specific properties, which can be class labels, textual descriptions, or other traits, by harnessing the power of conditions. 13 min read Generative Adversarial Networks (GANs) | An Introduction Generative Adversarial Networks (GANs) was first introduced by Ian Goodfellow in 2014. GANs are  powerful class of neural networks that are used for unsupervised learning. GANs can create anything whatever you feed to them, as it Learn-Generate-Improve. To understand GANs first you must have little understanding of Convolutional Neural Networks.   min read Wasserstein Generative Adversarial Networks (WGANs) Convergence and Optimization Wasserstein Generative Adversarial Network (WGANs) is  modification of Deep Learning GAN with few changes in the algorithm. GAN, or Generative Adversarial Network, is  way to build an accurate generative model. This network was introduced by Martin Arjovsky, Soumith Chintala, and Léon Bottou in 2017. It is widely used to generate realistic images  min read Generative Adversarial Networks (GANs) in PyTorch The aim of the article is to implement GANs architecture using PyTorch framework. The article provides comprehensive understanding of GANs in PyTorch along with in-depth explanation of the code. Generative Adversarial Networks (GANs) are  class of artificial intelligence algorithms used in unsupervised machine learning. They consist of two neural  min read Image Generation using Generative Adversarial Networks (GANs) Generative Adversarial Networks (GANs) represent  revolutionary approach to, artificial intelligence, particularly for generating images. Introduced in 2014, GANs have significantly advanced the ability to create realistic and high-quality images from random noise. In this article, we are going to train GANs model on MNIST dataset for generating   min read Architecture of Super-Resolution Generative Adversarial Networks (SRGANs) Super-Resolution Generative Adversarial Networks (SRGANs) are advanced deep learning models designed to upscale low-resolution images to high-resolution outputs with remarkable detail. This article aims to provide  comprehensive overview of SRGANs, focusing on their architecture, key components, and training techniques to enhance image quality. Ta  min read Generative Adversarial Networks (GANs) with  Generative Adversarial Networks (GANs) are  type of neural network architecture introduced by Ian Goodfellow and his colleagues in 2014. GANs are designed to generate new data samples that resemble  given dataset. They can produce high-quality synthetic data across various domains. Working of GANsGANs consist of two neural networks. first is the 15 min read Generative Adversarial Networks (GANs) vs Diffusion Models Generative Adversarial Networks (GANs) and Diffusion Models are powerful generative models designed to produce synthetic data that closely resembles real-world data. Each model has distinct architectures, strengths, and limitations, making them uniquely suited for various applications. This article aims to provide  comprehensive comparison between  min read Mastering Adversarial Attacks: How One Pixel Can Fool  Neural Network Neural networks are among the best tools for classification tasks. They power everything from image recognition to natural language processing, providing incredible accuracy and versatility. But what if  told you that you could completely undermine  neural network or trick it into making mistakes? Intrigued? Let' explore adversarial attacks and  min read Deep Convolutional GAN with Keras Deep Convolutional GAN (DCGAN) was proposed by  researcher from MIT and Facebook AI research. It is widely used in many convolution-based generation-based techniques. The focus of this paper was to make training GANs stable. Hence, they proposed some architectural changes in the computer vision problems. In this article, we will be using DCGAN on  min read Understanding Auxiliary Classifier : GAN Prerequisite: GANs(General Adversarial Networks) In this article, we will be discussing  special class conditional GAN or -GAN known as Auxiliary Classifier GAN or AC-GAN. Before getting into that, it is important to understand what  class conditional GAN is. Class-Conditional GAN (-GANs): -GAN can be understood as  GAN with some conditional  min read Building an Auxiliary GAN using Keras and Tensorflow Prerequisites: Generative Adversarial Network This article will demonstrate how to build an Auxiliary Generative Adversarial Network using the Keras and TensorFlow libraries. The dataset which is used is the MNIST Image dataset pre-loaded into Keras. Step : Setting up the environment Step  : Open Anaconda prompt in Administrator mode. Step  : Cr  min read Difference between GAN vs DCGAN. Answer: GAN is  broader class of generative models, while DCGAN specifically refers to  type of GAN that utilizes deep convolutional neural networks for image generation.Below is  detailed comparison between GAN (Generative Adversarial Network) and DCGAN (Deep Convolutional Generative Adversarial Network): FeatureGANDCGANArchitectureGeneric arch  min read Adversarial Search Algorithms Adversarial search algorithms are the backbone of strategic decision-making in artificial intelligence, it enables the agents to navigate competitive scenarios effectively. This article offers concise yet comprehensive advantages of these algorithms from their foundational principles to practical applications. Let' uncover the strategies that driv 15+ min read Alpha-Beta pruning in Adversarial Search Algorithms In artificial intelligence, particularly in game playing and decision-making, adversarial search algorithms are used to model and solve problems where two or more players compete against each other. One of the most well-known techniques in this domain is alpha-beta pruning. This article explores the concept of alpha-beta pruning, its implementation  min read Explain the role of minimax algorithm in adversarial search for optimal decision-making? In the realm of artificial intelligence (AI), particularly in game theory and decision-making scenarios involving competition, the ability to predict and counteract an opponent' moves is paramount. This is where adversarial search algorithms come into play. Among the most prominent and foundational of these algorithms is the Minimax algorithm. It 11 min read Pandas AI: The Generative AI Python Library In the age of AI, many of our tasks have been automated especially after the launch of ChatGPT. One such tool that uses the power of ChatGPT to ease data manipulation task in Python is PandasAI. It leverages the power of ChatGPT to generate Python code and executes it. The output of the generated code is returned. Pandas AI helps performing tasks   min read The Difference Between Generative and Discriminative Machine Learning Algorithms Machine learning algorithms allow computers to learn from data and make predictions or judgments, machine learning algorithms have revolutionized  number of sectors. Generic and discriminative algorithms are two essential strategies with various applications in the field of machine learning. We will examine the core distinctions between generative  min read What is Language Revitalization in Generative AI? Imagine  world where ancient tongues, on the brink of fading into silence, are reborn. Where stories whispered through generations find  digital echo and cultural knowledge carried in every syllable is amplified across the internet. This is the promise of language revitalization in generative AI,  revolutionary field that seeks to leverage the   min read Differences between Conversational AI and Generative AI Artificial intelligence has evolved significantly in the past few years, making day-to-day tasks easy and efficient. Conversational AI and Generative AI are the two subsets of artificial intelligence that rapidly advancing the field of AI and have become prominent and transformative. Both technologies make use of machine learning and natural langua  min read 10 Best Generative AI Tools to Refine Your Content Strategy Many of us struggle with content creation and strategy. We're good at the creative, artful side, like writing compelling stories. But the analytical, strategic part is harder. Even when we do get strategic, we spend lots of time on keyword research, topic selection, and tracking performance. AI content tools can give you an advantage on the science  min read  Top Generative AI Design Tools in 2024 [Free & Paid] Are you ready to level up your design game? Gone are the days when designers had to sit and design creatives from scratch. With the rise of artificial intelligence and its integration with different domains, you can save  lot of time and still come up with quality output. You can use these tools in generating base designs and even assist the whole  min read What is Generative AI? Nowadays as we all know the power of Artificial Intelligence is developing day by day, and after the introduction of Generative AI is taking creativity to the next level Generative AI is  subset of Deep learning that is again  part of Artificial Intelligence. In this article, we will explore, What is Generative AI? Examples, Definition, Models 12 min read What is the difference between Generative and Discriminative algorithm? Answer: Generative algorithms model the joint probability distribution of input features and target labels, while discriminative algorithms directly learn the decision boundary between classes.Generative algorithms focus on modeling the joint probability distribution of both input features and target labels. By capturing statistical dependencies wi  min read  Best Generative AI Tools for Developers [2024] In the rapidly evolving world of technology, generative Artificial intelligence (AI) tools for developers have become indispensable assets for innovation and efficiency. These cutting-edge tools harness the power of advanced algorithms and machine learning techniques to autonomously generate content, designs, and code, transforming the development  min read Generative Modeling in TensorFlow Generative modeling is the process of learning the underlying structure of  dataset to generate new samples that mimic the distribution of the original data. The article aims to provide  comprehensive overview of generative modelling along with the implementation leveraging the TensorFlow framework. Table of Content What are generative models and 14 min read AI-Coustics: Fights Noisy Audio With Generative AI Have you ever been troubled by noisy audio during  video call or interview? The constant hum of traffic, the rustle of wind, or even  bustling room can significantly degrade audio quality. For content creators, journalists, and anyone relying on clean audio recording and speech clarity in videos, these challenges can be  major source of frustrat  min read Article Tags : AI-ML-DS Deep Learning Python Python-Quizzes Technical Scripter python + More Practice Tags : python python Like 285k+ interested Geeks Data Structures & Algorithms in Python - Self Paced Explore 198k+ interested Geeks Python Full Course Online - Complete Beginner to Advanced Explore 927k+ interested Geeks Complete Interview Preparation Explore Explore More Read more ## Generative Adversarial Network (GAN) Open In App Share Your Experiences Deep Learning Tutorial Introduction to Deep Learning Introduction to Deep Learning Difference Between Artificial Intelligence vs Machine Learning vs Deep Learning Basic Neural Network Difference between ANN and BNN Single Layer Perceptron in TensorFlow Multi-Layer Perceptron Learning in Tensorflow Deep Neural net with forward and back propagation from scratch - Python Understanding Multi-Layer Feed Forward Networks List of Deep Learning Layers Activation Functions Activation Functions Types Of Activation Function in ANN Activation Functions in Pytorch Understanding Activation Functions in Depth Artificial Neural Network Artificial Neural Networks and its Applications Gradient Descent Optimization in Tensorflow Choose Optimal Number of Epochs to Train  Neural Network in Keras Classification Python | Classify Handwritten Digits with Tensorflow Train  Deep Learning Model With Pytorch Regression Linear Regression using PyTorch Linear Regression Using Tensorflow Hyperparameter tuning Hyperparameter tuning Introduction to Convolution Neural Network Introduction to Convolution Neural Network Digital Image Processing Basics Difference between Image Processing and Computer Vision CNN | Introduction to Pooling Layer CIFAR-10 Image Classification in TensorFlow Implementation of  CNN based Image Classifier using PyTorch Convolutional Neural Network (CNN) Architectures Object Detection vs Object Recognition vs Image Segmentation YOLO v2 - Object Detection Recurrent Neural Network Natural Language Processing (NLP) Tutorial Introduction to NLTK: Tokenization, Stemming, Lemmatization, POS Tagging Word Embeddings in NLP Introduction to Recurrent Neural Network Recurrent Neural Networks Explanation Sentiment Analysis with an Recurrent Neural Networks (RNN) Short term Memory What is LSTM - Long Short Term Memory? Long Short Term Memory Networks Explanation LSTM - Derivation of Back propagation through time Text Generation using Recurrent Long Short Term Memory Network Gated Recurrent Unit Networks Gated Recurrent Unit Networks ML | Text Generation using Gated Recurrent Unit Networks Generative Learning Autoencoders -Machine Learning How Autoencoders works ? Variational AutoEncoders Contractive Autoencoder (CAE) ML | AutoEncoder with TensorFlow . Implementing an Autoencoder in PyTorch Generative adversarial networks Basics of Generative Adversarial Networks (GANs) Generative Adversarial Network (GAN) Use Cases of Generative Adversarial Networks Building  Generative Adversarial Network using Keras Cycle Generative Adversarial Network (CycleGAN) StyleGAN - Style Generative Adversarial Networks Reinforcement Learning Understanding Reinforcement Learning in-depth Introduction to Thompson Sampling | Reinforcement Learning Markov Decision Process Bellman Equation Meta-Learning in Machine Learning -Learning in Python -Learning ML | Reinforcement Learning Algorithm : Python Implementation using -learning Deep  Learning Deep -Learning Implementing Deep -Learning using Tensorflow AI Driven Snake Game using Deep  Learning Deep Learning Interview Questions Machine Learning & Data Science Course Generative Adversarial Network (GAN) Last Updated : 09 Aug, 2024 Comments Improve Summarize Suggest changes Like Article Like Save Share Report Follow GAN (Generative Adversarial Network) represents  cutting-edge approach to generative modeling within deep learning, often leveraging architectures like convolutional neural networks . The goal of generative modeling is to autonomously identify patterns in input data, enabling the model to produce new examples that feasibly resemble the original dataset. This article covers everything you need to know about GAN, the Architecture of GAN, the Workings of GAN, and types of GAN Models, and so on. Table of Content What is  Generative Adversarial Network? Types of GANs Architecture of GANs How does  GAN work? Implementation of  GAN Application Of Generative Adversarial Networks (GANs) Advantages of GAN Disadvantages of GAN GAN(Generative Adversarial Network)- FAQs What is  Generative Adversarial Network? Generative Adversarial Networks (GANs) are  powerful class of neural networks that are used for an unsupervised learning . GANs are made up of two neural networks ,  discriminator and  generator. They use adversarial training to produce artificial data that is identical to actual data. The Generator attempts to fool the Discriminator, which is tasked with accurately distinguishing between produced and genuine data, by producing random noise samples. Realistic, high-quality samples are produced as  result of this competitive interaction, which drives both networks toward advancement. GANs are proving to be highly versatile artificial intelligence tools, as evidenced by their extensive use in image synthesis, style transfer, and text-to-image synthesis. They have also revolutionized generative modeling. Through adversarial training, these models engage in  competitive interplay until the generator becomes adept at creating realistic samples, fooling the discriminator approximately half the time. Generative Adversarial Networks (GANs) can be broken down into three parts: Generative: To learn  generative model, which describes how data is generated in terms of  probabilistic model. Adversarial: The word adversarial refers to setting one thing up against another. This means that, in the context of GANs, the generative result is compared with the actual images in the data set.  mechanism known as  discriminator is used to apply  model that attempts to distinguish between real and fake images. Networks: Use deep neural networks as artificial intelligence (AI) algorithms for training purposes. Types of GANs Vanilla GAN: This is the simplest type of GAN. Here, the Generator and the Discriminator are simple  basic multi-layer perceptrons . In vanilla GAN, the algorithm is really simple, it tries to optimize the mathematical equation using stochastic gradient descent. Conditional GAN (CGAN): CGAN can be described as  deep learning method in which some conditional parameters are put into place . In CGAN, an additional parameter ‘’ is added to the Generator for generating the corresponding data. Labels are also put into the input to the Discriminator in order for the Discriminator to help distinguish the real data from the fake generated data. Deep Convolutional GAN (DCGAN): DCGAN is one of the most popular and also the most successful implementations of GAN. It is composed of ConvNets in place of multi-layer perceptrons . The ConvNets are implemented without max pooling, which is in fact replaced by convolutional stride. Also, the layers are not fully connected. Laplacian Pyramid GAN (LAPGAN): The Laplacian pyramid is  linear invertible image representation consisting of  set of band-pass images, spaced an octave apart, plus  low-frequency residual. This approach uses multiple numbers of Generator and Discriminator networks and different levels of the Laplacian Pyramid. This approach is mainly used because it produces very high-quality images. The image is down-sampled at first at each layer of the pyramid and then it is again up-scaled at each layer in  backward pass where the image acquires some noise from the Conditional GAN at these layers until it reaches its original size. Super Resolution GAN (SRGAN): SRGAN as the name suggests is  way of designing  GAN in which  deep neural network is used along with an adversarial network in order to produce higher-resolution images. This type of GAN is particularly useful in optimally up-scaling native low-resolution images to enhance their details minimizing errors while doing so. Architecture of GANs  Generative Adversarial Network (GAN) is composed of two primary parts, which are the Generator and the Discriminator. Generator Model  key element responsible for creating fresh, accurate data in  Generative Adversarial Network (GAN) is the generator model. The generator takes random noise as input and converts it into complex data samples, such text or images. It is commonly depicted as  deep neural network. The training data’ underlying distribution is captured by layers of learnable parameters in its design through training. The generator adjusts its output to produce samples that closely mimic real data as it is being trained by using backpropagation to fine-tune its parameters. The generator’ ability to generate high-quality, varied samples that can fool the discriminator is what makes it successful. Generator Loss The objective of the generator in  GAN is to produce synthetic samples that are realistic enough to fool the discriminator. The generator achieves this by minimizing its loss function [Tex]J_G[/Tex] ​. The loss is minimized when the log probability is maximized, .., when the discriminator is highly likely to classify the generated samples as real. The following equation is given below: [Tex]J_{} = -\frac{}{} \Sigma^ {=} log ((z_{})) [/Tex] Where, [Tex]J_G[/Tex] measure how well the generator is fooling the discriminator. log [Tex]((z_i) )[/Tex] represents log probability of the discriminator being correct for generated samples. The generator aims to minimize this loss, encouraging the production of samples that the discriminator classifies as real [Tex](log ((z_i))[/Tex] , close to . Discriminator Model An artificial neural network called  discriminator model is used in Generative Adversarial Networks (GANs) to differentiate between generated and actual input. By evaluating input samples and allocating probability of authenticity, the discriminator functions as  binary classifier. Over time, the discriminator learns to differentiate between genuine data from the dataset and artificial samples created by the generator. This allows it to progressively hone its parameters and increase its level of proficiency. Convolutional layers or pertinent structures for other modalities are usually used in its architecture when dealing with picture data. Maximizing the discriminator’ capacity to accurately identify generated samples as fraudulent and real samples as authentic is the aim of the adversarial training procedure. The discriminator grows increasingly discriminating as  result of the generator and discriminator’ interaction, which helps the GAN produce extremely realistic-looking synthetic data overall. Discriminator Loss The discriminator reduces the negative log likelihood of correctly classifying both produced and real samples. This loss incentivizes the discriminator to accurately categorize generated samples as fake and real samples with the following equation: [Tex]J_{} = -\frac{}{} \Sigma_{=}^ log\; (x_{}) – \frac{}{}\Sigma_{=}^ log( – ((z_{})) [/Tex] [Tex]J_D[/Tex] assesses the discriminator’ ability to discern between produced and actual samples. The log likelihood that the discriminator will accurately categorize real data is represented by [Tex]logD(x_i)[/Tex] . The log chance that the discriminator would correctly categorize generated samples as fake is represented by [Tex]log⁡(-((z_i)))[/Tex] . The discriminator aims to reduce this loss by accurately identifying artificial and real samples. MinMax Loss In  Generative Adversarial Network (GAN), the minimax loss formula is provided by: [Tex]min_{}\;max_{}(,) = [\mathbb{}{∼p_{data}}[log\;()] + \mathbb{}{∼p_{}()}[log( – (()))] [/Tex] Where,  is generator network and is  is the discriminator network Actual data samples obtained from the true data distribution [Tex]p_{data}() [/Tex] are represented by . Random noise sampled from  previous distribution [Tex]p_z() [/Tex] (usually  normal or uniform distribution) is represented by . () represents the discriminator’ likelihood of correctly identifying actual data as real. (()) is the likelihood that the discriminator will identify generated data coming from the generator as authentic. How does  GAN work? The steps involved in how  GAN works: Initialization: Two neural networks are created:  Generator () and  Discriminator ().  is tasked with creating new data, like images or text, that closely resembles real data.  acts as  critic, trying to distinguish between real data (from  training dataset) and the data generated by . Generator’ First Move:  takes  random noise vector as input. This noise vector contains random values and acts as the starting point for ’ creation process. Using its internal layers and learned patterns,  transforms the noise vector into  new data sample, like  generated image. Discriminator’ Turn:  receives two kinds of inputs: Real data samples from the training dataset. The data samples generated by  in the previous step. ’ job is to analyze each input and determine whether it’ real data or something  cooked up. It outputs  probability score between  and .  score of  indicates the data is likely real, and  suggests it’ fake. The Learning Process: Now, the adversarial part comes in: If  correctly identifies real data as real (score close to ) and generated data as fake (score close to ), both  and  are rewarded to  small degree. This is because they’re both doing their jobs well. However, the key is to continuously improve. If  consistently identifies everything correctly, it won’ learn much. So, the goal is for  to eventually trick . Generator’ Improvement: When  mistakenly labels ’ creation as real (score close to ), it’  sign that  is on the right track. In this case,  receives  significant positive update, while  receives  penalty for being fooled. This feedback helps  improve its generation process to create more realistic data. Discriminator’ Adaptation: Conversely, if  correctly identifies ’ fake data (score close to ), but  receives no reward,  is further strengthened in its discrimination abilities. This ongoing duel between  and  refines both networks over time. As training progresses,  gets better at generating realistic data, making it harder for  to tell the difference. Ideally,  becomes so adept that  can’ reliably distinguish real from fake data. At this point,  is considered well-trained and can be used to generate new, realistic data samples. Implementation of Generative Adversarial Network (GAN) We will follow and understand the steps to understand how GAN is implemented: Step1 : Importing the required libraries Python import torch import torch.nn as nn import torch.optim as optim import torchvision from torchvision import datasets , transforms import matplotlib.pyplot as plt import numpy as np # Set device device = torch . device ( 'cuda' if torch . cuda . is_available () else 'cpu' ) For training on the CIFAR-10 image dataset, this PyTorch module creates  Generative Adversarial Network (GAN), switching between generator and discriminator training. Visualization of the generated images occurs every tenth epoch, and the development of the GAN is tracked. Step : Defining  Transform The code uses PyTorch’ transforms to define  simple picture transforms.Compose. It normalizes and transforms photos into tensors. Python # Define  basic transform transform = transforms . Compose ([ transforms . ToTensor (), transforms . Normalize (( . , . , . ), ( . , . , . )) ]) Step : Loading the Dataset  CIFAR-10 dataset is created for training with below code, which also specifies  root directory, turns on train mode, downloads if needed, and applies the specified transform. Subsequently, it generates  32-batch DataLoader and shuffles the training set of data. Python train_dataset = datasets . CIFAR10 ( root = './data' , \ train = True , download = True , transform = transform ) dataloader = torch . utils . data . DataLoader ( train_dataset , \ batch_size = 32 , shuffle = True ) Step : Defining parameters to be used in later processes  Generative Adversarial Network (GAN) is used with specified hyperparameters. The latent space’ dimensionality is represented by latent_dim. lr is the optimizer’ learning rate. The coefficients for the Adam optimizer are beta1 and beta2. To find the total number of training epochs, use num_epochs. Python # Hyperparameters latent_dim = 100 lr = .0002 beta1 = . beta2 = .999 num_epochs = 10 Step : Defining  Utility Class to Build the Generator The generator architecture for  GAN in PyTorch is defined with below code. From nn.Module , the Generator class inherits. It is comprised of  sequential model with Tanh, linear, convolutional, batch normalization, reshaping, and upsampling layers. The neural network synthesizes an image (img) from  latent vector (), which is the generator’ output. The architecture uses  series of learned transformations to turn the initial random noise in the latent space into  meaningful image. Python # Define the generator class Generator ( nn . Module ): def __init__ ( self , latent_dim ): super ( Generator , self ) . __init__ () self . model = nn . Sequential ( nn . Linear ( latent_dim , 128 *  *  ), nn . ReLU (), nn . Unflatten (  , ( 128 ,  ,  )), nn . Upsample ( scale_factor =  ), nn . Conv2d ( 128 , 128 , kernel_size =  , padding =  ), nn . BatchNorm2d ( 128 , momentum = .78 ), nn . ReLU (), nn . Upsample ( scale_factor =  ), nn . Conv2d ( 128 , 64 , kernel_size =  , padding =  ), nn . BatchNorm2d ( 64 , momentum = .78 ), nn . ReLU (), nn . Conv2d ( 64 ,  , kernel_size =  , padding =  ), nn . Tanh () ) def forward ( self ,  ): img = self . model (  ) return img Step : Defining  Utility Class to Build the Discriminator The PyTorch code describes the discriminator architecture for  GAN. The class Discriminator is descended from nn.Module. It is composed of linear layers, batch normalization, dropout , convolutional, LeakyReLU , and sequential layers. An image (img) is the discriminator’ input, and its validity—the probability that the input image is real as opposed to artificial—is its output. Python # Define the discriminator class Discriminator ( nn . Module ): def __init__ ( self ): super ( Discriminator , self ) . __init__ () self . model = nn . Sequential ( nn . Conv2d (  , 32 , kernel_size =  , stride =  , padding =  ), nn . LeakyReLU ( . ), nn . Dropout ( .25 ), nn . Conv2d ( 32 , 64 , kernel_size =  , stride =  , padding =  ), nn . ZeroPad2d ((  ,  ,  ,  )), nn . BatchNorm2d ( 64 , momentum = .82 ), nn . LeakyReLU ( .25 ), nn . Dropout ( .25 ), nn . Conv2d ( 64 , 128 , kernel_size =  , stride =  , padding =  ), nn . BatchNorm2d ( 128 , momentum = .82 ), nn . LeakyReLU ( . ), nn . Dropout ( .25 ), nn . Conv2d ( 128 , 256 , kernel_size =  , stride =  , padding =  ), nn . BatchNorm2d ( 256 , momentum = . ), nn . LeakyReLU ( .25 ), nn . Dropout ( .25 ), nn . Flatten (), nn . Linear ( 256 *  *  ,  ), nn . Sigmoid () ) def forward ( self , img ): validity = self . model ( img ) return validity Step : Building the Generative Adversarial Network The code snippet defines and initializes  discriminator (Discriminator) and  generator (Generator). The designated device (GPU if available) receives both models. Binary Cross Entropy Loss, which is frequently used for GANs, is selected as the loss function (adversarial_loss). For the generator (optimizer_G) and discriminator (optimizer_D), distinct Adam optimizers with predetermined learning rates and betas are also defined. Python # Define the generator and discriminator # Initialize generator and discriminator generator = Generator ( latent_dim ) . to ( device ) discriminator = Discriminator () . to ( device ) # Loss function adversarial_loss = nn . BCELoss () # Optimizers optimizer_G = optim . Adam ( generator . parameters () \ , lr = lr , betas = ( beta1 , beta2 )) optimizer_D = optim . Adam ( discriminator . parameters () \ , lr = lr , betas = ( beta1 , beta2 )) Step : Training the Generative Adversarial Network For  Generative Adversarial Network (GAN), the code implements the training loop. The training data batches are iterated through during each epoch. Whereas the generator (optimizer_G) is trained to generate realistic images that trick the discriminator, the discriminator (optimizer_D) is trained to distinguish between real and phony images. The generator and discriminator’ adversarial losses are computed. Model parameters are updated by means of Adam optimizers and the losses are backpropagated. Discriminator printing and generator losses are used to track progress. For  visual assessment of the training process, generated images are additionally saved and shown every 10 epochs. Python # Training loop for epoch in range ( num_epochs ): for  , batch in enumerate ( dataloader ): # Convert list to tensor real_images = batch [  ] . to ( device ) # Adversarial ground truths valid = torch . ones ( real_images . size (  ),  , device = device ) fake = torch . zeros ( real_images . size (  ),  , device = device ) # Configure input real_images = real_images . to ( device ) # --------------------- # Train Discriminator # --------------------- optimizer_D . zero_grad () # Sample noise as generator input  = torch . randn ( real_images . size (  ), latent_dim , device = device ) # Generate  batch of images fake_images = generator (  ) # Measure discriminator' ability # to classify real and fake images real_loss = adversarial_loss ( discriminator \ ( real_images ), valid ) fake_loss = adversarial_loss ( discriminator \ ( fake_images . detach ()), fake ) d_loss = ( real_loss + fake_loss ) /  # Backward pass and optimize d_loss . backward () optimizer_D . step () # ----------------- # Train Generator # ----------------- optimizer_G . zero_grad () # Generate  batch of images gen_images = generator (  ) # Adversarial loss g_loss = adversarial_loss ( discriminator ( gen_images ), valid ) # Backward pass and optimize g_loss . backward () optimizer_G . step () # --------------------- # Progress Monitoring # --------------------- if (  +  ) % 100 ==  : print (  "Epoch [ { epoch +  } / { num_epochs } ] \ Batch {  +  } / { len ( dataloader ) } "  "Discriminator Loss: { d_loss . item () : .4f } "  "Generator Loss: { g_loss . item () : .4f } " ) # Save generated images for every epoch if ( epoch +  ) % 10 ==  : with torch . no_grad ():  = torch . randn ( 16 , latent_dim , device = device ) generated = generator (  ) . detach () . cpu () grid = torchvision . utils . make_grid ( generated , \ nrow =  , normalize = True ) plt . imshow ( np . transpose ( grid , (  ,  ,  ))) plt . axis ( "off" ) plt . show () Output: Epoch [10/10] Batch 1300/1563 Discriminator Loss: .4473 Generator Loss: .9555 Epoch [10/10] Batch 1400/1563 Discriminator Loss: .6643 Generator Loss: .0215 Epoch [10/10] Batch 1500/1563 Discriminator Loss: .4720 Generator Loss: .5027 GAN Output Application Of Generative Adversarial Networks (GANs) GANs, or Generative Adversarial Networks, have many uses in many different fields. Here are some of the widely recognized uses of GANs: Image Synthesis and Generation : GANs are often used for picture synthesis and generation tasks, They may create fresh, lifelike pictures that mimic training data by learning the distribution that explains the dataset. The development of lifelike avatars, high-resolution photographs, and fresh artwork have all been facilitated by these types of generative networks. Image-to-Image Translation : GANs may be used for problems involving image-to-image translation, where the objective is to convert an input picture from one domain to another while maintaining its key features. GANs may be used, for instance, to change pictures from day to night, transform drawings into realistic images, or change the creative style of an image. Text-to-Image Synthesis : GANs have been used to create visuals from descriptions in text. GANs may produce pictures that translate to  description given  text input, such as  phrase or  caption. This application might have an impact on how realistic visual material is produced using text-based instructions. Data Augmentation : GANs can augment present data and increase the robustness and generalizability of machine-learning models by creating synthetic data samples. Data Generation for Training : GANs can enhance the resolution and quality of low-resolution images. By training on pairs of low-resolution and high-resolution images, GANs can generate high-resolution images from low-resolution inputs, enabling improved image quality in various applications such as medical imaging, satellite imaging, and video enhancement. Advantages of GAN The advantages of the GANs are as follows: Synthetic data generation : GANs can generate new, synthetic data that resembles some known data distribution, which can be useful for data augmentation, anomaly detection, or creative applications. High-quality results : GANs can produce high-quality, photorealistic results in image synthesis, video synthesis, music synthesis, and other tasks. Unsupervised learning : GANs can be trained without labeled data, making them suitable for unsupervised learning tasks, where labeled data is scarce or difficult to obtain. Versatility : GANs can be applied to  wide range of tasks, including image synthesis, text-to-image synthesis, image-to-image translation, anomaly detection , data augmentation , and others. Disadvantages of GAN The disadvantages of the GANs are as follows: Training Instability : GANs can be difficult to train, with the risk of instability, mode collapse, or failure to converge. Computational Cost : GANs can require  lot of computational resources and can be slow to train, especially for high-resolution images or large datasets. Overfitting : GANs can overfit the training data, producing synthetic data that is too similar to the training data and lacking diversity. Bias and Fairness : GANs can reflect the biases and unfairness present in the training data, leading to discriminatory or biased synthetic data. Interpretability and Accountability : GANs can be opaque and difficult to interpret or explain, making it challenging to ensure accountability, transparency, or fairness in their applications. Generative Adversarial Network (GAN) – FAQs What is  Generative Adversarial Network(GAN)? An artificial intelligence model known as  GAN is made up of two neural networks— discriminator and  generator—that were developed in tandem using adversarial training. The discriminator assesses the new data instances for authenticity, while the generator produces new ones. What are the main applications of GAN? Generating images and videos, transferring styles, enhancing data, translating images to other images, producing realistic synthetic data for machine learning model training, and super-resolution are just  few of the many uses for GANs. What challenges do GAN face? GANs encounter difficulties such training instability, mode collapse (when the generator generates  limited range of samples), and striking the correct balance between the discriminator and generator. It’ frequently necessary to carefully build the model architecture and tune the hyperparameters. How are GAN evaluated? The produced samples’ quality, diversity, and resemblance to real data are the main criteria used to assess GANs. For quantitative assessment, metrics like the Fréchet Inception Distance (FID) and Inception Score are frequently employed. Can GAN be used for tasks other than image generation ? Yes, different tasks can be assigned to GANs. Text, music, 3D models, and other things have all been generated with them. The usefulness of conditional GANs is expanded by enabling the creation of specific content under certain input conditions. What are some famous architectures of GANs ?  few well-known GAN architectures are Progressive GAN (PGAN), Wasserstein GAN (WGAN), Conditional GAN (cGAN), Deep Convolutional GAN (DCGAN), and Vanilla GAN. Each has special qualities and works best with particular kinds of data and tasks.  Rahul_Roy Follow Improve Previous Article Basics of Generative Adversarial Networks (GANs) Next Article Use Cases of Generative Adversarial Networks Please Login to comment... Read More Similar Reads What is so special about Generative Adversarial Network (GAN) Fans are ecstatic for  variety of reasons, including the fact that GANs were the first generative algorithms to produce convincingly good results, as well as the fact that they have opened up many new research directions. In the last several years, GANs are considered to be the most prominent machine learning research, and since then, GANs have re  min read Selection of GAN vs Adversarial Autoencoder models In this article, we are going to see the selection of GAN vs Adversarial Autoencoder models. Generative Adversarial Network (GAN)The Generative Adversarial Network, or GAN, is one of the most prominent deep generative modeling methodologies right now. The primary distinction between GAN and VAE is that GAN seeks to match the pixel level distributio  min read Building  Generative Adversarial Network using Keras Prerequisites: Generative Adversarial Network This article will demonstrate how to build  Generative Adversarial Network using the Keras library. The dataset which is used is the CIFAR10 Image dataset which is preloaded into Keras. You can read about the dataset here. Step : Importing the required libraries import numpy as np import matplotlib.py  min read Conditional Generative Adversarial Network Imagine  situation where you can generate images of cats that match your ideal vision or  landscape that adheres to  specific artistic style. CGANs is  neural network that enables the generation of data that aligns with specific properties, which can be class labels, textual descriptions, or other traits, by harnessing the power of conditions. 13 min read Generative Adversarial Networks (GANs) | An Introduction Generative Adversarial Networks (GANs) was first introduced by Ian Goodfellow in 2014. GANs are  powerful class of neural networks that are used for unsupervised learning. GANs can create anything whatever you feed to them, as it Learn-Generate-Improve. To understand GANs first you must have little understanding of Convolutional Neural Networks.   min read Wasserstein Generative Adversarial Networks (WGANs) Convergence and Optimization Wasserstein Generative Adversarial Network (WGANs) is  modification of Deep Learning GAN with few changes in the algorithm. GAN, or Generative Adversarial Network, is  way to build an accurate generative model. This network was introduced by Martin Arjovsky, Soumith Chintala, and Léon Bottou in 2017. It is widely used to generate realistic images  min read Generative Adversarial Networks (GANs) in PyTorch The aim of the article is to implement GANs architecture using PyTorch framework. The article provides comprehensive understanding of GANs in PyTorch along with in-depth explanation of the code. Generative Adversarial Networks (GANs) are  class of artificial intelligence algorithms used in unsupervised machine learning. They consist of two neural  min read Image Generation using Generative Adversarial Networks (GANs) Generative Adversarial Networks (GANs) represent  revolutionary approach to, artificial intelligence, particularly for generating images. Introduced in 2014, GANs have significantly advanced the ability to create realistic and high-quality images from random noise. In this article, we are going to train GANs model on MNIST dataset for generating   min read Architecture of Super-Resolution Generative Adversarial Networks (SRGANs) Super-Resolution Generative Adversarial Networks (SRGANs) are advanced deep learning models designed to upscale low-resolution images to high-resolution outputs with remarkable detail. This article aims to provide  comprehensive overview of SRGANs, focusing on their architecture, key components, and training techniques to enhance image quality. Ta  min read Generative Adversarial Networks (GANs) with  Generative Adversarial Networks (GANs) are  type of neural network architecture introduced by Ian Goodfellow and his colleagues in 2014. GANs are designed to generate new data samples that resemble  given dataset. They can produce high-quality synthetic data across various domains. Working of GANsGANs consist of two neural networks. first is the 15 min read Generative Adversarial Networks (GANs) vs Diffusion Models Generative Adversarial Networks (GANs) and Diffusion Models are powerful generative models designed to produce synthetic data that closely resembles real-world data. Each model has distinct architectures, strengths, and limitations, making them uniquely suited for various applications. This article aims to provide  comprehensive comparison between  min read Mastering Adversarial Attacks: How One Pixel Can Fool  Neural Network Neural networks are among the best tools for classification tasks. They power everything from image recognition to natural language processing, providing incredible accuracy and versatility. But what if  told you that you could completely undermine  neural network or trick it into making mistakes? Intrigued? Let' explore adversarial attacks and  min read Deep Convolutional GAN with Keras Deep Convolutional GAN (DCGAN) was proposed by  researcher from MIT and Facebook AI research. It is widely used in many convolution-based generation-based techniques. The focus of this paper was to make training GANs stable. Hence, they proposed some architectural changes in the computer vision problems. In this article, we will be using DCGAN on  min read Understanding Auxiliary Classifier : GAN Prerequisite: GANs(General Adversarial Networks) In this article, we will be discussing  special class conditional GAN or -GAN known as Auxiliary Classifier GAN or AC-GAN. Before getting into that, it is important to understand what  class conditional GAN is. Class-Conditional GAN (-GANs): -GAN can be understood as  GAN with some conditional  min read Building an Auxiliary GAN using Keras and Tensorflow Prerequisites: Generative Adversarial Network This article will demonstrate how to build an Auxiliary Generative Adversarial Network using the Keras and TensorFlow libraries. The dataset which is used is the MNIST Image dataset pre-loaded into Keras. Step : Setting up the environment Step  : Open Anaconda prompt in Administrator mode. Step  : Cr  min read Difference between GAN vs DCGAN. Answer: GAN is  broader class of generative models, while DCGAN specifically refers to  type of GAN that utilizes deep convolutional neural networks for image generation.Below is  detailed comparison between GAN (Generative Adversarial Network) and DCGAN (Deep Convolutional Generative Adversarial Network): FeatureGANDCGANArchitectureGeneric arch  min read Adversarial Search Algorithms Adversarial search algorithms are the backbone of strategic decision-making in artificial intelligence, it enables the agents to navigate competitive scenarios effectively. This article offers concise yet comprehensive advantages of these algorithms from their foundational principles to practical applications. Let' uncover the strategies that driv 15+ min read Alpha-Beta pruning in Adversarial Search Algorithms In artificial intelligence, particularly in game playing and decision-making, adversarial search algorithms are used to model and solve problems where two or more players compete against each other. One of the most well-known techniques in this domain is alpha-beta pruning. This article explores the concept of alpha-beta pruning, its implementation  min read Explain the role of minimax algorithm in adversarial search for optimal decision-making? In the realm of artificial intelligence (AI), particularly in game theory and decision-making scenarios involving competition, the ability to predict and counteract an opponent' moves is paramount. This is where adversarial search algorithms come into play. Among the most prominent and foundational of these algorithms is the Minimax algorithm. It 11 min read Pandas AI: The Generative AI Python Library In the age of AI, many of our tasks have been automated especially after the launch of ChatGPT. One such tool that uses the power of ChatGPT to ease data manipulation task in Python is PandasAI. It leverages the power of ChatGPT to generate Python code and executes it. The output of the generated code is returned. Pandas AI helps performing tasks   min read The Difference Between Generative and Discriminative Machine Learning Algorithms Machine learning algorithms allow computers to learn from data and make predictions or judgments, machine learning algorithms have revolutionized  number of sectors. Generic and discriminative algorithms are two essential strategies with various applications in the field of machine learning. We will examine the core distinctions between generative  min read What is Language Revitalization in Generative AI? Imagine  world where ancient tongues, on the brink of fading into silence, are reborn. Where stories whispered through generations find  digital echo and cultural knowledge carried in every syllable is amplified across the internet. This is the promise of language revitalization in generative AI,  revolutionary field that seeks to leverage the   min read Differences between Conversational AI and Generative AI Artificial intelligence has evolved significantly in the past few years, making day-to-day tasks easy and efficient. Conversational AI and Generative AI are the two subsets of artificial intelligence that rapidly advancing the field of AI and have become prominent and transformative. Both technologies make use of machine learning and natural langua  min read 10 Best Generative AI Tools to Refine Your Content Strategy Many of us struggle with content creation and strategy. We're good at the creative, artful side, like writing compelling stories. But the analytical, strategic part is harder. Even when we do get strategic, we spend lots of time on keyword research, topic selection, and tracking performance. AI content tools can give you an advantage on the science  min read  Top Generative AI Design Tools in 2024 [Free & Paid] Are you ready to level up your design game? Gone are the days when designers had to sit and design creatives from scratch. With the rise of artificial intelligence and its integration with different domains, you can save  lot of time and still come up with quality output. You can use these tools in generating base designs and even assist the whole  min read What is Generative AI? Nowadays as we all know the power of Artificial Intelligence is developing day by day, and after the introduction of Generative AI is taking creativity to the next level Generative AI is  subset of Deep learning that is again  part of Artificial Intelligence. In this article, we will explore, What is Generative AI? Examples, Definition, Models 12 min read What is the difference between Generative and Discriminative algorithm? Answer: Generative algorithms model the joint probability distribution of input features and target labels, while discriminative algorithms directly learn the decision boundary between classes.Generative algorithms focus on modeling the joint probability distribution of both input features and target labels. By capturing statistical dependencies wi  min read  Best Generative AI Tools for Developers [2024] In the rapidly evolving world of technology, generative Artificial intelligence (AI) tools for developers have become indispensable assets for innovation and efficiency. These cutting-edge tools harness the power of advanced algorithms and machine learning techniques to autonomously generate content, designs, and code, transforming the development  min read Generative Modeling in TensorFlow Generative modeling is the process of learning the underlying structure of  dataset to generate new samples that mimic the distribution of the original data. The article aims to provide  comprehensive overview of generative modelling along with the implementation leveraging the TensorFlow framework. Table of Content What are generative models and 14 min read AI-Coustics: Fights Noisy Audio With Generative AI Have you ever been troubled by noisy audio during  video call or interview? The constant hum of traffic, the rustle of wind, or even  bustling room can significantly degrade audio quality. For content creators, journalists, and anyone relying on clean audio recording and speech clarity in videos, these challenges can be  major source of frustrat  min read Article Tags : AI-ML-DS Deep Learning Python Python-Quizzes Technical Scripter python + More Practice Tags : python python Like 285k+ interested Geeks Data Structures & Algorithms in Python - Self Paced Explore 198k+ interested Geeks Python Full Course Online - Complete Beginner to Advanced Explore 927k+ interested Geeks Complete Interview Preparation Explore Explore More Read more ## Overview of GAN Structure Home Products Machine Learning Advanced courses GAN Send feedback Overview of GAN Structure Stay organized with collections Save and categorize content based on your preferences.  generative adversarial network (GAN) has two parts: The generator learns to generate plausible data. The generated instances become negative training examples for the discriminator. The discriminator learns to distinguish the generator' fake data from real data. The discriminator penalizes the generator for producing implausible results. When training begins, the generator produces obviously fake data, and the discriminator quickly learns to tell that it' fake: As training progresses, the generator gets closer to producing output that can fool the discriminator: Finally, if generator training goes well, the discriminator gets worse at telling the difference between real and fake. It starts to classify fake data as real, and its accuracy decreases. Here'  picture of the whole system: Both the generator and the discriminator are neural networks. The generator output is connected directly to the discriminator input. Through backpropagation , the discriminator' classification provides  signal that the generator uses to update its weights. Let' explain the pieces of this system in greater detail. Previous arrow_back Generative Models Next Discriminator arrow_forward Send feedback Except as otherwise noted, the content of this page is licensed under the Creative Commons Attribution . License , and code samples are licensed under the Apache . License . For details, see the Google Developers Site Policies . Java is  registered trademark of Oracle and/or its affiliates. Last updated 2022-07-18 UTC. Read more ## Statistics > Machine Learning Statistics > Machine Learning arXiv:1406.2661 (stat) [Submitted on 10 Jun 2014] Title: Generative Adversarial Networks Authors: Ian . Goodfellow , Jean Pouget-Abadie , Mehdi Mirza , Bing Xu , David Warde-Farley , Sherjil Ozair , Aaron Courville , Yoshua Bengio View  PDF of the paper titled Generative Adversarial Networks, by Ian . Goodfellow and  other authors View PDF Abstract: We propose  new framework for estimating generative models via an adversarial process, in which we simultaneously train two models:  generative model  that captures the data distribution, and  discriminative model  that estimates the probability that  sample came from the training data rather than . The training procedure for  is to maximize the probability of  making  mistake. This framework corresponds to  minimax two-player game. In the space of arbitrary functions  and ,  unique solution exists, with  recovering the training data distribution and  equal to / everywhere. In the case where  and  are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples. Subjects: Machine Learning (stat.ML) ; Machine Learning (cs.LG) Cite as: arXiv:1406.2661 [stat.ML] (or arXiv:1406.2661v1 [stat.ML] for this version) https://doi.org/10.48550/arXiv.1406.2661 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Ian Goodfellow [ view email ] [v1] Tue, 10 Jun 2014 18:58:17 UTC (,257 KB) Full-text links: Access Paper: View  PDF of the paper titled Generative Adversarial Networks, by Ian . Goodfellow and  other authors View PDF TeX Source Other Formats view license Current browse context: stat.ML < prev | next > new | recent | 2014-06 Change to browse by: cs cs.LG stat References & Citations NASA ADS Google Scholar Semantic Scholar 59 blog links ( what is this? )  export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is  framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for  project that will add value for arXiv' community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? ) Read more ## generative adversarial network (GAN) No Content Read more ## No Title No Content Read more ## No Title No Content Read more ## No Title No Content Read more ## No Title No Content Read more ##  Gentle Introduction to Generative Adversarial Networks (GANs) No Content Read more ## What is  GAN? What is Cloud Computing? Cloud Computing Concepts Hub Generative AI What is  GAN? Create an AWS Account Explore Generative AI Services Build, deploy, and run generative AI applications on AWS Check out Generative AI on AWS Innovate faster with the most comprehensive set of Generative AI services Browse Generative AI Trainings Get started on generative AI training with content built by AWS experts Read Generative AI Blogs Get the latest AWS generative AI product news and best practices What is  GAN? What are some use cases of generative adversarial networks? How does  generative adversarial network work? What are the types of generative adversarial networks? How can AWS support your generative adversarial network requirements? What is  GAN?  generative adversarial network (GAN) is  deep learning architecture. It trains two neural networks to compete against each other to generate more authentic new data from  given training dataset. For instance, you can generate new images from an existing image database or original music from  database of songs.  GAN is called adversarial because it trains two different networks and pits them against each other. One network generates new data by taking an input data sample and modifying it as much as possible. The other network tries to predict whether the generated data output belongs in the original dataset. In other words, the predicting network determines whether the generated data is fake or real. The system generates newer, improved versions of fake data values until the predicting network can no longer distinguish fake from original. What are some use cases of generative adversarial networks? The GAN architecture has several applications across different industries. Next, we give some examples. Generate images Generative adversarial networks create realistic images through text-based prompts or by modifying existing images. They can help create realistic and immersive visual experiences in video games and digital entertainment. GAN can also edit images—like converting  low-resolution image to  high resolution or turning  black-and-white image to color. It can also create realistic faces, characters, and animals for animation and video. Generate training data for other models In machine learning (ML) , data augmentation artificially increases the training set by creating modified copies of  dataset using existing data. You can use generative models for data augmentation to create synthetic data with all the attributes of real-world data. For instance, it can generate fraudulent transaction data that you then use to train another fraud-detection ML system. This data can teach the system to accurately distinguish between suspicious and genuine transactions. Complete missing information Sometimes, you may want the generative model to accurately guess and complete some missing information in  dataset. For instance, you can train GAN to generate images of the surface below ground (sub-surface) by understanding the correlation between surface data and underground structures. By studying known sub-surface images, it can create new ones using terrain maps for energy applications like geothermal mapping or carbon capture and storage. Generate 3D models from 2D data GAN can generate 3D models from 2D photos or scanned images. For instance, in healthcare, GAN combines -rays and other body scans to create realistic images of organs for surgical planning and simulation. How does  generative adversarial network work?  generative adversarial network system comprises two deep neural networks—the generator network and the discriminator network . Both networks train in an adversarial game, where one tries to generate new data and the other attempts to predict if the output is fake or real data. Technically, the GAN works as follows.  complex mathematical equation forms the basis of the entire computing process, but this is  simplistic overview: The generator neural network analyzes the training set and identifies data attributes The discriminator neural network also analyzes the initial training data and distinguishes between the attributes independently The generator modifies some data attributes by adding noise (or random changes) to certain attributes The generator passes the modified data to the discriminator The discriminator calculates the probability that the generated output belongs to the original dataset The discriminator gives some guidance to the generator to reduce the noise vector randomization in the next cycle The generator attempts to maximize the probability of mistake by the discriminator, but the discriminator attempts to minimize the probability of error. In training iterations, both the generator and discriminator evolve and confront each other continuously until they reach an equilibrium state. In the equilibrium state, the discriminator can no longer recognize synthesized data. At this point, the training process is over. GAN training example Let' contextualize the above with an example of the GAN model in image-to-image translation. Consider that the input image is  human face that the GAN attempts to modify. For example, the attributes can be the shapes of eyes or ears. Let' say the generator changes the real images by adding sunglasses to them. The discriminator receives  set of images, some of real people with sunglasses and some generated images that were modified to include sunglasses. If the discriminator can differentiate between fake and real, the generator updates its parameters to generate even better fake images. If the generator produces images that fool the discriminator, the discriminator updates its parameters. Competition improves both networks until equilibrium is reached. What are the types of generative adversarial networks? There are different types of GAN models depending on the mathematical formulas used and the different ways the generator and discriminator interact with each other. We give some commonly used models next, but the list is not comprehensive. There are numerous other GAN types—like StyleGAN, CycleGAN, and DiscoGAN—that solve different types of problems. Vanilla GAN This is the basic GAN model that generates data variation with little or no feedback from the discriminator network.  vanilla GAN typically requires enhancements for most real-world use cases. Conditional GAN  conditional GAN (cGAN) introduces the concept of conditionality, allowing for targeted data generation. The generator and discriminator receive additional information, typically as class labels or some other form of conditioning data. For instance, if generating images, the condition could be  label that describes the image content. Conditioning allows the generator to produce data that meets specific conditions. Deep xonvolutional GAN Recognizing the power of convolutional neural networks (CNNs) in image processing, Deep convolutional GAN (DCGAN) integrates CNN architectures into GANs. With DCGAN, the generator uses transposed convolutions to upscale data distribution, and the discriminator also uses convolutional layers to classify data. The DCGAN also introduces architectural guidelines to make training more stable. Super-resolution GAN Super-resolution GANS (SRGANs) focus on upscaling low-resolution images to high resolution. The goal is to enhance images to  higher resolution while maintaining image quality and details. Laplacian Pyramid GANs (LAPGANs) address the challenge of generating high-resolution images by breaking down the problem into stages. They use  hierarchical approach, with multiple generators and discriminators working at different scales or resolutions of the image. The process begins with generating  low-resolution image that improves in quality over progressive GAN stages. How can AWS support your generative adversarial network requirements? Amazon Web Services (AWS) offers many services to support your GAN requirements. Amazon SageMaker is  fully managed service that you can use to prepare data and build, train, and deploy machine learning models. These models can be used in many scenarios, and SageMaker comes with fully managed infrastructure, tools, and workflows. It has  wide range of features to accelerate GAN development and training for any application. Amazon Bedrock is  fully managed service. You can use it to access foundation models (FMs), or trained deep neural networks, from Amazon and leading artificial intelligence (AI) startups. These FMs are available through APIs—so you can choose from various options to find the best model for your needs. You can use these models in your own GAN applications. With Amazon Bedrock, you can more quickly develop and deploy scalable, reliable, and secure generative AI applications. And you don' have to manage infrastructure. AWS DeepComposer gives you  creative way to get started with ML. You can get hands-on with  musical keyboard and the latest ML techniques designed to expand your ML skills. Regardless of their background in ML or music, your developers can get started with GANs. And they can train and optimize GAN models to create original music. Get started with generative adversarial networks on AWS by creating an account today. Next Steps on AWS Check out additional product-related resources Innovate faster with AWS generative AI services Sign up for  free account Instant get access to the AWS Free Tier. Sign up Start building in the console Get started building in the AWS management console. Sign in Read more ## Generative Adversarial Networks(GANs): End-to-End Introduction No Content Read more ## Please update your browser No Content Read more ## Please update your browser No Content Read more ## Understand & manage your location when you search on Google No Content Read more ## Sign in No Content Read more ## No Title No Content Read more 

## Summary

## No Title No Content Read more ## Generative adversarial network Toggle the table of contents Generative adversarial network 23 languages العربية 閩南語 / Bân-lâm-gú Català Deutsch Ελληνικά Español فارسی Français 한국어 Italiano עברית Nederlands 日本語 Русский Simple English کوردی Suomi Svenska Türkçe Українська Tiếng Việt 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Special pages Permanent link Page information Cite this page Get shortened URL Download QR code Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Appearance move to sidebar hide From Wikipedia, the free encyclopedia Deep learning method Not to be confused with Adversarial machine learning . Part of  series on Machine learning and data mining Paradigms Supervised learning Unsupervised learning Semi-supervised learning Self-supervised learning Reinforcement learning Meta-learning Online learning Batch learning Curriculum learning Rule-based learning Neuro-symbolic AI Neuromorphic engineering Quantum machine learning Problems Classification Generative modeling Regression Clustering Dimensionality reduction Density estimation Anomaly detection Data cleaning AutoML Association rules Semantic analysis Structured prediction Feature engineering Feature learning Learning to rank Grammar induction Ontology learning Multimodal learning Supervised learning ( classification • regression ) Apprenticeship learning Decision trees Ensembles Bagging Boosting Random forest  -NN Linear regression Naive Bayes Artificial neural networks Logistic regression Perceptron Relevance vector machine (RVM) Support vector machine (SVM) Clustering BIRCH CURE Hierarchical  -means Fuzzy Expectation–maximization (EM) DBSCAN OPTICS Mean shift Dimensionality reduction Factor analysis CCA ICA LDA NMF PCA PGD -SNE SDL Structured prediction Graphical models Bayes net Conditional random field Hidden Markov Anomaly detection RANSAC  -NN Local outlier factor Isolation forest Artificial neural network Autoencoder Deep learning Feedforward neural network Recurrent neural network LSTM GRU ESN reservoir computing Boltzmann machine Restricted GAN Diffusion model SOM Convolutional neural network -Net LeNet AlexNet DeepDream Neural radiance field Transformer Vision Mamba Spiking neural network Memtransistor Electrochemical RAM (ECRAM) Reinforcement learning -learning SARSA Temporal difference (TD) Multi-agent Self-play Learning with humans Active learning Crowdsourcing Human-in-the-loop RLHF Model diagnostics Coefficient of determination Confusion matrix Learning curve ROC curve Mathematical foundations Kernel machines Bias–variance tradeoff Computational learning theory Empirical risk minimization Occam learning PAC learning Statistical learning VC theory Journals and conferences ECML PKDD NeurIPS ICML ICLR IJCAI ML JMLR Related articles Glossary of artificial intelligence List of datasets for machine-learning research List of datasets in computer vision and image processing Outline of machine learning    An illustration of how  GAN works  generative adversarial network ( GAN ) is  class of machine learning frameworks and  prominent framework for approaching generative AI . [  ] [  ] The concept was initially developed by Ian Goodfellow and his colleagues in June 2014